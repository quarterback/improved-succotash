{
  "date": "2026-02-16",
  "generated_at": "2026-02-16T06:27:26.544815+00:00",
  "model_count": 2680,
  "models": {
    "mistralai/mistral-ai-mistral-small-3.1-24b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.11,
      "name": "Mistral Small 3.1 24B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-small-24b-instruct-2501": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "name": "Mistral Small 3",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "allenai/allenai-olmo-3.1-32b-think": {
      "input_mtok": 0.15,
      "output_mtok": 0.5,
      "name": "Olmo 3.1 32B Think",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mixtral-8x22b-instruct": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Mixtral 8x22B Instruct",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "microsoft/microsoft-wizardlm-2-8x22b": {
      "input_mtok": 0.62,
      "output_mtok": 0.62,
      "name": "WizardLM-2 8x22B",
      "context_length": 65535,
      "source": "pricepertoken"
    },
    "xiaomi/xiaomi-mimo-v2-flash": {
      "input_mtok": 0.09,
      "output_mtok": 0.29,
      "name": "MiMo-V2-Flash",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "allenai/allenai-olmo-3-32b-think": {
      "input_mtok": 0.15,
      "output_mtok": 0.5,
      "name": "Olmo 3 32B Think",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4-turbo": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "name": "GPT-4 Turbo",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "kwaipilot/kwaipilot-kat-coder-pro": {
      "input_mtok": 0.207,
      "output_mtok": 0.828,
      "name": "KAT-Coder-Pro V1",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-oss-120b": {
      "input_mtok": 0.039,
      "output_mtok": 0.19,
      "name": "GPT-OSS-120b",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "allenai/allenai-olmo-2-0325-32b-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "name": "Olmo 2 32B Instruct",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "liquid/liquid-lfm2-8b-a1b": {
      "input_mtok": 0.01,
      "output_mtok": 0.02,
      "name": "LiquidAI/LFM2-8B-A1B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "liquid/liquid-lfm-2.2-6b": {
      "input_mtok": 0.01,
      "output_mtok": 0.02,
      "name": "LiquidAI/LFM2-2.6B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-3-haiku": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "name": "Claude 3 Haiku",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-large": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Mistral Large",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "qwen/alibaba-tongyi-deepresearch-30b-a3b": {
      "input_mtok": 0.09,
      "output_mtok": 0.45,
      "name": "Tongyi DeepResearch 30B A3B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "meituan/meituan-longcat-flash-chat": {
      "input_mtok": 0.2,
      "output_mtok": 0.8,
      "name": "LongCat Flash Chat",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-3.5-turbo-0613": {
      "input_mtok": 1.0,
      "output_mtok": 2.0,
      "name": "GPT-3.5 Turbo (older v0613)",
      "context_length": 4095,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-oss-safeguard-20b": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "name": "gpt-oss-safeguard-20b",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "tngtech/tngtech-deepseek-r1t2-chimera": {
      "input_mtok": 0.25,
      "output_mtok": 0.85,
      "name": "DeepSeek R1T2 Chimera",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4-turbo-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "name": "GPT-4 Turbo Preview",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "morph/morph-morph-v3-large": {
      "input_mtok": 0.9,
      "output_mtok": 1.9,
      "name": "Morph V3 Large",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "morph/morph-morph-v3-fast": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "name": "Morph V3 Fast",
      "context_length": 81920,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-7b-instruct-v0.2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "Mistral 7B Instruct v0.2",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mixtral-8x7b-instruct": {
      "input_mtok": 0.54,
      "output_mtok": 0.54,
      "name": "Mixtral 8x7B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "nousresearch/nousresearch-deephermes-3-mistral-24b-preview": {
      "input_mtok": 0.02,
      "output_mtok": 0.1,
      "name": "DeepHermes 3 Mistral 24B Preview",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "arceeai/arcee-ai-spotlight": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "name": "Spotlight",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-3-beta": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Grok 3 Beta",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-3-mini-beta": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "name": "Grok 3 Mini Beta",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "arceeai/arcee-ai-maestro-reasoning": {
      "input_mtok": 0.9,
      "output_mtok": 3.3,
      "name": "Maestro Reasoning",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "arceeai/arcee-ai-virtuoso-large": {
      "input_mtok": 0.75,
      "output_mtok": 1.2,
      "name": "Virtuoso Large",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "neversleep/neversleep-noromaid-20b": {
      "input_mtok": 1.0,
      "output_mtok": 1.75,
      "name": "Noromaid 20B",
      "context_length": 4096,
      "source": "pricepertoken"
    },
    "bytedance/bytedance-ui-tars-1.5-7b": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "name": "UI-TARS 7B",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "tngtech/tngtech-deepseek-r1t-chimera": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "name": "DeepSeek R1T Chimera",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "alfredpros/alfredpros-codellama-7b-instruct-solidity": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "name": "CodeLLaMa 7B Instruct Solidity",
      "context_length": 4096,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-saba": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "name": "Saba",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "aionlabs/aion-labs-aion-1.0": {
      "input_mtok": 4.0,
      "output_mtok": 8.0,
      "name": "Aion-1.0",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "aionlabs/aion-labs-aion-1.0-mini": {
      "input_mtok": 0.7,
      "output_mtok": 1.4,
      "name": "Aion-1.0-Mini",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-flash-preview-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "name": "Gemini 2.5 Flash Preview 09-2025",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-flash-lite-preview-09-2025": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "Gemini 2.5 Flash Lite Preview 09-2025",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "baidu/baidu-ernie-4.5-vl-424b-a47b": {
      "input_mtok": 0.42,
      "output_mtok": 1.25,
      "name": "ERNIE 4.5 VL 424B A47B",
      "context_length": 123000,
      "source": "pricepertoken"
    },
    "alpindale/alpindale-goliath-120b": {
      "input_mtok": 3.75,
      "output_mtok": 7.5,
      "name": "Goliath 120B",
      "context_length": 6144,
      "source": "pricepertoken"
    },
    "baidu/baidu-ernie-4.5-300b-a47b": {
      "input_mtok": 0.28,
      "output_mtok": 1.1,
      "name": "ERNIE 4.5 300B A47B",
      "context_length": 123000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-max": {
      "input_mtok": 1.6,
      "output_mtok": 6.4,
      "name": "Qwen-Max",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-pro-preview-05-06": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "Gemini 2.5 Pro Preview 05-06",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-plus-2025-07-28": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "name": "Qwen Plus 0728 (thinking)",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "cohere/cohere-command-r7b-12-2024": {
      "input_mtok": 0.0375,
      "output_mtok": 0.15,
      "name": "Command R7B (12-2024)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "aionlabs/aion-labs-aion-rp-llama-3.1-8b": {
      "input_mtok": 0.8,
      "output_mtok": 1.6,
      "name": "Aion-RP 1.0 (8B)",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "essentialai/essential-ai-rnj-1-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "name": "Rnj 1 Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "nex-agi/nex-agi-deepseek-v3.1-nex-n1": {
      "input_mtok": 0.27,
      "output_mtok": 1.0,
      "name": "DeepSeek V3.1 Nex N1",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-2024-11-20": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT-4o (2024-11-20)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "tencent/tencent-hunyuan-a13b-instruct": {
      "input_mtok": 0.14,
      "output_mtok": 0.57,
      "name": "Hunyuan A13B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "inception/inception-mercury": {
      "input_mtok": 0.25,
      "output_mtok": 1.0,
      "name": "Mercury",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "inception/inception-mercury-coder": {
      "input_mtok": 0.25,
      "output_mtok": 1.0,
      "name": "Mercury Coder",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "allenai/allenai-olmo-3.1-32b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "name": "Olmo 3.1 32B Instruct",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.2-codex": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "name": "GPT-5.2-Codex",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "moonshotai/moonshotai-kimi-k2.5": {
      "input_mtok": 0.45,
      "output_mtok": 0.44,
      "name": "Kimi K2.5",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "minimax/minimax-minimax-m2-her": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "name": "MiniMax M2 Her",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-audio": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT Audio",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-audio-mini": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "name": "GPT Audio Mini",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.7-flash": {
      "input_mtok": 0.06,
      "output_mtok": 0.4,
      "name": "GLM-4.7-Flash",
      "context_length": 202752,
      "source": "pricepertoken"
    },
    "writer/writer-palmyra-x5": {
      "input_mtok": 0.6,
      "output_mtok": 6.0,
      "name": "Palmyra X5",
      "context_length": 1040000,
      "source": "pricepertoken"
    },
    "allenai/allenai-molmo-2-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "Molmo 2 8B",
      "context_length": 36864,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-opus-4.6": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "name": "Claude Opus 4.6",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-coder-next": {
      "input_mtok": 0.07,
      "output_mtok": 0.3,
      "name": "Qwen3 Coder Next",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "minimax/minimax-minimax-m2.5": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "name": "MiniMax M2.5",
      "context_length": 204800,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-5": {
      "input_mtok": 0.75,
      "output_mtok": 2.55,
      "name": "GLM 5",
      "context_length": 204800,
      "source": "pricepertoken"
    },
    "stepfun-ai/stepfun-step-3.5-flash": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "name": "Step 3.5 Flash",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-max-thinking": {
      "input_mtok": 1.2,
      "output_mtok": 6.0,
      "name": "Qwen3 Max Thinking",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "cohere/cohere-command-r-08-2024": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "Command R (08-2024)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4-1106-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "name": "GPT-4 Turbo (older v1106)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "cohere/cohere-command-r-plus-08-2024": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "Command R+ (08-2024)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "arceeai/arcee-ai-coder-large": {
      "input_mtok": 0.5,
      "output_mtok": 0.8,
      "name": "Coder Large",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-2024-08-06": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT-4o (2024-08-06)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "GPT-4o-mini (2024-07-18)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-2024-05-13": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "name": "GPT-4o (2024-05-13)",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "bytedance-seed/bytedance-seed-seed-1.6-flash": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "name": "Seed 1.6 Flash",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "bytedance-seed/bytedance-seed-seed-1.6": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "name": "Seed 1.6",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "relace/relace-relace-search": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "name": "Relace Search",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "arceeai/arcee-ai-trinity-mini": {
      "input_mtok": 0.045,
      "output_mtok": 0.15,
      "name": "Trinity Mini",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "prime-intellect/prime-intellect-intellect-3": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "name": "INTELLECT-3",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "tngtech/tngtech-tng-r1t-chimera": {
      "input_mtok": 0.25,
      "output_mtok": 0.85,
      "name": "R1T Chimera",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "allenai/allenai-olmo-3-7b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "name": "Olmo 3 7B Instruct",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "allenai/allenai-olmo-3-7b-think": {
      "input_mtok": 0.12,
      "output_mtok": 0.2,
      "name": "Olmo 3 7B Think",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-voxtral-small-24b-2507": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "name": "Voxtral Small 24B 2507",
      "context_length": 32000,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.7": {
      "input_mtok": 0.4,
      "output_mtok": 1.5,
      "name": "GLM 4.7",
      "context_length": 202752,
      "source": "pricepertoken"
    },
    "google/google-gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "name": "Gemini 3 Flash Preview",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-small-creative": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "name": "Mistral Small Creative",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "nvidia/nvidia-nemotron-3-nano-30b-a3b": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "name": "Nemotron 3 Nano 30B A3B",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.2-chat": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "name": "GPT-5.2 Chat",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.2-pro": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "name": "GPT-5.2 Pro",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.2": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "name": "GPT-5.2",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-devstral-2512": {
      "input_mtok": 0.05,
      "output_mtok": 0.22,
      "name": "Devstral 2 2512",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.6v": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "name": "GLM 4.6V",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.1-codex-max": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5.1-Codex-Max",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-ministral-14b-2512": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "Ministral 3 14B 2512",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-ministral-8b-2512": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "name": "Ministral 3 8B 2512",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-ministral-3b-2512": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "name": "Ministral 3 3B 2512",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-large-2512": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "name": "Mistral Large 3 2512",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-opus-4.5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "name": "Claude Opus 4.5",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "google/google-gemini-3-pro-image-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "name": "Nano Banana Pro (Gemini 3 Pro Image Preview)",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-4.1-fast": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "name": "Grok 4.1 Fast",
      "context_length": 2000000,
      "source": "pricepertoken"
    },
    "google/google-gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "name": "Gemini 3 Pro Preview",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5.1",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.1-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5.1 Chat",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-3.5-turbo-instruct": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "name": "GPT-3.5 Turbo Instruct",
      "context_length": 4095,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.1-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5.1-Codex",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5.1-codex-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "name": "GPT-5.1-Codex-Mini",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "moonshotai/moonshotai-kimi-k2-thinking": {
      "input_mtok": 0.4,
      "output_mtok": 1.75,
      "name": "Kimi K2 Thinking",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "perplexity/perplexity-sonar-pro-search": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Sonar Pro Search",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "nvidia/nvidia-nemotron-nano-12b-v2-vl": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "name": "Nemotron Nano 12B 2 VL",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "ibm-granite/ibm-granite-granite-4.0-h-micro": {
      "input_mtok": 0.017,
      "output_mtok": 0.11,
      "name": "Granite 4.0 Micro",
      "context_length": 131000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-image-mini": {
      "input_mtok": 2.5,
      "output_mtok": 2.0,
      "name": "GPT-5 Image Mini",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-7b-instruct-v0.1": {
      "input_mtok": 0.11,
      "output_mtok": 0.19,
      "name": "Mistral 7B Instruct v0.1",
      "context_length": 2824,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-3.5-turbo-16k": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "name": "GPT-3.5 Turbo 16k",
      "context_length": 16385,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-haiku-4.5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "name": "Claude Haiku 4.5",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-image": {
      "input_mtok": 10.0,
      "output_mtok": 10.0,
      "name": "GPT-5 Image",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "openai/openai-o3-deep-research": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "name": "o3 Deep Research",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "openai/openai-o4-mini-deep-research": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "o4 Mini Deep Research",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "nvidia/nvidia-llama-3.3-nemotron-super-49b-v1.5": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "Llama 3.3 Nemotron Super 49B V1.5",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "baidu/baidu-ernie-4.5-21b-a3b-thinking": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "name": "ERNIE 4.5 21B A3B Thinking",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-flash-image": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "name": "Gemini 2.5 Flash Image (Nano Banana)",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-pro": {
      "input_mtok": 15.0,
      "output_mtok": 120.0,
      "name": "GPT-5 Pro",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.6": {
      "input_mtok": 0.35,
      "output_mtok": 1.5,
      "name": "GLM 4.6",
      "context_length": 202752,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-small-3.2-24b-instruct": {
      "input_mtok": 0.06,
      "output_mtok": 0.18,
      "name": "Mistral Small 3.2 24B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-sonnet-4.5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Claude Sonnet 4.5",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "thedrummer/thedrummer-cydonia-24b-v4.1": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "name": "Cydonia 24B V4.1",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5 Codex",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-4-fast": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "name": "Grok 4 Fast",
      "context_length": 2000000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-next-80b-a3b-instruct": {
      "input_mtok": 0.09,
      "output_mtok": 1.1,
      "name": "Qwen3 Next 80B A3B Instruct",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "nvidia/nvidia-nemotron-nano-9b-v2": {
      "input_mtok": 0.04,
      "output_mtok": 0.16,
      "name": "Nemotron Nano 9B V2",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mancer/mancer-weaver": {
      "input_mtok": 0.75,
      "output_mtok": 1.0,
      "name": "Weaver (alpha)",
      "context_length": 8000,
      "source": "pricepertoken"
    },
    "moonshotai/moonshotai-kimi-k2-0905": {
      "input_mtok": 0.39,
      "output_mtok": 1.9,
      "name": "Kimi K2 0905 (exacto)",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-30b-a3b-thinking-2507": {
      "input_mtok": 0.051,
      "output_mtok": 0.34,
      "name": "Qwen3 30B A3B Thinking 2507",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-code-fast-1": {
      "input_mtok": 0.2,
      "output_mtok": 1.5,
      "name": "Grok Code Fast 1",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "nousresearch/nousresearch-hermes-4-405b": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "name": "Hermes 4 405B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-chat-v3.1": {
      "input_mtok": 0.15,
      "output_mtok": 0.75,
      "name": "DeepSeek V3.1",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-audio-preview": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT-4o Audio",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-medium-3.1": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "name": "Mistral Medium 3.1",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "undi95/undi95-remm-slerp-l2-13b": {
      "input_mtok": 0.45,
      "output_mtok": 0.65,
      "name": "ReMM SLERP 13B",
      "context_length": 6144,
      "source": "pricepertoken"
    },
    "baidu/baidu-ernie-4.5-21b-a3b": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "name": "ERNIE 4.5 21B A3B",
      "context_length": 120000,
      "source": "pricepertoken"
    },
    "baidu/baidu-ernie-4.5-vl-28b-a3b": {
      "input_mtok": 0.14,
      "output_mtok": 0.56,
      "name": "ERNIE 4.5 VL 28B A3B",
      "context_length": 30000,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.5v": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "name": "GLM 4.5V",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "ai21/ai21-jamba-large-1.7": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "Jamba Large 1.7",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5 Chat",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-oss-20b": {
      "input_mtok": 0.03,
      "output_mtok": 0.14,
      "name": "GPT-OSS-20b",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "name": "GPT-5 Mini",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "name": "GPT-5 Nano",
      "context_length": 400000,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-opus-4.1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "name": "Claude Opus 4.1",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-codestral-2508": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "name": "Codestral 2508",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-coder-30b-a3b-instruct": {
      "input_mtok": 0.07,
      "output_mtok": 0.27,
      "name": "Qwen3 Coder 30B A3B Instruct",
      "context_length": 160000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-30b-a3b-instruct-2507": {
      "input_mtok": 0.08,
      "output_mtok": 0.33,
      "name": "Qwen3 30B A3B Instruct 2507",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.5": {
      "input_mtok": 0.35,
      "output_mtok": 1.55,
      "name": "GLM 4.5",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4.5-air": {
      "input_mtok": 0.13,
      "output_mtok": 0.85,
      "name": "GLM 4.5 Air",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "relace/relace-relace-apply-3": {
      "input_mtok": 0.85,
      "output_mtok": 1.25,
      "name": "Relace Apply 3",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "z-ai/z-ai-glm-4-32b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "name": "GLM 4 32B",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-flash-lite": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "Gemini 2.5 Flash Lite",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-235b-a22b-2507": {
      "input_mtok": 0.071,
      "output_mtok": 0.1,
      "name": "Qwen3 235B A22B Instruct 2507",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "switchpoint/switchpoint-router": {
      "input_mtok": 0.85,
      "output_mtok": 3.4,
      "name": "Switchpoint Router",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "moonshotai/moonshotai-kimi-k2": {
      "input_mtok": 0.5,
      "output_mtok": 2.4,
      "name": "Kimi K2 0711",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "opengvlab/opengvlab-internvl3-78b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "InternVL3 78B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-devstral-medium": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "name": "Devstral Medium",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-devstral-small": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "name": "Devstral Small 1.1",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Grok 4",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "minimax/minimax-minimax-m1": {
      "input_mtok": 0.4,
      "output_mtok": 2.2,
      "name": "MiniMax M1",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "gryphe/gryphe-mythomax-l2-13b": {
      "input_mtok": 0.06,
      "output_mtok": 0.06,
      "name": "MythoMax 13B",
      "context_length": 4096,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "name": "Gemini 2.5 Flash",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "Gemini 2.5 Pro",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "openai/openai-o3-pro": {
      "input_mtok": 20.0,
      "output_mtok": 80.0,
      "name": "o3 Pro",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-3-mini": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "name": "Grok 3 Mini",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "x-ai/xai-grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Grok 3",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.5-pro-preview": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "Gemini 2.5 Pro Preview 06-05",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-r1-0528": {
      "input_mtok": 0.4,
      "output_mtok": 1.75,
      "name": "R1 0528",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "name": "Claude Opus 4",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Claude Sonnet 4",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4-0314": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "name": "GPT-4 (older v0314)",
      "context_length": 8191,
      "source": "pricepertoken"
    },
    "google/google-gemma-3n-e4b-it": {
      "input_mtok": 0.02,
      "output_mtok": 0.04,
      "name": "Gemma 3n 4B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-medium-3": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "name": "Mistral Medium 3",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-guard-4-12b": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "name": "Llama Guard 4 12B",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-30b-a3b": {
      "input_mtok": 0.06,
      "output_mtok": 0.22,
      "name": "Qwen3 30B A3B",
      "context_length": 40960,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-14b": {
      "input_mtok": 0.05,
      "output_mtok": 0.22,
      "name": "Qwen3 14B",
      "context_length": 40960,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-coder": {
      "input_mtok": 0.22,
      "output_mtok": 1.0,
      "name": "Qwen3 Coder 480B A35B (exacto)",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-32b": {
      "input_mtok": 0.08,
      "output_mtok": 0.24,
      "name": "Qwen3 32B",
      "context_length": 40960,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-235b-a22b": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "name": "Qwen3 235B A22B",
      "context_length": 40960,
      "source": "pricepertoken"
    },
    "openai/openai-o4-mini-high": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o4 Mini High",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "openai/openai-o4-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o4 Mini",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen2.5-coder-7b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.09,
      "name": "Qwen2.5 Coder 7B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "GPT-4.1",
      "context_length": 1047576,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "name": "GPT-4.1 Mini",
      "context_length": 1047576,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "GPT-4.1 Nano",
      "context_length": 1047576,
      "source": "pricepertoken"
    },
    "eleutherai/eleutherai-llemma_7b": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "name": "Llemma 7b",
      "context_length": 4096,
      "source": "pricepertoken"
    },
    "nvidia/nvidia-llama-3.1-nemotron-ultra-253b-v1": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "name": "Llama 3.1 Nemotron Ultra 253B v1",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-4-maverick": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "Llama 4 Maverick",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-4-scout": {
      "input_mtok": 0.08,
      "output_mtok": 0.3,
      "name": "Llama 4 Scout",
      "context_length": 327680,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen2.5-vl-32b-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.22,
      "name": "Qwen2.5 VL 32B Instruct",
      "context_length": 16384,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-chat-v3-0324": {
      "input_mtok": 0.19,
      "output_mtok": 0.87,
      "name": "DeepSeek V3 0324",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "google/google-gemma-3-4b-it": {
      "input_mtok": 0.017,
      "output_mtok": 0.0682,
      "name": "Gemma 3 4B",
      "context_length": 96000,
      "source": "pricepertoken"
    },
    "google/google-gemma-3-12b-it": {
      "input_mtok": 0.03,
      "output_mtok": 0.1,
      "name": "Gemma 3 12B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "cohere/cohere-command-a": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "Command A",
      "context_length": 256000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-mini-search-preview": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "GPT-4o-mini Search Preview",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-search-preview": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT-4o Search Preview",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "google/google-gemma-3-27b-it": {
      "input_mtok": 0.04,
      "output_mtok": 0.15,
      "name": "Gemma 3 27B",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "thedrummer/thedrummer-skyfall-36b-v2": {
      "input_mtok": 0.55,
      "output_mtok": 0.8,
      "name": "Skyfall 36B V2",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "perplexity/perplexity-sonar-reasoning-pro": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "Sonar Reasoning Pro",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "perplexity/perplexity-sonar-pro": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Sonar Pro",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "perplexity/perplexity-sonar-deep-research": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "Sonar Deep Research",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwq-32b": {
      "input_mtok": 0.15,
      "output_mtok": 0.4,
      "name": "QwQ 32B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.0-flash-lite-001": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "name": "Gemini 2.0 Flash Lite",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "name": "GPT-4",
      "context_length": 8191,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-3.7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Claude 3.7 Sonnet",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-guard-3-8b": {
      "input_mtok": 0.02,
      "output_mtok": 0.06,
      "name": "Llama Guard 3 8B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-o3-mini-high": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o3 Mini High",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "google/google-gemini-2.0-flash-001": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "Gemini 2.0 Flash",
      "context_length": 1048576,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-vl-plus": {
      "input_mtok": 0.21,
      "output_mtok": 0.63,
      "name": "Qwen VL Plus",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-vl-max": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "name": "Qwen VL Max",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-turbo": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "name": "Qwen-Turbo",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen2.5-vl-72b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "Qwen2.5 VL 72B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-plus": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "name": "Qwen-Plus",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-3.5-turbo": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "name": "GPT-3.5 Turbo",
      "context_length": 16385,
      "source": "pricepertoken"
    },
    "openai/openai-o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o3 Mini",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-r1-distill-qwen-32b": {
      "input_mtok": 0.29,
      "output_mtok": 0.29,
      "name": "R1 Distill Qwen 32B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "perplexity/perplexity-sonar": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "name": "Sonar",
      "context_length": 127072,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-r1-distill-llama-70b": {
      "input_mtok": 0.03,
      "output_mtok": 0.11,
      "name": "R1 Distill Llama 70B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-r1": {
      "input_mtok": 0.7,
      "output_mtok": 2.5,
      "name": "R1",
      "context_length": 64000,
      "source": "pricepertoken"
    },
    "minimax/minimax-minimax-01": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "name": "MiniMax-01",
      "context_length": 1000192,
      "source": "pricepertoken"
    },
    "microsoft/microsoft-phi-4": {
      "input_mtok": 0.06,
      "output_mtok": 0.14,
      "name": "Phi 4",
      "context_length": 16384,
      "source": "pricepertoken"
    },
    "sao10k/sao10k-l3.1-70b-hanami-x1": {
      "input_mtok": 3.0,
      "output_mtok": 3.0,
      "name": "Llama 3.1 70B Hanami x1",
      "context_length": 16000,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-chat": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "name": "DeepSeek V3",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "sao10k/sao10k-l3.3-euryale-70b": {
      "input_mtok": 0.65,
      "output_mtok": 0.75,
      "name": "Llama 3.3 Euryale 70B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.3-70b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.32,
      "name": "Llama 3.3 70B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "minimax/minimax-minimax-m2.1": {
      "input_mtok": 0.27,
      "output_mtok": 0.95,
      "name": "MiniMax M2.1",
      "context_length": 196608,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-v3.2-speciale": {
      "input_mtok": 0.27,
      "output_mtok": 0.41,
      "name": "DeepSeek V3.2 Speciale",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-v3.2": {
      "input_mtok": 0.25,
      "output_mtok": 0.38,
      "name": "DeepSeek V3.2",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "minimax/minimax-minimax-m2": {
      "input_mtok": 0.255,
      "output_mtok": 1.0,
      "name": "MiniMax M2",
      "context_length": 196608,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-v3.2-exp": {
      "input_mtok": 0.27,
      "output_mtok": 0.41,
      "name": "DeepSeek V3.2 Exp",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "deepseek/deepseek-deepseek-v3.1-terminus": {
      "input_mtok": 0.21,
      "output_mtok": 0.79,
      "name": "DeepSeek V3.1 Terminus",
      "context_length": 163840,
      "source": "pricepertoken"
    },
    "nousresearch/nousresearch-hermes-4-70b": {
      "input_mtok": 0.11,
      "output_mtok": 0.38,
      "name": "Hermes 4 70B",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-o1-pro": {
      "input_mtok": 150.0,
      "output_mtok": 600.0,
      "name": "o1-pro",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "openai/openai-o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "name": "o1",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "openai/openai-o3": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "o3",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "amazon/amazon-nova-micro-v1": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "name": "Nova Micro 1.0",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "amazon/amazon-nova-pro-v1": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "name": "Nova Pro 1.0",
      "context_length": 300000,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Mistral Large 2411",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-large-2407": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Mistral Large 2407",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-pixtral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Pixtral Large 2411",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-2.5-coder-32b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.11,
      "name": "Qwen2.5 Coder 32B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "raifle/raifle-sorcererlm-8x22b": {
      "input_mtok": 4.5,
      "output_mtok": 4.5,
      "name": "SorcererLM 8x22B",
      "context_length": 16000,
      "source": "pricepertoken"
    },
    "thedrummer/thedrummer-unslopnemo-12b": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "name": "UnslopNemo 12B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-3.5-haiku": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "name": "Claude 3.5 Haiku",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "anthracite-org/anthracite-org-magnum-v4-72b": {
      "input_mtok": 3.0,
      "output_mtok": 5.0,
      "name": "Magnum v4 72B",
      "context_length": 16384,
      "source": "pricepertoken"
    },
    "anthropic/anthropic-claude-3.5-sonnet": {
      "input_mtok": 6.0,
      "output_mtok": 30.0,
      "name": "Claude 3.5 Sonnet",
      "context_length": 200000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-2.5-7b-instruct": {
      "input_mtok": 0.04,
      "output_mtok": 0.1,
      "name": "Qwen2.5 7B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "nvidia/nvidia-llama-3.1-nemotron-70b-instruct": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "name": "Llama 3.1 Nemotron 70B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "inflection/inflection-inflection-3-pi": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "Inflection 3 Pi",
      "context_length": 8000,
      "source": "pricepertoken"
    },
    "inflection/inflection-inflection-3-productivity": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "Inflection 3 Productivity",
      "context_length": 8000,
      "source": "pricepertoken"
    },
    "thedrummer/thedrummer-rocinante-12b": {
      "input_mtok": 0.17,
      "output_mtok": 0.43,
      "name": "Rocinante 12B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.2-3b-instruct": {
      "input_mtok": 0.02,
      "output_mtok": 0.02,
      "name": "Llama 3.2 3B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.2-1b-instruct": {
      "input_mtok": 0.027,
      "output_mtok": 0.2,
      "name": "Llama 3.2 1B Instruct",
      "context_length": 60000,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.2-11b-vision-instruct": {
      "input_mtok": 0.049,
      "output_mtok": 0.049,
      "name": "Llama 3.2 11B Vision Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "amazon/amazon-nova-2-lite-v1": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "name": "Nova 2 Lite",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "amazon/amazon-nova-premier-v1": {
      "input_mtok": 2.5,
      "output_mtok": 12.5,
      "name": "Nova Premier 1.0",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-vl-32b-instruct": {
      "input_mtok": 0.104,
      "output_mtok": 0.416,
      "name": "Qwen3 VL 32B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-vl-8b-thinking": {
      "input_mtok": 0.117,
      "output_mtok": 1.365,
      "name": "Qwen3 VL 8B Thinking",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-vl-8b-instruct": {
      "input_mtok": 0.08,
      "output_mtok": 0.5,
      "name": "Qwen3 VL 8B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-vl-30b-a3b-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.52,
      "name": "Qwen3 VL 30B A3B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-vl-235b-a22b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.88,
      "name": "Qwen3 VL 235B A22B Instruct",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-max": {
      "input_mtok": 1.2,
      "output_mtok": 6.0,
      "name": "Qwen3 Max",
      "context_length": 262144,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-coder-plus": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "name": "Qwen3 Coder Plus",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-coder-flash": {
      "input_mtok": 0.3,
      "output_mtok": 1.5,
      "name": "Qwen3 Coder Flash",
      "context_length": 1000000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-next-80b-a3b-thinking": {
      "input_mtok": 0.15,
      "output_mtok": 1.2,
      "name": "Qwen3 Next 80B A3B Thinking",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen3-8b": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "name": "Qwen3 8B",
      "context_length": 32000,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-2.5-72b-instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.39,
      "name": "Qwen2.5 72B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "neversleep/neversleep-llama-3.1-lumimaid-8b": {
      "input_mtok": 0.09,
      "output_mtok": 0.6,
      "name": "Lumimaid v0.2 8B",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "sao10k/sao10k-l3.1-euryale-70b": {
      "input_mtok": 0.65,
      "output_mtok": 0.75,
      "name": "Llama 3.1 Euryale 70B v2.2",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "qwen/qwen-qwen-2.5-vl-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "Qwen2.5-VL 7B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "nousresearch/nousresearch-hermes-3-llama-3.1-70b": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "name": "Hermes 3 70B Instruct",
      "context_length": 65536,
      "source": "pricepertoken"
    },
    "nousresearch/nousresearch-hermes-3-llama-3.1-405b": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "name": "Hermes 3 405B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-chatgpt-4o-latest": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "name": "ChatGPT-4o",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "sao10k/sao10k-l3-lunaris-8b": {
      "input_mtok": 0.04,
      "output_mtok": 0.05,
      "name": "Llama 3 8B Lunaris",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.1-405b": {
      "input_mtok": 4.0,
      "output_mtok": 4.0,
      "name": "Llama 3.1 405B (base)",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.1-8b-instruct": {
      "input_mtok": 0.02,
      "output_mtok": 0.05,
      "name": "Llama 3.1 8B Instruct",
      "context_length": 16384,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.1-405b-instruct": {
      "input_mtok": 4.0,
      "output_mtok": 4.0,
      "name": "Llama 3.1 405B Instruct",
      "context_length": 131000,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3.1-70b-instruct": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "name": "Llama 3.1 70B Instruct",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-nemo": {
      "input_mtok": 0.02,
      "output_mtok": 0.04,
      "name": "Mistral Nemo",
      "context_length": 131072,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "GPT-4o-mini",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "google/google-gemma-2-27b-it": {
      "input_mtok": 0.65,
      "output_mtok": 0.65,
      "name": "Gemma 2 27B",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "deepcogito/deepcogito-cogito-v2.1-671b": {
      "input_mtok": 1.25,
      "output_mtok": 1.25,
      "name": "Cogito v2.1 671B",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "nousresearch/nousresearch-hermes-2-pro-llama-3-8b": {
      "input_mtok": 0.14,
      "output_mtok": 0.14,
      "name": "Hermes 2 Pro - Llama-3 8B",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "google/google-gemma-2-9b-it": {
      "input_mtok": 0.03,
      "output_mtok": 0.09,
      "name": "Gemma 2 9B",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "sao10k/sao10k-l3-euryale-70b": {
      "input_mtok": 1.48,
      "output_mtok": 1.48,
      "name": "Llama 3 Euryale 70B v2.1",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "Mistral 7B Instruct",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "mistralai/mistral-ai-mistral-7b-instruct-v0.3": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "Mistral 7B Instruct v0.3",
      "context_length": 32768,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-guard-2-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "name": "LlamaGuard 2 8B",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3-70b-instruct": {
      "input_mtok": 0.51,
      "output_mtok": 0.74,
      "name": "Llama 3 70B Instruct",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "amazon/amazon-nova-lite-v1": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "name": "Nova Lite 1.0",
      "context_length": 300000,
      "source": "pricepertoken"
    },
    "meta-llama/meta-llama-llama-3-8b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.04,
      "name": "Llama 3 8B Instruct",
      "context_length": 8192,
      "source": "pricepertoken"
    },
    "openai/openai-gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT-4o",
      "context_length": 128000,
      "source": "pricepertoken"
    },
    "amazon/amazon-nova-micro": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "name": "Amazon Nova Micro",
      "source": "llm-prices"
    },
    "amazon/amazon-nova-lite": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "name": "Amazon Nova Lite",
      "source": "llm-prices"
    },
    "amazon/amazon-nova-pro": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "name": "Amazon Nova Pro",
      "source": "llm-prices"
    },
    "amazon/amazon-nova-premier": {
      "input_mtok": 2.5,
      "output_mtok": 12.5,
      "name": "Amazon Nova Premier",
      "source": "llm-prices"
    },
    "anthropic/claude-3.7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Claude 3.7 Sonnet",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "anthropic/claude-3.5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Claude 3.5 Sonnet",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "anthropic/claude-3-opus": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "name": "Claude 3 Opus",
      "source": "llm-prices"
    },
    "anthropic/claude-3-haiku": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "name": "Claude 3 Haiku",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "anthropic/claude-3.5-haiku": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "name": "Claude 3.5 Haiku",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "anthropic/claude-4.5-haiku": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "name": "Claude 4.5 Haiku",
      "source": "llm-prices"
    },
    "anthropic/claude-sonnet-4.5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Claude Sonnet 4 and 4.5 \u2264200k",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "anthropic/claude-sonnet-4.5-200k": {
      "input_mtok": 6.0,
      "output_mtok": 22.5,
      "name": "Claude Sonnet 4 and 4.5 >200k",
      "source": "llm-prices"
    },
    "anthropic/claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "name": "Claude Opus 4",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "anthropic/claude-opus-4-1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "name": "Claude Opus 4.1",
      "source": "llm-prices"
    },
    "anthropic/claude-opus-4-5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "name": "Claude Opus 4.5",
      "source": "llm-prices"
    },
    "deepseek/deepseek-chat": {
      "input_mtok": 0.27,
      "output_mtok": 1.1,
      "name": "DeepSeek Chat",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "deepseek/deepseek-reasoner": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "name": "DeepSeek Reasoner",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "google/gemini-2.5-pro-preview-03-25": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "Gemini 2.5 Pro Preview \u2264200k",
      "source": "llm-prices"
    },
    "google/gemini-2.5-pro-preview-03-25-200k": {
      "input_mtok": 2.5,
      "output_mtok": 15.0,
      "name": "Gemini 2.5 Pro Preview >200k",
      "source": "llm-prices"
    },
    "google/gemini-2.0-flash-lite": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "name": "Gemini 2.0 Flash Lite",
      "source": "llm-prices"
    },
    "google/gemini-2.0-flash": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "Gemini 2.0 Flash",
      "source": "llm-prices"
    },
    "google/gemini-1.5-flash": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "name": "Gemini 1.5 Flash \u2264128k",
      "source": "llm-prices"
    },
    "google/gemini-1.5-flash-128k": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "Gemini 1.5 Flash >128k",
      "source": "llm-prices"
    },
    "google/gemini-1.5-flash-8b": {
      "input_mtok": 0.0375,
      "output_mtok": 0.15,
      "name": "Gemini 1.5 Flash-8B \u2264128k",
      "source": "llm-prices"
    },
    "google/gemini-1.5-flash-8b-128k": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "name": "Gemini 1.5 Flash-8B >128k",
      "source": "llm-prices"
    },
    "google/gemini-1.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "name": "Gemini 1.5 Pro \u2264128k",
      "source": "llm-prices"
    },
    "google/gemini-1.5-pro-128k": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "Gemini 1.5 Pro >128k",
      "source": "llm-prices"
    },
    "google/gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "name": "Gemini 2.5 Flash",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "google/gemini-2.5-flash-lite": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "Gemini 2.5 Flash-Lite",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "google/gemini-2.5-flash-preview-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "name": "Gemini 2.5 Flash Preview (09-2025)",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "google/gemini-2.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "Gemini 2.5 Pro \u2264200k",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "google/gemini-2.5-pro-200k": {
      "input_mtok": 2.5,
      "output_mtok": 15.0,
      "name": "Gemini 2.5 Pro >200k",
      "source": "llm-prices"
    },
    "google/gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "name": "Gemini 3 Pro \u2264200k",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "google/gemini-3-pro-preview-200k": {
      "input_mtok": 4.0,
      "output_mtok": 18.0,
      "name": "Gemini 3 Pro >200k",
      "source": "llm-prices"
    },
    "google/gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "name": "Gemini 3 Flash Preview",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "minimax/minimax-m2": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "name": "MiniMax M2",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "mistral/pixtral-12b": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "name": "Pixtral 12B",
      "source": "llm-prices"
    },
    "mistral/mistral-small-latest": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "name": "Mistral Small 3.1",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/mistral-medium-2505": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "name": "Mistral Medium 3",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/mistral-nemo": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "name": "Mistral NeMo",
      "source": "llm-prices"
    },
    "mistral/open-mistral-7b": {
      "input_mtok": 0.25,
      "output_mtok": 0.25,
      "name": "Mistral 7B",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/open-mixtral-8x7b": {
      "input_mtok": 0.7,
      "output_mtok": 0.7,
      "name": "Mixtral 8x7B",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/open-mixtral-8x22b": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Mixtral 8x22B",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/mistral-large-latest": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Mistral Large 24.11",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/pixtral-large-latest": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "name": "Pixtral Large",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/mistral-saba-latest": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "name": "Mistral Saba",
      "source": "llm-prices"
    },
    "mistral/codestral-latest": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "name": "Codestral",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "mistral/ministral-8b-latest": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "name": "Ministral 8B 24.10",
      "source": "llm-prices"
    },
    "mistral/ministral-3b-latest": {
      "input_mtok": 0.04,
      "output_mtok": 0.04,
      "name": "Ministral 3B 24.10",
      "source": "llm-prices"
    },
    "mistral/magistral-medium-latest": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "name": "Magistral Medium",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "moonshot-ai/kimi-k2-0905-preview": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "name": "Kimi K2 0905 Preview",
      "source": "llm-prices"
    },
    "moonshot-ai/kimi-k2-0711-preview": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "name": "Kimi K2 0711 Preview",
      "source": "llm-prices"
    },
    "moonshot-ai/kimi-k2-turbo-preview": {
      "input_mtok": 1.15,
      "output_mtok": 8.0,
      "name": "Kimi K2 Turbo Preview",
      "source": "llm-prices"
    },
    "moonshot-ai/kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "name": "Kimi K2 Thinking",
      "source": "llm-prices"
    },
    "moonshot-ai/kimi-k2-thinking-turbo": {
      "input_mtok": 1.15,
      "output_mtok": 8.0,
      "name": "Kimi K2 Thinking Turbo",
      "source": "llm-prices"
    },
    "openai/text-davinci-003": {
      "input_mtok": 20.0,
      "output_mtok": 20.0,
      "name": "GPT-3 Text Davinci 003",
      "source": "llm-prices"
    },
    "openai/gpt-4.5": {
      "input_mtok": 75.0,
      "output_mtok": 150.0,
      "name": "GPT-4.5",
      "source": "llm-prices"
    },
    "openai/gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "name": "GPT-4o",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "name": "GPT-4o Mini",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/chatgpt-4o-latest": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "name": "ChatGPT 4o Latest",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o1-preview": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "name": "o1 and o1-preview",
      "source": "llm-prices"
    },
    "openai/o1-pro": {
      "input_mtok": 150.0,
      "output_mtok": 600.0,
      "name": "o1 Pro",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o1-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o1-mini",
      "source": "llm-prices"
    },
    "openai/o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o3-mini",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "GPT-4.1",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "name": "GPT-4.1 Mini",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "name": "GPT-4.1 Nano",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o3": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "name": "o3",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o4-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "name": "o4-mini",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "name": "GPT-5 Nano",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "name": "GPT-5 Mini",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-image-1": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "name": "gpt-image-1 (image gen)",
      "source": "llm-prices"
    },
    "openai/gpt-image-1-mini": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "gpt-image-1-mini (image gen)",
      "source": "llm-prices"
    },
    "openai/gpt-5-pro": {
      "input_mtok": 15.0,
      "output_mtok": 120.0,
      "name": "GPT-5 Pro",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o3-pro": {
      "input_mtok": 20.0,
      "output_mtok": 80.0,
      "name": "o3 Pro",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o4-mini-deep-research": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "name": "o4-mini Deep Research",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/o3-deep-research": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "name": "o3 Deep Research",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5.1-codex-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "name": "GPT-5.1 Codex mini",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5.1-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5.1 Codex",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5.1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "name": "GPT-5.1",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5.2": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "name": "GPT-5.2",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "openai/gpt-5.2-pro": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "name": "GPT-5.2 Pro",
      "source": "llm-prices",
      "also_in": "openrouter"
    },
    "xai/grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Grok 3",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "xai/grok-3-mini": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "name": "Grok 3 Mini",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "xai/grok-4-fast": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "name": "Grok 4 Fast \u2264128k",
      "source": "llm-prices"
    },
    "xai/grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "name": "Grok 4 \u2264128k",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "xai/grok-4-128k": {
      "input_mtok": 6.0,
      "output_mtok": 30.0,
      "name": "Grok 4 >128k",
      "source": "llm-prices"
    },
    "xai/grok-4-fast-128k": {
      "input_mtok": 0.4,
      "output_mtok": 1.0,
      "name": "Grok 4 Fast >128k",
      "source": "llm-prices"
    },
    "xai/grok-4-fast-reasoning": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "name": "Grok 4 Fast Reasoning \u2264128k",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "xai/grok-4-fast-reasoning-128k": {
      "input_mtok": 0.4,
      "output_mtok": 1.0,
      "name": "Grok 4 Fast Reasoning >128k",
      "source": "llm-prices"
    },
    "xai/grok-code-fast-1": {
      "input_mtok": 0.2,
      "output_mtok": 1.5,
      "name": "Grok Code Fast 1",
      "source": "llm-prices",
      "also_in": "litellm"
    },
    "ai21.j2-mid-v1": {
      "input_mtok": 12.5,
      "output_mtok": 12.5,
      "context_length": 8191,
      "source": "litellm"
    },
    "ai21.j2-ultra-v1": {
      "input_mtok": 18.8,
      "output_mtok": 18.8,
      "context_length": 8191,
      "source": "litellm"
    },
    "ai21.jamba-1-5-large-v1:0": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "ai21.jamba-1-5-mini-v1:0": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "ai21.jamba-instruct-v1:0": {
      "input_mtok": 0.5,
      "output_mtok": 0.7,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.writer.palmyra-x4-v1:0": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "us.writer.palmyra-x5-v1:0": {
      "input_mtok": 0.6,
      "output_mtok": 6.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "writer.palmyra-x4-v1:0": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "writer.palmyra-x5-v1:0": {
      "input_mtok": 0.6,
      "output_mtok": 6.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "amazon.nova-lite-v1:0": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 10000,
      "source": "litellm"
    },
    "amazon.nova-2-lite-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_mtok": 2.1875,
      "output_mtok": 17.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "apac.amazon.nova-2-lite-v1:0": {
      "input_mtok": 0.33,
      "output_mtok": 2.75,
      "context_length": 64000,
      "source": "litellm"
    },
    "apac.amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_mtok": 2.1875,
      "output_mtok": 17.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "eu.amazon.nova-2-lite-v1:0": {
      "input_mtok": 0.33,
      "output_mtok": 2.75,
      "context_length": 64000,
      "source": "litellm"
    },
    "eu.amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_mtok": 2.1875,
      "output_mtok": 17.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "us.amazon.nova-2-lite-v1:0": {
      "input_mtok": 0.33,
      "output_mtok": 2.75,
      "context_length": 64000,
      "source": "litellm"
    },
    "us.amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_mtok": 2.1875,
      "output_mtok": 17.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "amazon.nova-2-multimodal-embeddings-v1:0": {
      "input_mtok": 0.135,
      "output_mtok": 0.0,
      "context_length": 8172,
      "source": "litellm"
    },
    "amazon.nova-micro-v1:0": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "context_length": 10000,
      "source": "litellm"
    },
    "amazon.nova-pro-v1:0": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 10000,
      "source": "litellm"
    },
    "amazon.titan-embed-image-v1": {
      "input_mtok": 0.8,
      "output_mtok": 0.0,
      "context_length": 128,
      "source": "litellm"
    },
    "amazon.titan-embed-text-v1": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "amazon.titan-embed-text-v2:0": {
      "input_mtok": 0.2,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "twelvelabs.marengo-embed-2-7-v1:0": {
      "input_mtok": 70.0,
      "output_mtok": 0.0,
      "context_length": 77,
      "source": "litellm"
    },
    "us.twelvelabs.marengo-embed-2-7-v1:0": {
      "input_mtok": 70.0,
      "output_mtok": 0.0,
      "context_length": 77,
      "source": "litellm"
    },
    "eu.twelvelabs.marengo-embed-2-7-v1:0": {
      "input_mtok": 70.0,
      "output_mtok": 0.0,
      "context_length": 77,
      "source": "litellm"
    },
    "twelvelabs.pegasus-1-2-v1:0": {
      "input_mtok": 0.0,
      "output_mtok": 7.5,
      "context_length": null,
      "source": "litellm"
    },
    "us.twelvelabs.pegasus-1-2-v1:0": {
      "input_mtok": 0.0,
      "output_mtok": 7.5,
      "context_length": null,
      "source": "litellm"
    },
    "eu.twelvelabs.pegasus-1-2-v1:0": {
      "input_mtok": 0.0,
      "output_mtok": 7.5,
      "context_length": null,
      "source": "litellm"
    },
    "amazon.titan-text-express-v1": {
      "input_mtok": 1.3,
      "output_mtok": 1.7,
      "context_length": 8000,
      "source": "litellm"
    },
    "amazon.titan-text-lite-v1": {
      "input_mtok": 0.3,
      "output_mtok": 0.4,
      "context_length": 4000,
      "source": "litellm"
    },
    "amazon.titan-text-premier-v1:0": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 32000,
      "source": "litellm"
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "anthropic.claude-haiku-4-5@20251001": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "anthropic.claude-3-7-sonnet-20240620-v1:0": {
      "input_mtok": 3.6,
      "output_mtok": 18.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "anthropic.claude-instant-v1": {
      "input_mtok": 0.8,
      "output_mtok": 2.4,
      "context_length": 8191,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-1-20250805-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-20250514-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-6-v1": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "global.anthropic.claude-opus-4-6-v1": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-6-v1": {
      "input_mtok": 5.5,
      "output_mtok": 27.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-6-v1": {
      "input_mtok": 5.5,
      "output_mtok": 27.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "apac.anthropic.claude-opus-4-6-v1": {
      "input_mtok": 5.5,
      "output_mtok": 27.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "anthropic.claude-v1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "anthropic.claude-v2:1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "anyscale/HuggingFaceH4/zephyr-7b-beta": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 16384,
      "source": "litellm"
    },
    "anyscale/codellama/CodeLlama-34b-Instruct-hf": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "anyscale/codellama/CodeLlama-70b-Instruct-hf": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "anyscale/google/gemma-7b-it": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "anyscale/meta-llama/Llama-2-13b-chat-hf": {
      "input_mtok": 0.25,
      "output_mtok": 0.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "anyscale/meta-llama/Llama-2-70b-chat-hf": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "anyscale/meta-llama/Llama-2-7b-chat-hf": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 4096,
      "source": "litellm"
    },
    "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "anyscale/mistralai/Mistral-7B-Instruct-v0.1": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 16384,
      "source": "litellm"
    },
    "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 65536,
      "source": "litellm"
    },
    "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 16384,
      "source": "litellm"
    },
    "apac.amazon.nova-lite-v1:0": {
      "input_mtok": 0.063,
      "output_mtok": 0.252,
      "context_length": 10000,
      "source": "litellm"
    },
    "apac.amazon.nova-micro-v1:0": {
      "input_mtok": 0.037,
      "output_mtok": 0.148,
      "context_length": 10000,
      "source": "litellm"
    },
    "apac.amazon.nova-pro-v1:0": {
      "input_mtok": 0.84,
      "output_mtok": 3.36,
      "context_length": 10000,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-haiku-20240307-v1:0": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "apac.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.1,
      "output_mtok": 5.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "apac.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "au.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "azure/ada": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure/codex-mini": {
      "input_mtok": 1.5,
      "output_mtok": 6.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/command-r-plus": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/claude-haiku-4-5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "azure_ai/claude-opus-4-5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "azure_ai/claude-opus-4-6": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure_ai/claude-opus-4-1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "azure_ai/claude-sonnet-4-5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "azure/computer-use-preview": {
      "input_mtok": 3.0,
      "output_mtok": 12.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "azure_ai/gpt-oss-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/model_router": {
      "input_mtok": 0.14,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-2024-08-06": {
      "input_mtok": 2.75,
      "output_mtok": 11.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-2024-11-20": {
      "input_mtok": 2.75,
      "output_mtok": 11.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.165,
      "output_mtok": 0.66,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_mtok": 0.66,
      "output_mtok": 2.64,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
      "input_mtok": 5.5,
      "output_mtok": 22.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
      "input_mtok": 5.5,
      "output_mtok": 22.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/eu/gpt-5-2025-08-07": {
      "input_mtok": 1.375,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/gpt-5-mini-2025-08-07": {
      "input_mtok": 0.275,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/gpt-5.1": {
      "input_mtok": 1.38,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/gpt-5.1-chat": {
      "input_mtok": 1.38,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/gpt-5.1-codex": {
      "input_mtok": 1.38,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/gpt-5.1-codex-mini": {
      "input_mtok": 0.275,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/gpt-5-nano-2025-08-07": {
      "input_mtok": 0.055,
      "output_mtok": 0.44,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/eu/o1-2024-12-17": {
      "input_mtok": 16.5,
      "output_mtok": 66.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/eu/o1-mini-2024-09-12": {
      "input_mtok": 1.21,
      "output_mtok": 4.84,
      "context_length": 65536,
      "source": "litellm"
    },
    "azure/eu/o1-preview-2024-09-12": {
      "input_mtok": 16.5,
      "output_mtok": 66.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/eu/o3-mini-2025-01-31": {
      "input_mtok": 1.21,
      "output_mtok": 4.84,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/global-standard/gpt-4o-2024-11-20": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/global-standard/gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/global/gpt-4o-2024-08-06": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/global/gpt-4o-2024-11-20": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/global/gpt-5.1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/global/gpt-5.1-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/global/gpt-5.1-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/global/gpt-5.1-codex-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-3.5-turbo": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-3.5-turbo-0125": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4097,
      "source": "litellm"
    },
    "azure/gpt-35-turbo": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-0125": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-0301": {
      "input_mtok": 0.2,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-0613": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-1106": {
      "input_mtok": 1.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-16k": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-16k-0613": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-instruct": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4097,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-instruct-0914": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4097,
      "source": "litellm"
    },
    "azure/gpt-4": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-0125-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-0613": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-1106-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-32k": {
      "input_mtok": 60.0,
      "output_mtok": 120.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-32k-0613": {
      "input_mtok": 60.0,
      "output_mtok": 120.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-turbo": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-turbo-2024-04-09": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4-turbo-vision-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/gpt-4.1-2025-04-14": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/gpt-4.1-mini-2025-04-14": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/gpt-4.1-nano-2025-04-14": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/gpt-4.5-preview": {
      "input_mtok": 75.0,
      "output_mtok": 150.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-2024-05-13": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4o-2024-08-06": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-2024-11-20": {
      "input_mtok": 2.75,
      "output_mtok": 11.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-audio-2025-08-28": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-audio-mini-2025-10-06": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-audio-preview-2024-12-17": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-mini": {
      "input_mtok": 0.165,
      "output_mtok": 0.66,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.165,
      "output_mtok": 0.66,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-audio-preview-2024-12-17": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-realtime-2025-08-28": {
      "input_mtok": 4.0,
      "output_mtok": 16.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-realtime-mini-2025-10-06": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-transcribe": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-tts": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "azure/gpt-4o-realtime-preview-2024-10-01": {
      "input_mtok": 5.0,
      "output_mtok": 20.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4o-realtime-preview-2024-12-17": {
      "input_mtok": 5.0,
      "output_mtok": 20.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/gpt-4o-transcribe": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "azure/gpt-4o-transcribe-diarize": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "azure/gpt-5.1-2025-11-13": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1-chat-2025-11-13": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-5.1-codex-2025-11-13": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1-codex-mini-2025-11-13": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-2025-08-07": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-5-chat-latest": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-5-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-mini-2025-08-07": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-nano-2025-08-07": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5-pro": {
      "input_mtok": 15.0,
      "output_mtok": 120.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1-codex-max": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.1-codex-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.2": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.2-2025-12-11": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.2-chat": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-5.2-chat-2025-12-11": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/gpt-5.2-codex": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.2-pro": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-5.2-pro-2025-12-11": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/gpt-image-1": {
      "input_mtok": 5.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "azure/gpt-image-1-mini": {
      "input_mtok": 2.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "azure/gpt-image-1.5": {
      "input_mtok": 5.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "azure/gpt-image-1.5-2025-12-16": {
      "input_mtok": 5.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "azure/mistral-large-2402": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "azure/mistral-large-latest": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "azure/o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o1-2024-12-17": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o1-mini": {
      "input_mtok": 1.21,
      "output_mtok": 4.84,
      "context_length": 65536,
      "source": "litellm"
    },
    "azure/o1-mini-2024-09-12": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 65536,
      "source": "litellm"
    },
    "azure/o1-preview": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/o1-preview-2024-09-12": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/o3": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o3-2025-04-16": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o3-deep-research": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o3-mini-2025-01-31": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o3-pro": {
      "input_mtok": 20.0,
      "output_mtok": 80.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o3-pro-2025-06-10": {
      "input_mtok": 20.0,
      "output_mtok": 80.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o4-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/o4-mini-2025-04-16": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/text-embedding-3-large": {
      "input_mtok": 0.13,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure/text-embedding-3-small": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure/text-embedding-ada-002": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure/us/gpt-4.1-2025-04-14": {
      "input_mtok": 2.2,
      "output_mtok": 8.8,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/us/gpt-4.1-mini-2025-04-14": {
      "input_mtok": 0.44,
      "output_mtok": 1.76,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/us/gpt-4.1-nano-2025-04-14": {
      "input_mtok": 0.11,
      "output_mtok": 0.44,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/us/gpt-4o-2024-08-06": {
      "input_mtok": 2.75,
      "output_mtok": 11.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/us/gpt-4o-2024-11-20": {
      "input_mtok": 2.75,
      "output_mtok": 11.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/us/gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.165,
      "output_mtok": 0.66,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_mtok": 0.66,
      "output_mtok": 2.64,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/us/gpt-4o-realtime-preview-2024-10-01": {
      "input_mtok": 5.5,
      "output_mtok": 22.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/us/gpt-4o-realtime-preview-2024-12-17": {
      "input_mtok": 5.5,
      "output_mtok": 22.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure/us/gpt-5-2025-08-07": {
      "input_mtok": 1.375,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/gpt-5-mini-2025-08-07": {
      "input_mtok": 0.275,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/gpt-5-nano-2025-08-07": {
      "input_mtok": 0.055,
      "output_mtok": 0.44,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/gpt-5.1": {
      "input_mtok": 1.38,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/gpt-5.1-chat": {
      "input_mtok": 1.38,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/gpt-5.1-codex": {
      "input_mtok": 1.38,
      "output_mtok": 11.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/gpt-5.1-codex-mini": {
      "input_mtok": 0.275,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure/us/o1-2024-12-17": {
      "input_mtok": 16.5,
      "output_mtok": 66.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/us/o1-mini-2024-09-12": {
      "input_mtok": 1.21,
      "output_mtok": 4.84,
      "context_length": 65536,
      "source": "litellm"
    },
    "azure/us/o1-preview-2024-09-12": {
      "input_mtok": 16.5,
      "output_mtok": 66.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "azure/us/o3-2025-04-16": {
      "input_mtok": 2.2,
      "output_mtok": 8.8,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/us/o3-mini-2025-01-31": {
      "input_mtok": 1.21,
      "output_mtok": 4.84,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure/us/o4-mini-2025-04-16": {
      "input_mtok": 1.21,
      "output_mtok": 4.84,
      "context_length": 100000,
      "source": "litellm"
    },
    "azure_ai/Cohere-embed-v3-english": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "azure_ai/Cohere-embed-v3-multilingual": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
      "input_mtok": 0.37,
      "output_mtok": 0.37,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
      "input_mtok": 2.04,
      "output_mtok": 2.04,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
      "input_mtok": 0.71,
      "output_mtok": 0.71,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_mtok": 1.41,
      "output_mtok": 0.35,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.78,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
      "input_mtok": 1.1,
      "output_mtok": 0.37,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
      "input_mtok": 5.33,
      "output_mtok": 16.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
      "input_mtok": 2.68,
      "output_mtok": 3.54,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
      "input_mtok": 0.3,
      "output_mtok": 0.61,
      "context_length": 2048,
      "source": "litellm"
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
      "input_mtok": 0.17,
      "output_mtok": 0.68,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3-medium-4k-instruct": {
      "input_mtok": 0.17,
      "output_mtok": 0.68,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.52,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3-mini-4k-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.52,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3-small-128k-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3-small-8k-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
      "input_mtok": 0.16,
      "output_mtok": 0.64,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3.5-mini-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.52,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-3.5-vision-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.52,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-4": {
      "input_mtok": 0.125,
      "output_mtok": 0.5,
      "context_length": 16384,
      "source": "litellm"
    },
    "azure_ai/Phi-4-mini-instruct": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-4-multimodal-instruct": {
      "input_mtok": 0.08,
      "output_mtok": 0.32,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-4-mini-reasoning": {
      "input_mtok": 0.08,
      "output_mtok": 0.32,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/Phi-4-reasoning": {
      "input_mtok": 0.125,
      "output_mtok": 0.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/MAI-DS-R1": {
      "input_mtok": 1.35,
      "output_mtok": 5.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3.2": {
      "input_mtok": 0.58,
      "output_mtok": 1.68,
      "context_length": 163840,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3.2-speciale": {
      "input_mtok": 0.58,
      "output_mtok": 1.68,
      "context_length": 163840,
      "source": "litellm"
    },
    "azure_ai/deepseek-r1": {
      "input_mtok": 1.35,
      "output_mtok": 5.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3": {
      "input_mtok": 1.14,
      "output_mtok": 4.56,
      "context_length": 8192,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3-0324": {
      "input_mtok": 1.14,
      "output_mtok": 4.56,
      "context_length": 8192,
      "source": "litellm"
    },
    "azure_ai/embed-v-4-0": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "azure_ai/global/grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/global/grok-3-mini": {
      "input_mtok": 0.25,
      "output_mtok": 1.27,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/grok-3-mini": {
      "input_mtok": 0.25,
      "output_mtok": 1.27,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/grok-4-fast-non-reasoning": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/grok-4-fast-reasoning": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/grok-code-fast-1": {
      "input_mtok": 0.2,
      "output_mtok": 1.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "azure_ai/jais-30b-chat": {
      "input_mtok": 3200.0,
      "output_mtok": 9710.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "azure_ai/jamba-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 0.7,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "azure_ai/ministral-3b": {
      "input_mtok": 0.04,
      "output_mtok": 0.04,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/mistral-large": {
      "input_mtok": 4.0,
      "output_mtok": 12.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure_ai/mistral-large-2407": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/mistral-large-latest": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/mistral-large-3": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure_ai/mistral-medium-2505": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure_ai/mistral-nemo": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 4096,
      "source": "litellm"
    },
    "azure_ai/mistral-small": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "azure_ai/mistral-small-2503": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "babbage-002": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
      "input_mtok": 2.23,
      "output_mtok": 7.55,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/deepseek.v3.2": {
      "input_mtok": 0.74,
      "output_mtok": 2.22,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.73,
      "output_mtok": 3.03,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/moonshotai.kimi-k2.5": {
      "input_mtok": 0.72,
      "output_mtok": 3.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.73,
      "output_mtok": 3.03,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/moonshotai.kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.03,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 3.18,
      "output_mtok": 4.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.36,
      "output_mtok": 0.72,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ap-south-1/deepseek.v3.2": {
      "input_mtok": 0.74,
      "output_mtok": 2.22,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/ap-south-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ap-south-1/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.71,
      "output_mtok": 2.94,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/ap-south-1/moonshotai.kimi-k2.5": {
      "input_mtok": 0.72,
      "output_mtok": 3.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/ap-south-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/deepseek.v3.2": {
      "input_mtok": 0.74,
      "output_mtok": 2.22,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/moonshotai.kimi-k2.5": {
      "input_mtok": 0.72,
      "output_mtok": 3.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 3.05,
      "output_mtok": 4.03,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.35,
      "output_mtok": 0.69,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-north-1/deepseek.v3.2": {
      "input_mtok": 0.74,
      "output_mtok": 2.22,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/eu-north-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-north-1/moonshotai.kimi-k2.5": {
      "input_mtok": 0.72,
      "output_mtok": 3.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/eu-central-1/anthropic.claude-instant-v1": {
      "input_mtok": 2.48,
      "output_mtok": 8.38,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/eu-central-1/anthropic.claude-v1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/eu-central-1/anthropic.claude-v2:1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/eu-central-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-central-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 2.86,
      "output_mtok": 3.78,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.32,
      "output_mtok": 0.65,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 3.45,
      "output_mtok": 4.55,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.39,
      "output_mtok": 0.78,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-2/minimax.minimax-m2.1": {
      "input_mtok": 0.47,
      "output_mtok": 1.86,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-2/qwen.qwen3-coder-next": {
      "input_mtok": 0.78,
      "output_mtok": 1.86,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
      "input_mtok": 0.2,
      "output_mtok": 0.26,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
      "input_mtok": 10.4,
      "output_mtok": 31.2,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
      "input_mtok": 0.59,
      "output_mtok": 0.91,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/eu-south-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/eu-south-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 4.45,
      "output_mtok": 5.88,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.5,
      "output_mtok": 1.01,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/sa-east-1/deepseek.v3.2": {
      "input_mtok": 0.74,
      "output_mtok": 2.22,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/sa-east-1/minimax.minimax-m2.1": {
      "input_mtok": 0.36,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/sa-east-1/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.73,
      "output_mtok": 3.03,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/sa-east-1/moonshotai.kimi-k2.5": {
      "input_mtok": 0.72,
      "output_mtok": 3.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/sa-east-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.6,
      "output_mtok": 1.44,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-east-1/anthropic.claude-instant-v1": {
      "input_mtok": 0.8,
      "output_mtok": 2.4,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-east-1/anthropic.claude-v1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-east-1/anthropic.claude-v2:1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 2.65,
      "output_mtok": 3.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
      "input_mtok": 0.15,
      "output_mtok": 0.2,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
      "input_mtok": 0.45,
      "output_mtok": 0.7,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-east-1/deepseek.v3.2": {
      "input_mtok": 0.62,
      "output_mtok": 1.85,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/us-east-1/minimax.minimax-m2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-east-1/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/us-east-1/moonshotai.kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/us-east-1/qwen.qwen3-coder-next": {
      "input_mtok": 0.5,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-east-2/deepseek.v3.2": {
      "input_mtok": 0.62,
      "output_mtok": 1.85,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/us-east-2/minimax.minimax-m2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-east-2/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/us-east-2/moonshotai.kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/us-east-2/qwen.qwen3-coder-next": {
      "input_mtok": 0.5,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.nova-pro-v1:0": {
      "input_mtok": 0.96,
      "output_mtok": 3.84,
      "context_length": 10000,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-embed-text-v1": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0": {
      "input_mtok": 0.2,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-text-express-v1": {
      "input_mtok": 1.3,
      "output_mtok": 1.7,
      "context_length": 8000,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-text-lite-v1": {
      "input_mtok": 0.3,
      "output_mtok": 0.4,
      "context_length": 4000,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 32000,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.6,
      "output_mtok": 18.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 2.65,
      "output_mtok": 3.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 2.65,
      "context_length": 2048,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.nova-pro-v1:0": {
      "input_mtok": 0.96,
      "output_mtok": 3.84,
      "context_length": 10000,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-embed-text-v1": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0": {
      "input_mtok": 0.2,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-text-express-v1": {
      "input_mtok": 1.3,
      "output_mtok": 1.7,
      "context_length": 8000,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-text-lite-v1": {
      "input_mtok": 0.3,
      "output_mtok": 0.4,
      "context_length": 4000,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 32000,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_mtok": 3.6,
      "output_mtok": 18.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.6,
      "output_mtok": 18.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 2.65,
      "output_mtok": 3.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 2.65,
      "context_length": 2048,
      "source": "litellm"
    },
    "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 2.65,
      "output_mtok": 3.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-west-2/anthropic.claude-instant-v1": {
      "input_mtok": 0.8,
      "output_mtok": 2.4,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-west-2/anthropic.claude-v1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-west-2/anthropic.claude-v2:1": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
      "input_mtok": 0.15,
      "output_mtok": 0.2,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
      "input_mtok": 0.45,
      "output_mtok": 0.7,
      "context_length": 8191,
      "source": "litellm"
    },
    "bedrock/us-west-2/deepseek.v3.2": {
      "input_mtok": 0.62,
      "output_mtok": 1.85,
      "context_length": 163840,
      "source": "litellm"
    },
    "bedrock/us-west-2/minimax.minimax-m2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us-west-2/moonshotai.kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/us-west-2/moonshotai.kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "bedrock/us-west-2/qwen.qwen3-coder-next": {
      "input_mtok": 0.5,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "cerebras/llama-3.3-70b": {
      "input_mtok": 0.85,
      "output_mtok": 1.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "cerebras/llama3.1-70b": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "cerebras/llama3.1-8b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 128000,
      "source": "litellm"
    },
    "cerebras/gpt-oss-120b": {
      "input_mtok": 0.35,
      "output_mtok": 0.75,
      "context_length": 32768,
      "source": "litellm"
    },
    "cerebras/qwen-3-32b": {
      "input_mtok": 0.4,
      "output_mtok": 0.8,
      "context_length": 128000,
      "source": "litellm"
    },
    "cerebras/zai-glm-4.6": {
      "input_mtok": 2.25,
      "output_mtok": 2.75,
      "context_length": 128000,
      "source": "litellm"
    },
    "cerebras/zai-glm-4.7": {
      "input_mtok": 2.25,
      "output_mtok": 2.75,
      "context_length": 128000,
      "source": "litellm"
    },
    "chat-bison": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 4096,
      "source": "litellm"
    },
    "chat-bison-32k": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 8192,
      "source": "litellm"
    },
    "chat-bison-32k@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 8192,
      "source": "litellm"
    },
    "chat-bison@001": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 4096,
      "source": "litellm"
    },
    "chat-bison@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 4096,
      "source": "litellm"
    },
    "chatdolphin": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 16384,
      "source": "litellm"
    },
    "chatgpt-4o-latest": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-transcribe-diarize": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "claude-3-5-haiku-20241022": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "claude-3-5-haiku-latest": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "claude-haiku-4-5-20251001": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-haiku-4-5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-3-5-sonnet-20240620": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "claude-3-5-sonnet-20241022": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "claude-3-5-sonnet-latest": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "claude-3-7-sonnet-20250219": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-3-7-sonnet-latest": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-3-haiku-20240307": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "claude-3-opus-20240229": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "claude-3-opus-latest": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "claude-4-opus-20250514": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "claude-4-sonnet-20250514": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-sonnet-4-5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-sonnet-4-5-20250929": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-opus-4-1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "claude-opus-4-1-20250805": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "claude-opus-4-20250514": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "claude-opus-4-5-20251101": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-opus-4-5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "claude-opus-4-6": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "fast/claude-opus-4-6": {
      "input_mtok": 30.0,
      "output_mtok": 150.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "us/claude-opus-4-6": {
      "input_mtok": 5.5,
      "output_mtok": 27.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "fast/us/claude-opus-4-6": {
      "input_mtok": 30.0,
      "output_mtok": 150.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "claude-opus-4-6-20260205": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "fast/claude-opus-4-6-20260205": {
      "input_mtok": 30.0,
      "output_mtok": 150.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "us/claude-opus-4-6-20260205": {
      "input_mtok": 5.5,
      "output_mtok": 27.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "claude-sonnet-4-20250514": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-fp16": {
      "input_mtok": 1.923,
      "output_mtok": 1.923,
      "context_length": 3072,
      "source": "litellm"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-int8": {
      "input_mtok": 1.923,
      "output_mtok": 1.923,
      "context_length": 2048,
      "source": "litellm"
    },
    "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": {
      "input_mtok": 1.923,
      "output_mtok": 1.923,
      "context_length": 8192,
      "source": "litellm"
    },
    "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": {
      "input_mtok": 1.923,
      "output_mtok": 1.923,
      "context_length": 4096,
      "source": "litellm"
    },
    "code-bison": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "code-bison-32k@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "code-bison32k": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "code-bison@001": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "code-bison@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "code-gecko": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 64,
      "source": "litellm"
    },
    "code-gecko-latest": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 64,
      "source": "litellm"
    },
    "code-gecko@001": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 64,
      "source": "litellm"
    },
    "code-gecko@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 64,
      "source": "litellm"
    },
    "codechat-bison": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "codechat-bison-32k": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 8192,
      "source": "litellm"
    },
    "codechat-bison-32k@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 8192,
      "source": "litellm"
    },
    "codechat-bison@001": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "codechat-bison@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "codechat-bison@latest": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "codex-mini-latest": {
      "input_mtok": 1.5,
      "output_mtok": 6.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "cohere.command-light-text-v14": {
      "input_mtok": 0.3,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "cohere.command-r-plus-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "cohere.command-r-v1:0": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "cohere.command-text-v14": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "cohere.embed-english-v3": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "cohere.embed-multilingual-v3": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "cohere.embed-v4:0": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "cohere/embed-v4.0": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "command": {
      "input_mtok": 1.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-a-03-2025": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "command-light": {
      "input_mtok": 0.3,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-nightly": {
      "input_mtok": 1.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-r": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-r-08-2024": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-r-plus": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-r-plus-08-2024": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "command-r7b-12-2024": {
      "input_mtok": 0.15,
      "output_mtok": 0.0375,
      "context_length": 4096,
      "source": "litellm"
    },
    "computer-use-preview": {
      "input_mtok": 3.0,
      "output_mtok": 12.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "deepseek-chat": {
      "input_mtok": 0.28,
      "output_mtok": 0.42,
      "context_length": 8192,
      "source": "litellm"
    },
    "deepseek-reasoner": {
      "input_mtok": 0.28,
      "output_mtok": 0.42,
      "context_length": 65536,
      "source": "litellm"
    },
    "dashscope/qwen-coder": {
      "input_mtok": 0.3,
      "output_mtok": 1.5,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwen-max": {
      "input_mtok": 1.6,
      "output_mtok": 6.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "dashscope/qwen-plus": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwen-plus-2025-01-25": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "dashscope/qwen-plus-2025-04-28": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwen-plus-2025-07-14": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwen-turbo": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwen-turbo-2024-11-01": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "dashscope/qwen-turbo-2025-04-28": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwen-turbo-latest": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "dashscope/qwq-plus": {
      "input_mtok": 0.8,
      "output_mtok": 2.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "databricks/databricks-bge-large-en": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "databricks/databricks-claude-3-7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-claude-haiku-4-5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "databricks/databricks-claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "databricks/databricks-claude-opus-4-1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "databricks/databricks-claude-opus-4-5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "databricks/databricks-claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "databricks/databricks-claude-sonnet-4-1": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "databricks/databricks-claude-sonnet-4-5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "databricks/databricks-gemini-2-5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "databricks/databricks-gemini-2-5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65536,
      "source": "litellm"
    },
    "databricks/databricks-gemma-3-12b": {
      "input_mtok": 0.15,
      "output_mtok": 0.5,
      "context_length": 32000,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5-1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-gpt-oss-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "databricks/databricks-gpt-oss-20b": {
      "input_mtok": 0.07,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "databricks/databricks-gte-large-en": {
      "input_mtok": 0.13,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "databricks/databricks-llama-2-70b-chat": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "databricks/databricks-llama-4-maverick": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-1-8b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.45,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-3-70b-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "databricks/databricks-mixtral-8x7b-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 1.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "databricks/databricks-mpt-30b-instruct": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "databricks/databricks-mpt-7b-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "davinci-002": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "deepinfra/Gryphe/MythoMax-L2-13b": {
      "input_mtok": 0.08,
      "output_mtok": 0.09,
      "context_length": 4096,
      "source": "litellm"
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/Qwen/QwQ-32B": {
      "input_mtok": 0.15,
      "output_mtok": 0.4,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen2.5-72B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.39,
      "context_length": 32768,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen2.5-7B-Instruct": {
      "input_mtok": 0.04,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-14B": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 40960,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-235B-A22B": {
      "input_mtok": 0.18,
      "output_mtok": 0.54,
      "context_length": 40960,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "input_mtok": 0.09,
      "output_mtok": 0.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "input_mtok": 0.3,
      "output_mtok": 2.9,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-30B-A3B": {
      "input_mtok": 0.08,
      "output_mtok": 0.29,
      "context_length": 40960,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-32B": {
      "input_mtok": 0.1,
      "output_mtok": 0.28,
      "context_length": 40960,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
      "input_mtok": 0.29,
      "output_mtok": 1.2,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "input_mtok": 0.14,
      "output_mtok": 1.4,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "input_mtok": 0.14,
      "output_mtok": 1.4,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo": {
      "input_mtok": 0.04,
      "output_mtok": 0.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2": {
      "input_mtok": 0.65,
      "output_mtok": 0.75,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3": {
      "input_mtok": 0.65,
      "output_mtok": 0.75,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/allenai/olmOCR-7B-0725-FP8": {
      "input_mtok": 0.27,
      "output_mtok": 1.5,
      "context_length": 16384,
      "source": "litellm"
    },
    "deepinfra/anthropic/claude-3-7-sonnet-latest": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 200000,
      "source": "litellm"
    },
    "deepinfra/anthropic/claude-4-opus": {
      "input_mtok": 16.5,
      "output_mtok": 82.5,
      "context_length": 200000,
      "source": "litellm"
    },
    "deepinfra/anthropic/claude-4-sonnet": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 200000,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1": {
      "input_mtok": 0.7,
      "output_mtok": 2.4,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528": {
      "input_mtok": 0.5,
      "output_mtok": 2.15,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "input_mtok": 0.27,
      "output_mtok": 0.27,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Turbo": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 40960,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3": {
      "input_mtok": 0.38,
      "output_mtok": 0.89,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3-0324": {
      "input_mtok": 0.25,
      "output_mtok": 0.88,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1": {
      "input_mtok": 0.27,
      "output_mtok": 1.0,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus": {
      "input_mtok": 0.27,
      "output_mtok": 1.0,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/google/gemini-2.0-flash-001": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 1000000,
      "source": "litellm"
    },
    "deepinfra/google/gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 1000000,
      "source": "litellm"
    },
    "deepinfra/google/gemini-2.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 1000000,
      "source": "litellm"
    },
    "deepinfra/google/gemma-3-12b-it": {
      "input_mtok": 0.05,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/google/gemma-3-27b-it": {
      "input_mtok": 0.09,
      "output_mtok": 0.16,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/google/gemma-3-4b-it": {
      "input_mtok": 0.04,
      "output_mtok": 0.08,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct": {
      "input_mtok": 0.049,
      "output_mtok": 0.049,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.2-3B-Instruct": {
      "input_mtok": 0.02,
      "output_mtok": 0.02,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct": {
      "input_mtok": 0.23,
      "output_mtok": 0.4,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "input_mtok": 0.13,
      "output_mtok": 0.39,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 1048576,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_mtok": 0.08,
      "output_mtok": 0.3,
      "context_length": 327680,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-Guard-3-8B": {
      "input_mtok": 0.055,
      "output_mtok": 0.055,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-Guard-4-12B": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "context_length": 163840,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.06,
      "context_length": 8192,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "input_mtok": 0.1,
      "output_mtok": 0.28,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.05,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "input_mtok": 0.02,
      "output_mtok": 0.03,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/microsoft/WizardLM-2-8x22B": {
      "input_mtok": 0.48,
      "output_mtok": 0.48,
      "context_length": 65536,
      "source": "litellm"
    },
    "deepinfra/microsoft/phi-4": {
      "input_mtok": 0.07,
      "output_mtok": 0.14,
      "context_length": 16384,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mistral-Nemo-Instruct-2407": {
      "input_mtok": 0.02,
      "output_mtok": 0.04,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "context_length": 32768,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
      "input_mtok": 0.075,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
      "input_mtok": 0.5,
      "output_mtok": 2.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct-0905": {
      "input_mtok": 0.5,
      "output_mtok": 2.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2": {
      "input_mtok": 0.04,
      "output_mtok": 0.16,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/openai/gpt-oss-120b": {
      "input_mtok": 0.05,
      "output_mtok": 0.45,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/openai/gpt-oss-20b": {
      "input_mtok": 0.04,
      "output_mtok": 0.15,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepinfra/zai-org/GLM-4.5": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "deepseek/deepseek-coder": {
      "input_mtok": 0.14,
      "output_mtok": 0.28,
      "context_length": 4096,
      "source": "litellm"
    },
    "deepseek/deepseek-r1": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 8192,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "deepseek/deepseek-v3": {
      "input_mtok": 0.27,
      "output_mtok": 1.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "deepseek/deepseek-v3.2": {
      "input_mtok": 0.28,
      "output_mtok": 0.4,
      "context_length": 163840,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "deepseek.v3-v1:0": {
      "input_mtok": 0.58,
      "output_mtok": 1.68,
      "context_length": 81920,
      "source": "litellm"
    },
    "deepseek.v3.2": {
      "input_mtok": 0.62,
      "output_mtok": 1.85,
      "context_length": 163840,
      "source": "litellm"
    },
    "dolphin": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 16384,
      "source": "litellm"
    },
    "embed-english-light-v2.0": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "embed-english-light-v3.0": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "embed-english-v2.0": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "embed-english-v3.0": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "embed-multilingual-v2.0": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 768,
      "source": "litellm"
    },
    "embed-multilingual-v3.0": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "embed-multilingual-light-v3.0": {
      "input_mtok": 100.0,
      "output_mtok": 0.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "eu.amazon.nova-lite-v1:0": {
      "input_mtok": 0.078,
      "output_mtok": 0.312,
      "context_length": 10000,
      "source": "litellm"
    },
    "eu.amazon.nova-micro-v1:0": {
      "input_mtok": 0.046,
      "output_mtok": 0.184,
      "context_length": 10000,
      "source": "litellm"
    },
    "eu.amazon.nova-pro-v1:0": {
      "input_mtok": 1.05,
      "output_mtok": 4.2,
      "context_length": 10000,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 8192,
      "source": "litellm"
    },
    "eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.1,
      "output_mtok": 5.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-1-20250805-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-20250514-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "eu.meta.llama3-2-1b-instruct-v1:0": {
      "input_mtok": 0.13,
      "output_mtok": 0.13,
      "context_length": 4096,
      "source": "litellm"
    },
    "eu.meta.llama3-2-3b-instruct-v1:0": {
      "input_mtok": 0.19,
      "output_mtok": 0.19,
      "context_length": 4096,
      "source": "litellm"
    },
    "eu.mistral.pixtral-large-2502-v1:0": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks-ai-4.1b-to-16b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks-ai-56b-to-176b": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks-ai-above-16b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks-ai-embedding-150m-to-350m": {
      "input_mtok": 0.016,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks-ai-embedding-up-to-150m": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks-ai-moe-up-to-56b": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks-ai-up-to-4b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "fireworks_ai/WhereIsAI/UAE-Large-V1": {
      "input_mtok": 0.016,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 65536,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
      "input_mtok": 3.0,
      "output_mtok": 8.0,
      "context_length": 20480,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": {
      "input_mtok": 3.0,
      "output_mtok": 8.0,
      "context_length": 160000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 20480,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1": {
      "input_mtok": 0.56,
      "output_mtok": 1.68,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus": {
      "input_mtok": 0.56,
      "output_mtok": 1.68,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p2": {
      "input_mtok": 0.56,
      "output_mtok": 1.68,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v2": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 96000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5-air": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 96000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p6": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 202800,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": {
      "input_mtok": 3.0,
      "output_mtok": 3.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 65536,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-large": {
      "input_mtok": 3.0,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/nomic-ai/nomic-embed-text-v1": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/nomic-ai/nomic-embed-text-v1.5": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/thenlper/gte-base": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "fireworks_ai/thenlper/gte-large": {
      "input_mtok": 0.016,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "friendliai/meta-llama-3.1-70b-instruct": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "friendliai/meta-llama-3.1-8b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "ft:babbage-002": {
      "input_mtok": 1.6,
      "output_mtok": 1.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:davinci-002": {
      "input_mtok": 12.0,
      "output_mtok": 12.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo": {
      "input_mtok": 3.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo-0125": {
      "input_mtok": 3.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo-0613": {
      "input_mtok": 3.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo-1106": {
      "input_mtok": 3.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:gpt-4-0613": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "ft:gpt-4o-2024-08-06": {
      "input_mtok": 3.75,
      "output_mtok": 15.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "ft:gpt-4o-2024-11-20": {
      "input_mtok": 3.75,
      "output_mtok": 15.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "ft:gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "ft:gpt-4.1-2025-04-14": {
      "input_mtok": 3.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "ft:gpt-4.1-mini-2025-04-14": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "ft:gpt-4.1-nano-2025-04-14": {
      "input_mtok": 0.2,
      "output_mtok": 0.8,
      "context_length": 32768,
      "source": "litellm"
    },
    "ft:o4-mini-2025-04-16": {
      "input_mtok": 4.0,
      "output_mtok": 16.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "gemini-1.0-pro": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.0-pro-001": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.0-pro-002": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.0-pro-vision": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini-1.0-pro-vision-001": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini-1.0-ultra": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini-1.0-ultra-001": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini-1.5-flash": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-flash-001": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-flash-002": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-flash-exp-0827": {
      "input_mtok": 0.0047,
      "output_mtok": 0.0047,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-flash-preview-0514": {
      "input_mtok": 0.075,
      "output_mtok": 0.0047,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-pro-001": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-pro-002": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-pro-preview-0215": {
      "input_mtok": 0.0781,
      "output_mtok": 0.3125,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-pro-preview-0409": {
      "input_mtok": 0.0781,
      "output_mtok": 0.3125,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-1.5-pro-preview-0514": {
      "input_mtok": 0.0781,
      "output_mtok": 0.3125,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.0-flash": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.0-flash-001": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.0-flash-exp": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.0-flash-lite": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 1048576,
      "source": "litellm"
    },
    "gemini-2.0-flash-lite-001": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 1048576,
      "source": "litellm"
    },
    "gemini-2.0-flash-live-preview-04-09": {
      "input_mtok": 0.5,
      "output_mtok": 2.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.0-flash-preview-image-generation": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.0-pro-exp-02-05": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-flash-image": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "gemini-2.5-flash-image-preview": {
      "input_mtok": 0.3,
      "output_mtok": 30.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-3-pro-image-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "deep-research-pro-preview-12-2025": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "gemini-2.5-flash-lite": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-live-2.5-flash-preview-native-audio-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-flash-lite-preview-06-17": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-04-17": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-05-20": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "vertex_ai/gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "vertex_ai/gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-pro-exp-03-25": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-03-25": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-05-06": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-06-05": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-tts": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-robotics-er-1.5-preview": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-robotics-er-1.5-preview": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-2.5-computer-use-preview-10-2025": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "gemini-embedding-001": {
      "input_mtok": 0.15,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini-pro": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-pro-vision": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini/gemini-embedding-001": {
      "input_mtok": 0.15,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash-001": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash-002": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash-latest": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro": {
      "input_mtok": 3.5,
      "output_mtok": 10.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-001": {
      "input_mtok": 3.5,
      "output_mtok": 10.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-002": {
      "input_mtok": 3.5,
      "output_mtok": 10.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-exp-0801": {
      "input_mtok": 3.5,
      "output_mtok": 10.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-latest": {
      "input_mtok": 3.5,
      "output_mtok": 1.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-001": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-lite": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 1048576,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-live-001": {
      "input_mtok": 0.35,
      "output_mtok": 1.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-preview-image-generation": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-image": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-image-preview": {
      "input_mtok": 0.3,
      "output_mtok": 30.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-3-pro-image-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "gemini/deep-research-pro-preview-12-2025": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-lite": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-lite-preview-09-2025": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-flash-latest": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-flash-lite-latest": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-lite-preview-06-17": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-04-17": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-05-20": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-tts": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": null,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-computer-use-preview-10-2025": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "gemini/gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-05-06": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-06-05": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-tts": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-gemma-2-27b-it": {
      "input_mtok": 0.35,
      "output_mtok": 1.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-gemma-2-9b-it": {
      "input_mtok": 0.35,
      "output_mtok": 1.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-pro": {
      "input_mtok": 0.35,
      "output_mtok": 1.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-pro-vision": {
      "input_mtok": 0.35,
      "output_mtok": 1.05,
      "context_length": 2048,
      "source": "litellm"
    },
    "gmi/anthropic/claude-opus-4.5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/anthropic/claude-sonnet-4.5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/anthropic/claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/anthropic/claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/openai/gpt-5.2": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/openai/gpt-5.1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/openai/gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "gmi/openai/gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/openai/gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/deepseek-ai/DeepSeek-V3.2": {
      "input_mtok": 0.28,
      "output_mtok": 0.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/deepseek-ai/DeepSeek-V3-0324": {
      "input_mtok": 0.28,
      "output_mtok": 0.88,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/google/gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 65536,
      "source": "litellm"
    },
    "gmi/google/gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "context_length": 65536,
      "source": "litellm"
    },
    "gmi/moonshotai/Kimi-K2-Thinking": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/MiniMaxAI/MiniMax-M2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/Qwen/Qwen3-VL-235B-A22B-Instruct-FP8": {
      "input_mtok": 0.3,
      "output_mtok": 1.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "gmi/zai-org/GLM-4.7-FP8": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "google.gemma-3-12b-it": {
      "input_mtok": 0.09,
      "output_mtok": 0.29,
      "context_length": 8192,
      "source": "litellm"
    },
    "google.gemma-3-27b-it": {
      "input_mtok": 0.23,
      "output_mtok": 0.38,
      "context_length": 8192,
      "source": "litellm"
    },
    "google.gemma-3-4b-it": {
      "input_mtok": 0.04,
      "output_mtok": 0.08,
      "context_length": 8192,
      "source": "litellm"
    },
    "global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "global.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "global.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "global.amazon.nova-2-lite-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "gpt-3.5-turbo": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-0125": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-0301": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-0613": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-1106": {
      "input_mtok": 1.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-16k": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-16k-0613": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-instruct": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-3.5-turbo-instruct-0914": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4097,
      "source": "litellm"
    },
    "gpt-4": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-0125-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-0314": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-0613": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-1106-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-1106-vision-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-32k": {
      "input_mtok": 60.0,
      "output_mtok": 120.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-32k-0314": {
      "input_mtok": 60.0,
      "output_mtok": 120.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-32k-0613": {
      "input_mtok": 60.0,
      "output_mtok": 120.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-turbo": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-turbo-2024-04-09": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-turbo-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4-vision-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "gpt-4.1-2025-04-14": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "gpt-4.1-mini-2025-04-14": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "gpt-4.1-nano-2025-04-14": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "gpt-4.5-preview": {
      "input_mtok": 75.0,
      "output_mtok": 150.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4.5-preview-2025-02-27": {
      "input_mtok": 75.0,
      "output_mtok": 150.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-2024-05-13": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-2024-08-06": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-2024-11-20": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-audio-preview": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-audio-preview-2024-10-01": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-audio-preview-2024-12-17": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-audio-preview-2025-06-03": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-audio": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-audio-2025-08-28": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-audio-mini": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-audio-mini-2025-10-06": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-audio-mini-2025-12-15": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini-audio-preview": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini-realtime-preview": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-mini-search-preview": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-mini-transcribe": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "gpt-4o-mini-tts": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview": {
      "input_mtok": 5.0,
      "output_mtok": 20.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview-2024-10-01": {
      "input_mtok": 5.0,
      "output_mtok": 20.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview-2024-12-17": {
      "input_mtok": 5.0,
      "output_mtok": 20.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview-2025-06-03": {
      "input_mtok": 5.0,
      "output_mtok": 20.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-4o-search-preview": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-search-preview-2025-03-11": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-4o-transcribe": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "gpt-image-1.5": {
      "input_mtok": 5.0,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-image-1.5-2025-12-16": {
      "input_mtok": 5.0,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.1": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.1-2025-11-13": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.1-chat-latest": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-5.2": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.2-2025-12-11": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.2-chat-latest": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-5.2-pro": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.2-pro-2025-12-11": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-pro": {
      "input_mtok": 15.0,
      "output_mtok": 120.0,
      "context_length": 272000,
      "source": "litellm"
    },
    "gpt-5-pro-2025-10-06": {
      "input_mtok": 15.0,
      "output_mtok": 120.0,
      "context_length": 272000,
      "source": "litellm"
    },
    "gpt-5-2025-08-07": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-5-chat-latest": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "gpt-5-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.1-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.1-codex-max": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.1-codex-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5.2-codex": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-mini-2025-08-07": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-nano-2025-08-07": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-image-1": {
      "input_mtok": 5.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-image-1-mini": {
      "input_mtok": 2.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-realtime": {
      "input_mtok": 4.0,
      "output_mtok": 16.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-realtime-mini": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-realtime-2025-08-28": {
      "input_mtok": 4.0,
      "output_mtok": 16.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3-opus": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3.5-haiku": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3.5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3.7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "gradient_ai/deepseek-r1-distill-llama-70b": {
      "input_mtok": 0.99,
      "output_mtok": 0.99,
      "context_length": 8000,
      "source": "litellm"
    },
    "gradient_ai/llama3-8b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 512,
      "source": "litellm"
    },
    "gradient_ai/llama3.3-70b-instruct": {
      "input_mtok": 0.65,
      "output_mtok": 0.65,
      "context_length": 2048,
      "source": "litellm"
    },
    "gradient_ai/mistral-nemo-instruct-2407": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 512,
      "source": "litellm"
    },
    "gradient_ai/openai-o3": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "gradient_ai/openai-o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "amazon-nova/nova-micro-v1": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "context_length": 10000,
      "source": "litellm"
    },
    "amazon-nova/nova-lite-v1": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 10000,
      "source": "litellm"
    },
    "amazon-nova/nova-premier-v1": {
      "input_mtok": 2.5,
      "output_mtok": 12.5,
      "context_length": 10000,
      "source": "litellm"
    },
    "amazon-nova/nova-pro-v1": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 10000,
      "source": "litellm"
    },
    "groq/llama-3.1-8b-instant": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "context_length": 8192,
      "source": "litellm"
    },
    "groq/llama-3.3-70b-versatile": {
      "input_mtok": 0.59,
      "output_mtok": 0.79,
      "context_length": 32768,
      "source": "litellm"
    },
    "groq/gemma-7b-it": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "context_length": 8192,
      "source": "litellm"
    },
    "groq/meta-llama/llama-guard-4-12b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
      "input_mtok": 0.11,
      "output_mtok": 0.34,
      "context_length": 8192,
      "source": "litellm"
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "groq/openai/gpt-oss-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 32766,
      "source": "litellm"
    },
    "groq/openai/gpt-oss-20b": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "groq/qwen/qwen3-32b": {
      "input_mtok": 0.29,
      "output_mtok": 0.59,
      "context_length": 131000,
      "source": "litellm"
    },
    "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/Qwen/QwQ-32B": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/Qwen/Qwen3-235B-A22B": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
      "input_mtok": 0.25,
      "output_mtok": 0.25,
      "context_length": 131072,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "hyperbolic/moonshotai/Kimi-K2-Instruct": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "j2-light": {
      "input_mtok": 3.0,
      "output_mtok": 3.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "j2-mid": {
      "input_mtok": 10.0,
      "output_mtok": 10.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "j2-ultra": {
      "input_mtok": 15.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "jamba-1.5": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-1.5-large": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-1.5-large@001": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-1.5-mini": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-1.5-mini@001": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-large-1.6": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-large-1.7": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-mini-1.6": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "jamba-mini-1.7": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "jina-reranker-v2-base-multilingual": {
      "input_mtok": 0.018,
      "output_mtok": 0.018,
      "context_length": 1024,
      "source": "litellm"
    },
    "jp.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "jp.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.1,
      "output_mtok": 5.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "lambda_ai/deepseek-llama3.3-70b": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/deepseek-r1-0528": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/deepseek-r1-671b": {
      "input_mtok": 0.8,
      "output_mtok": 0.8,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/deepseek-v3-0324": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/hermes3-405b": {
      "input_mtok": 0.8,
      "output_mtok": 0.8,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/hermes3-70b": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/hermes3-8b": {
      "input_mtok": 0.025,
      "output_mtok": 0.04,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/lfm-40b": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/lfm-7b": {
      "input_mtok": 0.025,
      "output_mtok": 0.04,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
      "input_mtok": 0.05,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "lambda_ai/llama-4-scout-17b-16e-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-405b-instruct-fp8": {
      "input_mtok": 0.8,
      "output_mtok": 0.8,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-70b-instruct-fp8": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-8b-instruct": {
      "input_mtok": 0.025,
      "output_mtok": 0.04,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama3.2-11b-vision-instruct": {
      "input_mtok": 0.015,
      "output_mtok": 0.025,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama3.2-3b-instruct": {
      "input_mtok": 0.015,
      "output_mtok": 0.025,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/llama3.3-70b-instruct-fp8": {
      "input_mtok": 0.12,
      "output_mtok": 0.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/qwen25-coder-32b-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "lambda_ai/qwen3-32b-fp8": {
      "input_mtok": 0.05,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "luminous-base": {
      "input_mtok": 30.0,
      "output_mtok": 33.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "luminous-base-control": {
      "input_mtok": 37.5,
      "output_mtok": 41.25,
      "context_length": 2048,
      "source": "litellm"
    },
    "luminous-extended": {
      "input_mtok": 45.0,
      "output_mtok": 49.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "luminous-extended-control": {
      "input_mtok": 56.25,
      "output_mtok": 61.875,
      "context_length": 2048,
      "source": "litellm"
    },
    "luminous-supreme": {
      "input_mtok": 175.0,
      "output_mtok": 192.5,
      "context_length": 2048,
      "source": "litellm"
    },
    "luminous-supreme-control": {
      "input_mtok": 218.75,
      "output_mtok": 240.625,
      "context_length": 2048,
      "source": "litellm"
    },
    "meta.llama2-13b-chat-v1": {
      "input_mtok": 0.75,
      "output_mtok": 1.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama2-70b-chat-v1": {
      "input_mtok": 1.95,
      "output_mtok": 2.56,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-1-405b-instruct-v1:0": {
      "input_mtok": 5.32,
      "output_mtok": 16.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-1-70b-instruct-v1:0": {
      "input_mtok": 0.99,
      "output_mtok": 0.99,
      "context_length": 2048,
      "source": "litellm"
    },
    "meta.llama3-1-8b-instruct-v1:0": {
      "input_mtok": 0.22,
      "output_mtok": 0.22,
      "context_length": 2048,
      "source": "litellm"
    },
    "meta.llama3-2-11b-instruct-v1:0": {
      "input_mtok": 0.35,
      "output_mtok": 0.35,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-2-1b-instruct-v1:0": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-2-3b-instruct-v1:0": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-2-90b-instruct-v1:0": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-3-70b-instruct-v1:0": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama3-70b-instruct-v1:0": {
      "input_mtok": 2.65,
      "output_mtok": 3.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "meta.llama3-8b-instruct-v1:0": {
      "input_mtok": 0.3,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "meta.llama4-maverick-17b-instruct-v1:0": {
      "input_mtok": 0.24,
      "output_mtok": 0.97,
      "context_length": 4096,
      "source": "litellm"
    },
    "meta.llama4-scout-17b-instruct-v1:0": {
      "input_mtok": 0.17,
      "output_mtok": 0.66,
      "context_length": 4096,
      "source": "litellm"
    },
    "minimax.minimax-m2": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "minimax.minimax-m2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 1000000,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.1-lightning": {
      "input_mtok": 0.3,
      "output_mtok": 2.4,
      "context_length": 1000000,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.5": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 1000000,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.5-lightning": {
      "input_mtok": 0.3,
      "output_mtok": 2.4,
      "context_length": 1000000,
      "source": "litellm"
    },
    "minimax/MiniMax-M2": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 200000,
      "source": "litellm"
    },
    "mistral.magistral-small-2509": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral.ministral-3-14b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral.ministral-3-3b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral.ministral-3-8b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral.mistral-7b-instruct-v0:2": {
      "input_mtok": 0.15,
      "output_mtok": 0.2,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral.mistral-large-2402-v1:0": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral.mistral-large-2407-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 9.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral.mistral-large-3-675b-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral.mistral-small-2402-v1:0": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
      "input_mtok": 0.45,
      "output_mtok": 0.7,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral.voxtral-mini-3b-2507": {
      "input_mtok": 0.04,
      "output_mtok": 0.04,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral.voxtral-small-24b-2507": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral/codestral-2405": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/codestral-2508": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 256000,
      "source": "litellm"
    },
    "mistral/codestral-mamba-latest": {
      "input_mtok": 0.25,
      "output_mtok": 0.25,
      "context_length": 256000,
      "source": "litellm"
    },
    "mistral/devstral-medium-2507": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/devstral-small-2505": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/devstral-small-2507": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/labs-devstral-small-2512": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 256000,
      "source": "litellm"
    },
    "mistral/devstral-2512": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "mistral/magistral-medium-2506": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 40000,
      "source": "litellm"
    },
    "mistral/magistral-medium-2509": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 40000,
      "source": "litellm"
    },
    "mistral/magistral-small-2506": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 40000,
      "source": "litellm"
    },
    "mistral/magistral-small-latest": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 40000,
      "source": "litellm"
    },
    "mistral/mistral-embed": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral/codestral-embed": {
      "input_mtok": 0.15,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral/codestral-embed-2505": {
      "input_mtok": 0.15,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "mistral/mistral-large-2402": {
      "input_mtok": 4.0,
      "output_mtok": 12.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/mistral-large-2407": {
      "input_mtok": 3.0,
      "output_mtok": 9.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/mistral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/mistral-large-3": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/mistral-medium": {
      "input_mtok": 2.7,
      "output_mtok": 8.1,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/mistral-medium-2312": {
      "input_mtok": 2.7,
      "output_mtok": 8.1,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/mistral-medium-latest": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/mistral-small": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/mistral-tiny": {
      "input_mtok": 0.25,
      "output_mtok": 0.25,
      "context_length": 8191,
      "source": "litellm"
    },
    "mistral/open-codestral-mamba": {
      "input_mtok": 0.25,
      "output_mtok": 0.25,
      "context_length": 256000,
      "source": "litellm"
    },
    "mistral/open-mistral-nemo": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/open-mistral-nemo-2407": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/pixtral-12b-2409": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 128000,
      "source": "litellm"
    },
    "mistral/pixtral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "moonshot.kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "moonshotai.kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "moonshot/kimi-k2-0711-preview": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/kimi-k2-0905-preview": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "moonshot/kimi-k2-turbo-preview": {
      "input_mtok": 1.15,
      "output_mtok": 8.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "moonshot/kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "moonshot/kimi-latest": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/kimi-latest-128k": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/kimi-latest-32k": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "moonshot/kimi-latest-8k": {
      "input_mtok": 0.2,
      "output_mtok": 2.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "moonshot/kimi-thinking-preview": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "moonshot/kimi-k2-thinking-turbo": {
      "input_mtok": 1.15,
      "output_mtok": 8.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-128k": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-128k-0430": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-128k-vision-preview": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-32k": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-32k-0430": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-32k-vision-preview": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-8k": {
      "input_mtok": 0.2,
      "output_mtok": 2.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-8k-0430": {
      "input_mtok": 0.2,
      "output_mtok": 2.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-8k-vision-preview": {
      "input_mtok": 0.2,
      "output_mtok": 2.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-auto": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "morph/morph-v3-fast": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "context_length": 16000,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "morph/morph-v3-large": {
      "input_mtok": 0.9,
      "output_mtok": 1.9,
      "context_length": 16000,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "multimodalembedding": {
      "input_mtok": 0.8,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "multimodalembedding@001": {
      "input_mtok": 0.8,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "nscale/Qwen/QwQ-32B": {
      "input_mtok": 0.18,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "input_mtok": 0.06,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": {
      "input_mtok": 0.01,
      "output_mtok": 0.03,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": {
      "input_mtok": 0.01,
      "output_mtok": 0.03,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "input_mtok": 0.375,
      "output_mtok": 0.375,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
      "input_mtok": 0.025,
      "output_mtok": 0.025,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
      "input_mtok": 0.09,
      "output_mtok": 0.09,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "input_mtok": 0.07,
      "output_mtok": 0.07,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/meta-llama/Llama-3.1-8B-Instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.03,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/meta-llama/Llama-3.3-70B-Instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_mtok": 0.09,
      "output_mtok": 0.29,
      "context_length": null,
      "source": "litellm"
    },
    "nscale/mistralai/mixtral-8x22b-instruct-v0.1": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": null,
      "source": "litellm"
    },
    "nvidia.nemotron-nano-12b-v2": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "nvidia.nemotron-nano-9b-v2": {
      "input_mtok": 0.06,
      "output_mtok": 0.23,
      "context_length": 8192,
      "source": "litellm"
    },
    "nvidia.nemotron-nano-3-30b": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 8192,
      "source": "litellm"
    },
    "o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o1-2024-12-17": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o1-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 65536,
      "source": "litellm"
    },
    "o1-mini-2024-09-12": {
      "input_mtok": 3.0,
      "output_mtok": 12.0,
      "context_length": 65536,
      "source": "litellm"
    },
    "o1-preview": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "o1-preview-2024-09-12": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "o1-pro": {
      "input_mtok": 150.0,
      "output_mtok": 600.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o1-pro-2025-03-19": {
      "input_mtok": 150.0,
      "output_mtok": 600.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-2025-04-16": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-deep-research": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-deep-research-2025-06-26": {
      "input_mtok": 10.0,
      "output_mtok": 40.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-mini-2025-01-31": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-pro": {
      "input_mtok": 20.0,
      "output_mtok": 80.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o3-pro-2025-06-10": {
      "input_mtok": 20.0,
      "output_mtok": 80.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o4-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "o4-mini-2025-04-16": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "o4-mini-deep-research": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "o4-mini-deep-research-2025-06-26": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "oci/meta.llama-3.1-405b-instruct": {
      "input_mtok": 10.68,
      "output_mtok": 10.68,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/meta.llama-3.2-90b-vision-instruct": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/meta.llama-3.3-70b-instruct": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/meta.llama-4-scout-17b-16e-instruct": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/xai.grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 0.15,
      "context_length": 131072,
      "source": "litellm"
    },
    "oci/xai.grok-3-fast": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "oci/xai.grok-3-mini": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "oci/xai.grok-3-mini-fast": {
      "input_mtok": 0.6,
      "output_mtok": 4.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "oci/xai.grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 0.15,
      "context_length": 128000,
      "source": "litellm"
    },
    "oci/cohere.command-latest": {
      "input_mtok": 1.56,
      "output_mtok": 1.56,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/cohere.command-a-03-2025": {
      "input_mtok": 1.56,
      "output_mtok": 1.56,
      "context_length": 4000,
      "source": "litellm"
    },
    "oci/cohere.command-plus-latest": {
      "input_mtok": 1.56,
      "output_mtok": 1.56,
      "context_length": 4000,
      "source": "litellm"
    },
    "openai.gpt-oss-120b-1:0": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "openai.gpt-oss-20b-1:0": {
      "input_mtok": 0.07,
      "output_mtok": 0.3,
      "context_length": 128000,
      "source": "litellm"
    },
    "openai.gpt-oss-safeguard-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "openai.gpt-oss-safeguard-20b": {
      "input_mtok": 0.07,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-3-haiku": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 200000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-opus-4.1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-opus-4.5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 1000000,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-haiku-4.5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 200000,
      "source": "litellm"
    },
    "openrouter/bytedance/ui-tars-1.5-7b": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 2048,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-chat": {
      "input_mtok": 0.14,
      "output_mtok": 0.28,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
      "input_mtok": 0.14,
      "output_mtok": 0.28,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
      "input_mtok": 0.2,
      "output_mtok": 0.8,
      "context_length": 163840,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-v3.2": {
      "input_mtok": 0.28,
      "output_mtok": 0.4,
      "context_length": 163840,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-v3.2-exp": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 163840,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-r1": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-r1-0528": {
      "input_mtok": 0.5,
      "output_mtok": 2.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/google/gemini-2.0-flash-001": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/google/gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/google/gemini-2.5-pro": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/google/gemini-3-pro-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "openrouter/google/gemini-3-flash-preview": {
      "input_mtok": 0.5,
      "output_mtok": 3.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "openrouter/gryphe/mythomax-l2-13b": {
      "input_mtok": 1.875,
      "output_mtok": 1.875,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/mancer/weaver": {
      "input_mtok": 5.625,
      "output_mtok": 5.625,
      "context_length": 8000,
      "source": "litellm"
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
      "input_mtok": 0.59,
      "output_mtok": 0.79,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/minimax/minimax-m2": {
      "input_mtok": 0.255,
      "output_mtok": 1.02,
      "context_length": 204800,
      "source": "litellm"
    },
    "openrouter/mistralai/devstral-2512": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 65536,
      "source": "litellm"
    },
    "openrouter/mistralai/ministral-3b-2512": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "openrouter/mistralai/ministral-8b-2512": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 262144,
      "source": "litellm"
    },
    "openrouter/mistralai/ministral-14b-2512": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 262144,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-large-2512": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-7b-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.13,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-large": {
      "input_mtok": 8.0,
      "output_mtok": 24.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
      "input_mtok": 0.65,
      "output_mtok": 0.65,
      "context_length": 65536,
      "source": "litellm"
    },
    "openrouter/moonshotai/kimi-k2.5": {
      "input_mtok": 0.6,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "openrouter/openai/gpt-3.5-turbo": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4095,
      "source": "litellm"
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "context_length": 16383,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2-codex": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2-chat": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2-pro": {
      "input_mtok": 21.0,
      "output_mtok": 168.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "openrouter/openai/gpt-oss-120b": {
      "input_mtok": 0.18,
      "output_mtok": 0.8,
      "context_length": 32768,
      "source": "litellm"
    },
    "openrouter/openai/gpt-oss-20b": {
      "input_mtok": 0.02,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "openrouter/openai/o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "openrouter/openai/o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 65536,
      "source": "litellm"
    },
    "openrouter/openai/o3-mini-high": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 65536,
      "source": "litellm"
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "context_length": 33792,
      "source": "litellm"
    },
    "openrouter/qwen/qwen-vl-plus": {
      "input_mtok": 0.21,
      "output_mtok": 0.63,
      "context_length": 2048,
      "source": "litellm"
    },
    "openrouter/qwen/qwen3-coder": {
      "input_mtok": 0.22,
      "output_mtok": 0.95,
      "context_length": 262100,
      "source": "litellm"
    },
    "openrouter/qwen/qwen3-235b-a22b-2507": {
      "input_mtok": 0.071,
      "output_mtok": 0.1,
      "context_length": 262144,
      "source": "litellm"
    },
    "openrouter/qwen/qwen3-235b-a22b-thinking-2507": {
      "input_mtok": 0.11,
      "output_mtok": 0.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "openrouter/switchpoint/router": {
      "input_mtok": 0.85,
      "output_mtok": 3.4,
      "context_length": 131072,
      "source": "litellm"
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
      "input_mtok": 1.875,
      "output_mtok": 1.875,
      "context_length": 6144,
      "source": "litellm"
    },
    "openrouter/x-ai/grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.6": {
      "input_mtok": 0.4,
      "output_mtok": 1.75,
      "context_length": 131000,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.6:exacto": {
      "input_mtok": 0.45,
      "output_mtok": 1.9,
      "context_length": 131000,
      "source": "litellm"
    },
    "openrouter/xiaomi/mimo-v2-flash": {
      "input_mtok": 0.09,
      "output_mtok": 0.29,
      "context_length": 16384,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.7": {
      "input_mtok": 0.4,
      "output_mtok": 1.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.7-flash": {
      "input_mtok": 0.07,
      "output_mtok": 0.4,
      "context_length": 32000,
      "source": "litellm"
    },
    "openrouter/minimax/minimax-m2.1": {
      "input_mtok": 0.27,
      "output_mtok": 1.2,
      "context_length": 64000,
      "source": "litellm"
    },
    "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
      "input_mtok": 0.67,
      "output_mtok": 0.67,
      "context_length": 131000,
      "source": "litellm"
    },
    "ovhcloud/Llama-3.1-8B-Instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131000,
      "source": "litellm"
    },
    "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
      "input_mtok": 0.67,
      "output_mtok": 0.67,
      "context_length": 131000,
      "source": "litellm"
    },
    "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
      "input_mtok": 0.67,
      "output_mtok": 0.67,
      "context_length": 131000,
      "source": "litellm"
    },
    "ovhcloud/Mistral-7B-Instruct-v0.3": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 127000,
      "source": "litellm"
    },
    "ovhcloud/Mistral-Nemo-Instruct-2407": {
      "input_mtok": 0.13,
      "output_mtok": 0.13,
      "context_length": 118000,
      "source": "litellm"
    },
    "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
      "input_mtok": 0.09,
      "output_mtok": 0.28,
      "context_length": 128000,
      "source": "litellm"
    },
    "ovhcloud/Mixtral-8x7B-Instruct-v0.1": {
      "input_mtok": 0.63,
      "output_mtok": 0.63,
      "context_length": 32000,
      "source": "litellm"
    },
    "ovhcloud/Qwen2.5-Coder-32B-Instruct": {
      "input_mtok": 0.87,
      "output_mtok": 0.87,
      "context_length": 32000,
      "source": "litellm"
    },
    "ovhcloud/Qwen2.5-VL-72B-Instruct": {
      "input_mtok": 0.91,
      "output_mtok": 0.91,
      "context_length": 32000,
      "source": "litellm"
    },
    "ovhcloud/Qwen3-32B": {
      "input_mtok": 0.08,
      "output_mtok": 0.23,
      "context_length": 32000,
      "source": "litellm"
    },
    "ovhcloud/gpt-oss-120b": {
      "input_mtok": 0.08,
      "output_mtok": 0.4,
      "context_length": 131000,
      "source": "litellm"
    },
    "ovhcloud/gpt-oss-20b": {
      "input_mtok": 0.04,
      "output_mtok": 0.15,
      "context_length": 131000,
      "source": "litellm"
    },
    "ovhcloud/llava-v1.6-mistral-7b-hf": {
      "input_mtok": 0.29,
      "output_mtok": 0.29,
      "context_length": 32000,
      "source": "litellm"
    },
    "ovhcloud/mamba-codestral-7B-v0.1": {
      "input_mtok": 0.19,
      "output_mtok": 0.19,
      "context_length": 256000,
      "source": "litellm"
    },
    "palm/chat-bison": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 4096,
      "source": "litellm"
    },
    "palm/chat-bison-001": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 4096,
      "source": "litellm"
    },
    "palm/text-bison": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "palm/text-bison-001": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "palm/text-bison-safety-off": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "palm/text-bison-safety-recitation-off": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "perplexity/codellama-34b-instruct": {
      "input_mtok": 0.35,
      "output_mtok": 1.4,
      "context_length": 16384,
      "source": "litellm"
    },
    "perplexity/codellama-70b-instruct": {
      "input_mtok": 0.7,
      "output_mtok": 2.8,
      "context_length": 16384,
      "source": "litellm"
    },
    "perplexity/llama-2-70b-chat": {
      "input_mtok": 0.7,
      "output_mtok": 2.8,
      "context_length": 4096,
      "source": "litellm"
    },
    "perplexity/llama-3.1-70b-instruct": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "perplexity/llama-3.1-8b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
      "input_mtok": 5.0,
      "output_mtok": 5.0,
      "context_length": 127072,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 127072,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 127072,
      "source": "litellm"
    },
    "perplexity/mistral-7b-instruct": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 4096,
      "source": "litellm"
    },
    "perplexity/mixtral-8x7b-instruct": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 4096,
      "source": "litellm"
    },
    "perplexity/pplx-70b-chat": {
      "input_mtok": 0.7,
      "output_mtok": 2.8,
      "context_length": 4096,
      "source": "litellm"
    },
    "perplexity/pplx-70b-online": {
      "input_mtok": 0.0,
      "output_mtok": 2.8,
      "context_length": 4096,
      "source": "litellm"
    },
    "perplexity/pplx-7b-chat": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 8192,
      "source": "litellm"
    },
    "perplexity/pplx-7b-online": {
      "input_mtok": 0.0,
      "output_mtok": 0.28,
      "context_length": 4096,
      "source": "litellm"
    },
    "perplexity/sonar": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 128000,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "perplexity/sonar-deep-research": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 128000,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "perplexity/sonar-medium-chat": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "context_length": 16384,
      "source": "litellm"
    },
    "perplexity/sonar-medium-online": {
      "input_mtok": 0.0,
      "output_mtok": 1.8,
      "context_length": 12000,
      "source": "litellm"
    },
    "perplexity/sonar-pro": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8000,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "perplexity/sonar-reasoning": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "perplexity/sonar-reasoning-pro": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 128000,
      "source": "litellm",
      "also_in": "openrouter"
    },
    "perplexity/sonar-small-chat": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 16384,
      "source": "litellm"
    },
    "perplexity/sonar-small-online": {
      "input_mtok": 0.0,
      "output_mtok": 0.28,
      "context_length": 12000,
      "source": "litellm"
    },
    "qwen.qwen3-coder-480b-a35b-v1:0": {
      "input_mtok": 0.22,
      "output_mtok": 1.8,
      "context_length": 65536,
      "source": "litellm"
    },
    "qwen.qwen3-235b-a22b-2507-v1:0": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 131072,
      "source": "litellm"
    },
    "qwen.qwen3-coder-30b-a3b-v1:0": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "qwen.qwen3-32b-v1:0": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "qwen.qwen3-next-80b-a3b": {
      "input_mtok": 0.15,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "qwen.qwen3-vl-235b-a22b": {
      "input_mtok": 0.53,
      "output_mtok": 2.66,
      "context_length": 8192,
      "source": "litellm"
    },
    "qwen.qwen3-coder-next": {
      "input_mtok": 0.5,
      "output_mtok": 1.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "replicate/meta/llama-2-13b": {
      "input_mtok": 0.1,
      "output_mtok": 0.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/meta/llama-2-13b-chat": {
      "input_mtok": 0.1,
      "output_mtok": 0.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/meta/llama-2-70b": {
      "input_mtok": 0.65,
      "output_mtok": 2.75,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/meta/llama-2-70b-chat": {
      "input_mtok": 0.65,
      "output_mtok": 2.75,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/meta/llama-2-7b": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/meta/llama-2-7b-chat": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/meta/llama-3-70b": {
      "input_mtok": 0.65,
      "output_mtok": 2.75,
      "context_length": 8192,
      "source": "litellm"
    },
    "replicate/meta/llama-3-70b-instruct": {
      "input_mtok": 0.65,
      "output_mtok": 2.75,
      "context_length": 8192,
      "source": "litellm"
    },
    "replicate/meta/llama-3-8b": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 8086,
      "source": "litellm"
    },
    "replicate/meta/llama-3-8b-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 8086,
      "source": "litellm"
    },
    "replicate/mistralai/mistral-7b-instruct-v0.2": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/mistralai/mistral-7b-v0.1": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/mistralai/mixtral-8x7b-instruct-v0.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "replicate/openai/gpt-5": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicateopenai/gpt-oss-20b": {
      "input_mtok": 0.09,
      "output_mtok": 0.36,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/anthropic/claude-4.5-haiku": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/ibm-granite/granite-3.3-8b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.25,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/o4-mini": {
      "input_mtok": 1.0,
      "output_mtok": 4.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/o1-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/qwen/qwen3-235b-a22b-instruct-2507": {
      "input_mtok": 0.264,
      "output_mtok": 1.06,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/anthropic/claude-4-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/deepseek-ai/deepseek-v3": {
      "input_mtok": 1.45,
      "output_mtok": 1.45,
      "context_length": 8192,
      "source": "litellm"
    },
    "replicate/anthropic/claude-3.7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/anthropic/claude-3.5-haiku": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/anthropic/claude-3.5-sonnet": {
      "input_mtok": 3.75,
      "output_mtok": 18.75,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/google/gemini-3-pro": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/anthropic/claude-4.5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-5-nano": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-5-mini": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/google/gemini-2.5-flash": {
      "input_mtok": 2.5,
      "output_mtok": 2.5,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/openai/gpt-oss-120b": {
      "input_mtok": 0.18,
      "output_mtok": 0.72,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/deepseek-ai/deepseek-v3.1": {
      "input_mtok": 0.672,
      "output_mtok": 2.016,
      "context_length": 163840,
      "source": "litellm"
    },
    "replicate/xai/grok-4": {
      "input_mtok": 7.2,
      "output_mtok": 36.0,
      "context_length": null,
      "source": "litellm"
    },
    "replicate/deepseek-ai/deepseek-r1": {
      "input_mtok": 3.75,
      "output_mtok": 10.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "sambanova/DeepSeek-R1": {
      "input_mtok": 5.0,
      "output_mtok": 7.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "sambanova/DeepSeek-R1-Distill-Llama-70B": {
      "input_mtok": 0.7,
      "output_mtok": 1.4,
      "context_length": 131072,
      "source": "litellm"
    },
    "sambanova/DeepSeek-V3-0324": {
      "input_mtok": 3.0,
      "output_mtok": 4.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
      "input_mtok": 0.63,
      "output_mtok": 1.8,
      "context_length": 131072,
      "source": "litellm"
    },
    "sambanova/Llama-4-Scout-17B-16E-Instruct": {
      "input_mtok": 0.4,
      "output_mtok": 0.7,
      "context_length": 8192,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.1-405B-Instruct": {
      "input_mtok": 5.0,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.1-8B-Instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.2-1B-Instruct": {
      "input_mtok": 0.04,
      "output_mtok": 0.08,
      "context_length": 16384,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.2-3B-Instruct": {
      "input_mtok": 0.08,
      "output_mtok": 0.16,
      "context_length": 4096,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.3-70B-Instruct": {
      "input_mtok": 0.6,
      "output_mtok": 1.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-Guard-3-8B": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 16384,
      "source": "litellm"
    },
    "sambanova/QwQ-32B": {
      "input_mtok": 0.5,
      "output_mtok": 1.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "sambanova/Qwen2-Audio-7B-Instruct": {
      "input_mtok": 0.5,
      "output_mtok": 100.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "sambanova/Qwen3-32B": {
      "input_mtok": 0.4,
      "output_mtok": 0.8,
      "context_length": 8192,
      "source": "litellm"
    },
    "sambanova/DeepSeek-V3.1": {
      "input_mtok": 3.0,
      "output_mtok": 4.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "sambanova/gpt-oss-120b": {
      "input_mtok": 3.0,
      "output_mtok": 4.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "text-bison32k": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "text-bison32k@002": {
      "input_mtok": 0.125,
      "output_mtok": 0.125,
      "context_length": 1024,
      "source": "litellm"
    },
    "text-embedding-004": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "text-embedding-005": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "text-embedding-3-large": {
      "input_mtok": 0.13,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "text-embedding-3-small": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "text-embedding-ada-002": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "text-embedding-ada-002-v2": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "text-embedding-large-exp-03-07": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "text-embedding-preview-0409": {
      "input_mtok": 0.0062,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "text-multilingual-embedding-002": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "text-multilingual-embedding-preview-0409": {
      "input_mtok": 0.0062,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "text-unicorn": {
      "input_mtok": 10.0,
      "output_mtok": 28.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "text-unicorn@001": {
      "input_mtok": 10.0,
      "output_mtok": 28.0,
      "context_length": 1024,
      "source": "litellm"
    },
    "textembedding-gecko": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "textembedding-gecko-multilingual": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "textembedding-gecko-multilingual@001": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "textembedding-gecko@001": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "textembedding-gecko@003": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 3072,
      "source": "litellm"
    },
    "together-ai-21.1b-41b": {
      "input_mtok": 0.8,
      "output_mtok": 0.8,
      "context_length": null,
      "source": "litellm"
    },
    "together-ai-4.1b-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": null,
      "source": "litellm"
    },
    "together-ai-41.1b-80b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": null,
      "source": "litellm"
    },
    "together-ai-8.1b-21b": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 1000,
      "source": "litellm"
    },
    "together-ai-81.1b-110b": {
      "input_mtok": 1.8,
      "output_mtok": 1.8,
      "context_length": null,
      "source": "litellm"
    },
    "together-ai-embedding-151m-to-350m": {
      "input_mtok": 0.016,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "together-ai-embedding-up-to-150m": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/baai/bge-base-en-v1.5": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "together_ai/BAAI/bge-base-en-v1.5": {
      "input_mtok": 0.008,
      "output_mtok": 0.0,
      "context_length": 512,
      "source": "litellm"
    },
    "together-ai-up-to-4b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
      "input_mtok": 0.2,
      "output_mtok": 6.0,
      "context_length": 262000,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "input_mtok": 0.65,
      "output_mtok": 3.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-235B-A22B-fp8-tput": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 40000,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-R1": {
      "input_mtok": 3.0,
      "output_mtok": 7.0,
      "context_length": 20480,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-R1-0528-tput": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 128000,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-V3": {
      "input_mtok": 1.25,
      "output_mtok": 1.25,
      "context_length": 8192,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-V3.1": {
      "input_mtok": 0.6,
      "output_mtok": 1.7,
      "context_length": 128000,
      "source": "litellm"
    },
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "input_mtok": 0.88,
      "output_mtok": 0.88,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_mtok": 0.27,
      "output_mtok": 0.85,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_mtok": 0.18,
      "output_mtok": 0.59,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
      "input_mtok": 3.5,
      "output_mtok": 3.5,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "input_mtok": 0.88,
      "output_mtok": 0.88,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/moonshotai/Kimi-K2-Instruct": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": null,
      "source": "litellm"
    },
    "together_ai/openai/gpt-oss-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "together_ai/openai/gpt-oss-20b": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "together_ai/zai-org/GLM-4.5-Air-FP8": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "context_length": 128000,
      "source": "litellm"
    },
    "together_ai/zai-org/GLM-4.6": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 200000,
      "source": "litellm"
    },
    "together_ai/zai-org/GLM-4.7": {
      "input_mtok": 0.45,
      "output_mtok": 2.0,
      "context_length": 200000,
      "source": "litellm"
    },
    "together_ai/moonshotai/Kimi-K2.5": {
      "input_mtok": 0.5,
      "output_mtok": 2.8,
      "context_length": 256000,
      "source": "litellm"
    },
    "together_ai/moonshotai/Kimi-K2-Instruct-0905": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "input_mtok": 0.15,
      "output_mtok": 1.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "input_mtok": 0.15,
      "output_mtok": 1.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "us.amazon.nova-lite-v1:0": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 10000,
      "source": "litellm"
    },
    "us.amazon.nova-micro-v1:0": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "context_length": 10000,
      "source": "litellm"
    },
    "us.amazon.nova-premier-v1:0": {
      "input_mtok": 2.5,
      "output_mtok": 12.5,
      "context_length": 10000,
      "source": "litellm"
    },
    "us.amazon.nova-pro-v1:0": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 10000,
      "source": "litellm"
    },
    "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "us.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.1,
      "output_mtok": 5.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-1-20250805-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_mtok": 3.3,
      "output_mtok": 16.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "au.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_mtok": 1.1,
      "output_mtok": 5.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-20250514-v1:0": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_mtok": 5.5,
      "output_mtok": 27.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "global.anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "us.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "us.deepseek.r1-v1:0": {
      "input_mtok": 1.35,
      "output_mtok": 5.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.deepseek.v3.2": {
      "input_mtok": 0.62,
      "output_mtok": 1.85,
      "context_length": 163840,
      "source": "litellm"
    },
    "eu.deepseek.v3.2": {
      "input_mtok": 0.74,
      "output_mtok": 2.22,
      "context_length": 163840,
      "source": "litellm"
    },
    "us.meta.llama3-1-405b-instruct-v1:0": {
      "input_mtok": 5.32,
      "output_mtok": 16.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama3-1-70b-instruct-v1:0": {
      "input_mtok": 0.99,
      "output_mtok": 0.99,
      "context_length": 2048,
      "source": "litellm"
    },
    "us.meta.llama3-1-8b-instruct-v1:0": {
      "input_mtok": 0.22,
      "output_mtok": 0.22,
      "context_length": 2048,
      "source": "litellm"
    },
    "us.meta.llama3-2-11b-instruct-v1:0": {
      "input_mtok": 0.35,
      "output_mtok": 0.35,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama3-2-1b-instruct-v1:0": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama3-2-3b-instruct-v1:0": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama3-2-90b-instruct-v1:0": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama3-3-70b-instruct-v1:0": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama4-maverick-17b-instruct-v1:0": {
      "input_mtok": 0.24,
      "output_mtok": 0.97,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.meta.llama4-scout-17b-instruct-v1:0": {
      "input_mtok": 0.17,
      "output_mtok": 0.66,
      "context_length": 4096,
      "source": "litellm"
    },
    "us.mistral.pixtral-large-2502-v1:0": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "v0/v0-1.0-md": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "v0/v0-1.5-lg": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 512000,
      "source": "litellm"
    },
    "v0/v0-1.5-md": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-14b": {
      "input_mtok": 0.08,
      "output_mtok": 0.24,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-235b": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-30b": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-32b": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen3-coder": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 66536,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/nova-lite": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/nova-micro": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/nova-pro": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/titan-embed-text-v2": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-haiku": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-opus": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
      "input_mtok": 0.8,
      "output_mtok": 4.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-4-opus": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-4-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-5-sonnet-20241022": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-7-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-haiku-4.5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.6": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-sonnet-4.5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/command-a": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/command-r": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/command-r-plus": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/embed-v4.0": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/deepseek/deepseek-r1": {
      "input_mtok": 0.55,
      "output_mtok": 2.19,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
      "input_mtok": 0.75,
      "output_mtok": 0.99,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/deepseek/deepseek-v3": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.0-flash": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.5-flash": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65536,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.5-pro": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 65536,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-embedding-001": {
      "input_mtok": 0.15,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemma-2-9b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/text-embedding-005": {
      "input_mtok": 0.025,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/text-multilingual-embedding-002": {
      "input_mtok": 0.025,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/inception/mercury-coder-small": {
      "input_mtok": 0.25,
      "output_mtok": 1.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3-70b": {
      "input_mtok": 0.59,
      "output_mtok": 0.79,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3-8b": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.1-70b": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.1-8b": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-11b": {
      "input_mtok": 0.16,
      "output_mtok": 0.16,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-1b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-3b": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-90b": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.3-70b": {
      "input_mtok": 0.72,
      "output_mtok": 0.72,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-4-maverick": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-4-scout": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 8192,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/codestral": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/codestral-embed": {
      "input_mtok": 0.15,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/devstral-small": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 128000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/magistral-medium": {
      "input_mtok": 2.0,
      "output_mtok": 5.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/magistral-small": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 64000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/ministral-3b": {
      "input_mtok": 0.04,
      "output_mtok": 0.04,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/ministral-8b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-embed": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-large": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-saba-24b": {
      "input_mtok": 0.79,
      "output_mtok": 0.79,
      "context_length": 32768,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-small": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mixtral-8x22b-instruct": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 2048,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/pixtral-12b": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/pixtral-large": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/moonshotai/kimi-k2": {
      "input_mtok": 0.55,
      "output_mtok": 2.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/morph/morph-v3-fast": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/morph/morph-v3-large": {
      "input_mtok": 0.9,
      "output_mtok": 1.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4-turbo": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4.1": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4.1-mini": {
      "input_mtok": 0.4,
      "output_mtok": 1.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4.1-nano": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4o": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4o-mini": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 16384,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o3": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 100000,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o3-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o4-mini": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 100000,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/text-embedding-3-large": {
      "input_mtok": 0.13,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/text-embedding-3-small": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/text-embedding-ada-002": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar-pro": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "vercel_ai_gateway/vercel/v0-1.0-md": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vercel_ai_gateway/vercel/v0-1.5-md": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-2": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 4000,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-2-vision": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3-fast": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3-mini": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3-mini-fast": {
      "input_mtok": 0.6,
      "output_mtok": 4.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "vercel_ai_gateway/zai/glm-4.5": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "vercel_ai_gateway/zai/glm-4.5-air": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "context_length": 96000,
      "source": "litellm"
    },
    "vercel_ai_gateway/zai/glm-4.6": {
      "input_mtok": 0.45,
      "output_mtok": 1.8,
      "context_length": 200000,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-haiku": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-haiku@20241022": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-haiku-4-5@20251001": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet-v2": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet-v2@20241022": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-7-sonnet@20250219": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/claude-3-haiku": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "vertex_ai/claude-3-haiku@20240307": {
      "input_mtok": 0.25,
      "output_mtok": 1.25,
      "context_length": 4096,
      "source": "litellm"
    },
    "vertex_ai/claude-3-opus": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vertex_ai/claude-3-opus@20240229": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vertex_ai/claude-3-sonnet": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vertex_ai/claude-3-sonnet@20240229": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-1@20250805": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-5@20251101": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-6": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4-5": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4-5@20250929": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4@20250514": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4@20250514": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "vertex_ai/mistralai/codestral-2@001": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/codestral-2": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/codestral-2@001": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/mistralai/codestral-2": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/codestral-2501": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/codestral@2405": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/codestral@latest": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
      "input_mtok": 1.35,
      "output_mtok": 5.4,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
      "input_mtok": 0.56,
      "output_mtok": 1.68,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-r1-0528-maas": {
      "input_mtok": 1.35,
      "output_mtok": 5.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "vertex_ai/gemini-2.5-flash-image": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/gemini-3-pro-image-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/deep-research-pro-preview-12-2025": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-large": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-large@001": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-mini": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-mini@001": {
      "input_mtok": 0.2,
      "output_mtok": 0.4,
      "context_length": 256000,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-3.1-405b-instruct-maas": {
      "input_mtok": 5.0,
      "output_mtok": 16.0,
      "context_length": 2048,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
      "input_mtok": 0.35,
      "output_mtok": 1.15,
      "context_length": 1000000,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
      "input_mtok": 0.35,
      "output_mtok": 1.15,
      "context_length": 1000000,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
      "input_mtok": 0.25,
      "output_mtok": 0.7,
      "context_length": 10000000,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
      "input_mtok": 0.25,
      "output_mtok": 0.7,
      "context_length": 10000000,
      "source": "litellm"
    },
    "vertex_ai/minimaxai/minimax-m2-maas": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 196608,
      "source": "litellm"
    },
    "vertex_ai/moonshotai/kimi-k2-thinking-maas": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 256000,
      "source": "litellm"
    },
    "vertex_ai/zai-org/glm-4.7-maas": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/zai-org/glm-5-maas": {
      "input_mtok": 1.0,
      "output_mtok": 3.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/mistral-medium-3": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistral-medium-3@001": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistralai/mistral-medium-3": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistralai/mistral-medium-3@001": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistral-large@2407": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistral-large@2411-001": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistral-large@latest": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/mistral-nemo@2407": {
      "input_mtok": 3.0,
      "output_mtok": 3.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/mistral-nemo@latest": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/mistral-small-2503": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "vertex_ai/mistral-small-2503@001": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 8191,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-ocr-maas": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": null,
      "source": "litellm"
    },
    "vertex_ai/openai/gpt-oss-120b-maas": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/openai/gpt-oss-20b-maas": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
      "input_mtok": 0.25,
      "output_mtok": 1.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
      "input_mtok": 1.0,
      "output_mtok": 4.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
      "input_mtok": 0.15,
      "output_mtok": 1.2,
      "context_length": 262144,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
      "input_mtok": 0.15,
      "output_mtok": 1.2,
      "context_length": 262144,
      "source": "litellm"
    },
    "voyage/rerank-2": {
      "input_mtok": 0.05,
      "output_mtok": 0.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "voyage/rerank-2-lite": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 8000,
      "source": "litellm"
    },
    "voyage/rerank-2.5": {
      "input_mtok": 0.05,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/rerank-2.5-lite": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-2": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 4000,
      "source": "litellm"
    },
    "voyage/voyage-3": {
      "input_mtok": 0.06,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-3-large": {
      "input_mtok": 0.18,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-3-lite": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-3.5": {
      "input_mtok": 0.06,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-3.5-lite": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-code-2": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "voyage/voyage-code-3": {
      "input_mtok": 0.18,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-context-3": {
      "input_mtok": 0.18,
      "output_mtok": 0.0,
      "context_length": 120000,
      "source": "litellm"
    },
    "voyage/voyage-finance-2": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "voyage/voyage-large-2": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "voyage/voyage-law-2": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "voyage/voyage-lite-01": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "voyage/voyage-lite-02-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 4000,
      "source": "litellm"
    },
    "voyage/voyage-multimodal-3": {
      "input_mtok": 0.12,
      "output_mtok": 0.0,
      "context_length": 32000,
      "source": "litellm"
    },
    "wandb/openai/gpt-oss-120b": {
      "input_mtok": 15000.0,
      "output_mtok": 60000.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "wandb/openai/gpt-oss-20b": {
      "input_mtok": 5000.0,
      "output_mtok": 20000.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "wandb/zai-org/GLM-4.5": {
      "input_mtok": 55000.0,
      "output_mtok": 200000.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "input_mtok": 10000.0,
      "output_mtok": 10000.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "input_mtok": 100000.0,
      "output_mtok": 150000.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "input_mtok": 10000.0,
      "output_mtok": 10000.0,
      "context_length": 262144,
      "source": "litellm"
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
      "input_mtok": 22000.0,
      "output_mtok": 22000.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "wandb/deepseek-ai/DeepSeek-V3.1": {
      "input_mtok": 55000.0,
      "output_mtok": 165000.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
      "input_mtok": 135000.0,
      "output_mtok": 540000.0,
      "context_length": 161000,
      "source": "litellm"
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
      "input_mtok": 114000.0,
      "output_mtok": 275000.0,
      "context_length": 161000,
      "source": "litellm"
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
      "input_mtok": 71000.0,
      "output_mtok": 71000.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_mtok": 17000.0,
      "output_mtok": 66000.0,
      "context_length": 64000,
      "source": "litellm"
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
      "input_mtok": 8000.0,
      "output_mtok": 35000.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/ibm/granite-3-8b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 1024,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-large": {
      "input_mtok": 3.0,
      "output_mtok": 10.0,
      "context_length": 16384,
      "source": "litellm"
    },
    "watsonx/bigscience/mt0-xxl-13b": {
      "input_mtok": 500.0,
      "output_mtok": 2000.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/core42/jais-13b-chat": {
      "input_mtok": 500.0,
      "output_mtok": 2000.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/google/flan-t5-xl-3b": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/ibm/granite-13b-chat-v2": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/ibm/granite-13b-instruct-v2": {
      "input_mtok": 0.6,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/ibm/granite-3-3-8b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/ibm/granite-4-h-small": {
      "input_mtok": 0.06,
      "output_mtok": 0.25,
      "context_length": 20480,
      "source": "litellm"
    },
    "watsonx/ibm/granite-guardian-3-2-2b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/ibm/granite-guardian-3-3-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/ibm/granite-ttm-1024-96-r2": {
      "input_mtok": 0.38,
      "output_mtok": 0.38,
      "context_length": 512,
      "source": "litellm"
    },
    "watsonx/ibm/granite-ttm-1536-96-r2": {
      "input_mtok": 0.38,
      "output_mtok": 0.38,
      "context_length": 512,
      "source": "litellm"
    },
    "watsonx/ibm/granite-ttm-512-96-r2": {
      "input_mtok": 0.38,
      "output_mtok": 0.38,
      "context_length": 512,
      "source": "litellm"
    },
    "watsonx/ibm/granite-vision-3-2-2b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-11b-vision-instruct": {
      "input_mtok": 0.35,
      "output_mtok": 0.35,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-1b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-3b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-90b-vision-instruct": {
      "input_mtok": 2.0,
      "output_mtok": 2.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-3-70b-instruct": {
      "input_mtok": 0.71,
      "output_mtok": 0.71,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-4-maverick-17b": {
      "input_mtok": 0.35,
      "output_mtok": 1.4,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-guard-3-11b-vision": {
      "input_mtok": 0.35,
      "output_mtok": 0.35,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-medium-2505": {
      "input_mtok": 3.0,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-small-2503": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32000,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32000,
      "source": "litellm"
    },
    "watsonx/mistralai/pixtral-12b-2409": {
      "input_mtok": 0.35,
      "output_mtok": 0.35,
      "context_length": 128000,
      "source": "litellm"
    },
    "watsonx/openai/gpt-oss-120b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 8192,
      "source": "litellm"
    },
    "watsonx/sdaia/allam-1-13b-instruct": {
      "input_mtok": 1.8,
      "output_mtok": 1.8,
      "context_length": 8192,
      "source": "litellm"
    },
    "xai/grok-2": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-2-1212": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-2-latest": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-2-vision": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "xai/grok-2-vision-1212": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "xai/grok-2-vision-latest": {
      "input_mtok": 2.0,
      "output_mtok": 10.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "xai/grok-3-beta": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-fast-beta": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-fast-latest": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-latest": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-mini-beta": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-mini-fast": {
      "input_mtok": 0.6,
      "output_mtok": 4.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-mini-fast-beta": {
      "input_mtok": 0.6,
      "output_mtok": 4.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-mini-fast-latest": {
      "input_mtok": 0.6,
      "output_mtok": 4.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-3-mini-latest": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-4-fast-non-reasoning": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000.0,
      "source": "litellm"
    },
    "xai/grok-4-0709": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "xai/grok-4-latest": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 256000,
      "source": "litellm"
    },
    "xai/grok-4-1-fast": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000.0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-reasoning": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000.0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-reasoning-latest": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000.0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-non-reasoning": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000.0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-non-reasoning-latest": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000.0,
      "source": "litellm"
    },
    "xai/grok-beta": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "source": "litellm"
    },
    "xai/grok-code-fast": {
      "input_mtok": 0.2,
      "output_mtok": 1.5,
      "context_length": 256000,
      "source": "litellm"
    },
    "xai/grok-code-fast-1-0825": {
      "input_mtok": 0.2,
      "output_mtok": 1.5,
      "context_length": 256000,
      "source": "litellm"
    },
    "xai/grok-vision-beta": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "zai.glm-4.7": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "zai/glm-4.7": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 200000,
      "source": "litellm"
    },
    "zai/glm-4.6": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 200000,
      "source": "litellm"
    },
    "zai/glm-4.5": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "zai/glm-4.5v": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "context_length": 128000,
      "source": "litellm"
    },
    "zai/glm-4.5-x": {
      "input_mtok": 2.2,
      "output_mtok": 8.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "zai/glm-4.5-air": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "context_length": 128000,
      "source": "litellm"
    },
    "zai/glm-4.5-airx": {
      "input_mtok": 1.1,
      "output_mtok": 4.5,
      "context_length": 128000,
      "source": "litellm"
    },
    "zai/glm-4-32b-0414-128k": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
      "input_mtok": 0.45,
      "output_mtok": 1.8,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-kontext-pro": {
      "input_mtok": 0.04,
      "output_mtok": 0.04,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/SSD-1B": {
      "input_mtok": 0.0001,
      "output_mtok": 0.0001,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/chronos-hermes-13b-v2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-python": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-python": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-python": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-python": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-qwen-1p5-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 65536,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-2b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-kontext-max": {
      "input_mtok": 0.08,
      "output_mtok": 0.08,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dbrx-instruct": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-1b-base": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-33b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base-v1p5": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 163840,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2p5": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/devstral-small-2505": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-21b-a3b-pt": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-300b-a47b-pt": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/fare-20b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v1": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firellava-13b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firesearch-ocr-v6": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-controlnet-union": {
      "input_mtok": 0.001,
      "output_mtok": 0.001,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-fp8": {
      "input_mtok": 0.0005,
      "output_mtok": 0.0005,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell-fp8": {
      "input_mtok": 0.0003,
      "output_mtok": 0.0003,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-2b-it": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b-it": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma2-9b-it": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5v": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/hermes-2-pro-mistral-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-38b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-78b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/japanese-stable-diffusion-xl": {
      "input_mtok": 0.0001,
      "output_mtok": 0.0001,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kat-coder": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-2-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b-chat": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b-chat": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 2048,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b-chat": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct-hf": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b-instruct-hf": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct-long": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct-1b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llamaguard-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llava-yi-34b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m1-80k": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m2": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 256000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 256000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 256000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-4k": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v0p2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v3": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-v0p2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 256000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-small-24b-instruct-2501": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 65536,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 65536,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mythomax-l2-13b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nemotron-nano-v2-12b-vl": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-capybara-7b-v1p9": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-yi-34b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-13b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-70b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openchat-3p5-0106-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2-mistral-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2p5-mistral-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openorca-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phi-2-3b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 2048,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-vision-128k-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32064,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-python-v1": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v1": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v2": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/playground-v2-1024px-aesthetic": {
      "input_mtok": 0.0001,
      "output_mtok": 0.0001,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/playground-v2-5-1024px-aesthetic": {
      "input_mtok": 0.0001,
      "output_mtok": 0.0001,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/pythia-12b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 2048,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-qwq-32b-preview": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-14b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen1p5-72b-chat": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-2b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-72b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-0p5b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-14b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-1p5b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 65536,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-math-72b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-0p6b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 40960,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-14b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 40960,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 40960,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
      "input_mtok": 0.5,
      "output_mtok": 0.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 40960,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 40960,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/": {
      "input_mtok": 0.1,
      "output_mtok": 0.0,
      "context_length": 40960,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-thinking": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
      "input_mtok": 0.22,
      "output_mtok": 0.88,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 262144,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-32b-instruct": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-8b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwq-32b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 131072,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/rolm-ocr": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/stable-diffusion-xl-1024-v1-0": {
      "input_mtok": 0.0001,
      "output_mtok": 0.0001,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/stablecode-3b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-16b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-15b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-3b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/toppy-m-7b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 200000,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-chat": {
      "input_mtok": 0.9,
      "output_mtok": 0.9,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-6b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 4096,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/zephyr-7b-beta": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.2": {
      "input_mtok": 0.269,
      "output_mtok": 0.4,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/minimax/minimax-m2.1": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.7": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/xiaomimimo/mimo-v2-flash": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32000,
      "source": "litellm"
    },
    "novita/zai-org/autoglm-phone-9b-multilingual": {
      "input_mtok": 0.035,
      "output_mtok": 0.138,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/moonshotai/kimi-k2-thinking": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "novita/minimax/minimax-m2": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/paddlepaddle/paddleocr-vl": {
      "input_mtok": 0.02,
      "output_mtok": 0.02,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.2-exp": {
      "input_mtok": 0.27,
      "output_mtok": 0.41,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-235b-a22b-thinking": {
      "input_mtok": 0.98,
      "output_mtok": 3.95,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.6v": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.6": {
      "input_mtok": 0.55,
      "output_mtok": 2.2,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/kwaipilot/kat-coder-pro": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 128000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-next-80b-a3b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 1.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-next-80b-a3b-thinking": {
      "input_mtok": 0.15,
      "output_mtok": 1.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-ocr": {
      "input_mtok": 0.03,
      "output_mtok": 0.03,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.1-terminus": {
      "input_mtok": 0.27,
      "output_mtok": 1.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-235b-a22b-instruct": {
      "input_mtok": 0.3,
      "output_mtok": 1.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-max": {
      "input_mtok": 2.11,
      "output_mtok": 8.45,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/skywork/r1v4-lite": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.1": {
      "input_mtok": 0.27,
      "output_mtok": 1.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/moonshotai/kimi-k2-0905": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "source": "litellm"
    },
    "novita/qwen/qwen3-coder-480b-a35b-instruct": {
      "input_mtok": 0.3,
      "output_mtok": 1.3,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/qwen/qwen3-coder-30b-a3b-instruct": {
      "input_mtok": 0.07,
      "output_mtok": 0.27,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/openai/gpt-oss-120b": {
      "input_mtok": 0.05,
      "output_mtok": 0.25,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/moonshotai/kimi-k2-instruct": {
      "input_mtok": 0.57,
      "output_mtok": 2.3,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3-0324": {
      "input_mtok": 0.27,
      "output_mtok": 1.12,
      "context_length": 163840,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.5": {
      "input_mtok": 0.6,
      "output_mtok": 2.2,
      "context_length": 98304,
      "source": "litellm"
    },
    "novita/qwen/qwen3-235b-a22b-thinking-2507": {
      "input_mtok": 0.3,
      "output_mtok": 3.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3.1-8b-instruct": {
      "input_mtok": 0.02,
      "output_mtok": 0.05,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/google/gemma-3-12b-it": {
      "input_mtok": 0.05,
      "output_mtok": 0.1,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.5v": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/openai/gpt-oss-20b": {
      "input_mtok": 0.04,
      "output_mtok": 0.15,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-235b-a22b-instruct-2507": {
      "input_mtok": 0.09,
      "output_mtok": 0.58,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-distill-qwen-14b": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3.3-70b-instruct": {
      "input_mtok": 0.135,
      "output_mtok": 0.4,
      "context_length": 120000,
      "source": "litellm"
    },
    "novita/qwen/qwen-2.5-72b-instruct": {
      "input_mtok": 0.38,
      "output_mtok": 0.4,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/mistralai/mistral-nemo": {
      "input_mtok": 0.04,
      "output_mtok": 0.17,
      "context_length": 16000,
      "source": "litellm"
    },
    "novita/minimaxai/minimax-m1-80k": {
      "input_mtok": 0.55,
      "output_mtok": 2.2,
      "context_length": 40000,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-0528": {
      "input_mtok": 0.7,
      "output_mtok": 2.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-distill-qwen-32b": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 32000,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3-8b-instruct": {
      "input_mtok": 0.04,
      "output_mtok": 0.04,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/microsoft/wizardlm-2-8x22b": {
      "input_mtok": 0.62,
      "output_mtok": 0.62,
      "context_length": 8000,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-0528-qwen3-8b": {
      "input_mtok": 0.06,
      "output_mtok": 0.09,
      "context_length": 32000,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-distill-llama-70b": {
      "input_mtok": 0.8,
      "output_mtok": 0.8,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3-70b-instruct": {
      "input_mtok": 0.51,
      "output_mtok": 0.74,
      "context_length": 8000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-235b-a22b-fp8": {
      "input_mtok": 0.2,
      "output_mtok": 0.8,
      "context_length": 20000,
      "source": "litellm"
    },
    "novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8": {
      "input_mtok": 0.27,
      "output_mtok": 0.85,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/meta-llama/llama-4-scout-17b-16e-instruct": {
      "input_mtok": 0.18,
      "output_mtok": 0.59,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/nousresearch/hermes-2-pro-llama-3-8b": {
      "input_mtok": 0.14,
      "output_mtok": 0.14,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/qwen/qwen2.5-vl-72b-instruct": {
      "input_mtok": 0.8,
      "output_mtok": 0.8,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/sao10k/l3-70b-euryale-v2.1": {
      "input_mtok": 1.48,
      "output_mtok": 1.48,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-21B-a3b-thinking": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/sao10k/l3-8b-lunaris": {
      "input_mtok": 0.05,
      "output_mtok": 0.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/baichuan/baichuan-m2-32b": {
      "input_mtok": 0.07,
      "output_mtok": 0.07,
      "context_length": 131072,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-vl-424b-a47b": {
      "input_mtok": 0.42,
      "output_mtok": 1.25,
      "context_length": 16000,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-300b-a47b-paddle": {
      "input_mtok": 0.28,
      "output_mtok": 1.1,
      "context_length": 12000,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-prover-v2-671b": {
      "input_mtok": 0.7,
      "output_mtok": 2.5,
      "context_length": 160000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-32b-fp8": {
      "input_mtok": 0.1,
      "output_mtok": 0.45,
      "context_length": 20000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-30b-a3b-fp8": {
      "input_mtok": 0.09,
      "output_mtok": 0.45,
      "context_length": 20000,
      "source": "litellm"
    },
    "novita/google/gemma-3-27b-it": {
      "input_mtok": 0.119,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3-turbo": {
      "input_mtok": 0.4,
      "output_mtok": 1.3,
      "context_length": 16000,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-turbo": {
      "input_mtok": 0.7,
      "output_mtok": 2.5,
      "context_length": 16000,
      "source": "litellm"
    },
    "novita/Sao10K/L3-8B-Stheno-v3.2": {
      "input_mtok": 0.05,
      "output_mtok": 0.05,
      "context_length": 32000,
      "source": "litellm"
    },
    "novita/gryphe/mythomax-l2-13b": {
      "input_mtok": 0.09,
      "output_mtok": 0.09,
      "context_length": 3200,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-vl-28b-a3b-thinking": {
      "input_mtok": 0.39,
      "output_mtok": 0.39,
      "context_length": 65536,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-8b-instruct": {
      "input_mtok": 0.08,
      "output_mtok": 0.5,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.5-air": {
      "input_mtok": 0.13,
      "output_mtok": 0.85,
      "context_length": 98304,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-30b-a3b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.7,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-30b-a3b-thinking": {
      "input_mtok": 0.2,
      "output_mtok": 1.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-omni-30b-a3b-thinking": {
      "input_mtok": 0.25,
      "output_mtok": 0.97,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/qwen/qwen3-omni-30b-a3b-instruct": {
      "input_mtok": 0.25,
      "output_mtok": 0.97,
      "context_length": 16384,
      "source": "litellm"
    },
    "novita/qwen/qwen-mt-plus": {
      "input_mtok": 0.25,
      "output_mtok": 0.75,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-vl-28b-a3b": {
      "input_mtok": 0.14,
      "output_mtok": 0.56,
      "context_length": 8000,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-21B-a3b": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 8000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-8b-fp8": {
      "input_mtok": 0.035,
      "output_mtok": 0.138,
      "context_length": 20000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-4b-fp8": {
      "input_mtok": 0.03,
      "output_mtok": 0.03,
      "context_length": 20000,
      "source": "litellm"
    },
    "novita/qwen/qwen2.5-7b-instruct": {
      "input_mtok": 0.07,
      "output_mtok": 0.07,
      "context_length": 32000,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3.2-3b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.05,
      "context_length": 32000,
      "source": "litellm"
    },
    "novita/sao10k/l31-70b-euryale-v2.2": {
      "input_mtok": 1.48,
      "output_mtok": 1.48,
      "context_length": 8192,
      "source": "litellm"
    },
    "novita/qwen/qwen3-embedding-0.6b": {
      "input_mtok": 0.07,
      "output_mtok": 0.0,
      "context_length": 32768,
      "source": "litellm"
    },
    "novita/qwen/qwen3-embedding-8b": {
      "input_mtok": 0.07,
      "output_mtok": 0.0,
      "context_length": 4096,
      "source": "litellm"
    },
    "novita/baai/bge-m3": {
      "input_mtok": 0.01,
      "output_mtok": 0.01,
      "context_length": 96000,
      "source": "litellm"
    },
    "novita/qwen/qwen3-reranker-8b": {
      "input_mtok": 0.05,
      "output_mtok": 0.05,
      "context_length": 4096,
      "source": "litellm"
    },
    "novita/baai/bge-reranker-v2-m3": {
      "input_mtok": 0.01,
      "output_mtok": 0.01,
      "context_length": 8000,
      "source": "litellm"
    },
    "llamagate/llama-3.1-8b": {
      "input_mtok": 0.03,
      "output_mtok": 0.05,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/llama-3.2-3b": {
      "input_mtok": 0.04,
      "output_mtok": 0.08,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/mistral-7b-v0.3": {
      "input_mtok": 0.1,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/qwen3-8b": {
      "input_mtok": 0.04,
      "output_mtok": 0.14,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/dolphin3-8b": {
      "input_mtok": 0.08,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/deepseek-r1-8b": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 16384,
      "source": "litellm"
    },
    "llamagate/deepseek-r1-7b-qwen": {
      "input_mtok": 0.08,
      "output_mtok": 0.15,
      "context_length": 16384,
      "source": "litellm"
    },
    "llamagate/openthinker-7b": {
      "input_mtok": 0.08,
      "output_mtok": 0.15,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/qwen2.5-coder-7b": {
      "input_mtok": 0.06,
      "output_mtok": 0.12,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/deepseek-coder-6.7b": {
      "input_mtok": 0.06,
      "output_mtok": 0.12,
      "context_length": 4096,
      "source": "litellm"
    },
    "llamagate/codellama-7b": {
      "input_mtok": 0.06,
      "output_mtok": 0.12,
      "context_length": 4096,
      "source": "litellm"
    },
    "llamagate/qwen3-vl-8b": {
      "input_mtok": 0.15,
      "output_mtok": 0.55,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/llava-7b": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 2048,
      "source": "litellm"
    },
    "llamagate/gemma3-4b": {
      "input_mtok": 0.03,
      "output_mtok": 0.08,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/nomic-embed-text": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 8192,
      "source": "litellm"
    },
    "llamagate/qwen3-embedding-8b": {
      "input_mtok": 0.02,
      "output_mtok": 0.0,
      "context_length": 40960,
      "source": "litellm"
    },
    "gpt-4o-mini-tts-2025-03-20": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-4o-mini-tts-2025-12-15": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": null,
      "source": "litellm"
    },
    "gpt-4o-mini-transcribe-2025-03-20": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "gpt-4o-mini-transcribe-2025-12-15": {
      "input_mtok": 1.25,
      "output_mtok": 5.0,
      "context_length": 16000,
      "source": "litellm"
    },
    "gpt-5-search-api": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-5-search-api-2025-10-14": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "source": "litellm"
    },
    "gpt-realtime-mini-2025-10-06": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "gpt-realtime-mini-2025-12-15": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 4096,
      "source": "litellm"
    },
    "chatgpt-image-latest": {
      "input_mtok": 5.0,
      "output_mtok": 0.0,
      "context_length": null,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-lite-001": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 1048576,
      "source": "litellm"
    },
    "gemini-2.5-flash-native-audio-latest": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.5-flash-native-audio-preview-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.5-flash-native-audio-preview-12-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-native-audio-latest": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-native-audio-preview-09-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-native-audio-preview-12-2025": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 8192,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-tts": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": null,
      "source": "litellm"
    },
    "gemini-flash-latest": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-flash-lite-latest": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-pro-latest": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini/gemini-pro-latest": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 65535,
      "source": "litellm"
    },
    "gemini-exp-1206": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 65535,
      "source": "litellm"
    },
    "minimax/minimax-m2.5": {
      "input_mtok": 0.2,
      "output_mtok": 1.0,
      "context_length": 196608,
      "name": "MiniMax: MiniMax M2.5",
      "source": "openrouter"
    },
    "z-ai/glm-5": {
      "input_mtok": 0.75,
      "output_mtok": 2.55,
      "context_length": 204800,
      "name": "Z.ai: GLM 5",
      "source": "openrouter"
    },
    "qwen/qwen3-max-thinking": {
      "input_mtok": 1.2,
      "output_mtok": 6.0,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Max Thinking",
      "source": "openrouter"
    },
    "openrouter/aurora-alpha": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 128000,
      "name": "Aurora Alpha",
      "source": "openrouter"
    },
    "anthropic/claude-opus-4.6": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 1000000,
      "name": "Anthropic: Claude Opus 4.6",
      "source": "openrouter"
    },
    "qwen/qwen3-coder-next": {
      "input_mtok": 0.07,
      "output_mtok": 0.3,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Coder Next",
      "source": "openrouter"
    },
    "openrouter/free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 200000,
      "name": "Free Models Router",
      "source": "openrouter"
    },
    "stepfun/step-3.5-flash:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 256000,
      "name": "StepFun: Step 3.5 Flash (free)",
      "source": "openrouter"
    },
    "stepfun/step-3.5-flash": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 256000,
      "name": "StepFun: Step 3.5 Flash",
      "source": "openrouter"
    },
    "arcee-ai/trinity-large-preview:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131000,
      "name": "Arcee AI: Trinity Large Preview (free)",
      "source": "openrouter"
    },
    "moonshotai/kimi-k2.5": {
      "input_mtok": 0.45,
      "output_mtok": 2.2,
      "context_length": 262144,
      "name": "MoonshotAI: Kimi K2.5",
      "source": "openrouter"
    },
    "upstage/solar-pro-3:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 128000,
      "name": "Upstage: Solar Pro 3 (free)",
      "source": "openrouter"
    },
    "minimax/minimax-m2-her": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 65536,
      "name": "MiniMax: MiniMax M2-her",
      "source": "openrouter"
    },
    "writer/palmyra-x5": {
      "input_mtok": 0.6,
      "output_mtok": 6.0,
      "context_length": 1040000,
      "name": "Writer: Palmyra X5",
      "source": "openrouter"
    },
    "liquid/lfm-2.5-1.2b-thinking:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 32768,
      "name": "LiquidAI: LFM2.5-1.2B-Thinking (free)",
      "source": "openrouter"
    },
    "liquid/lfm-2.5-1.2b-instruct:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 32768,
      "name": "LiquidAI: LFM2.5-1.2B-Instruct (free)",
      "source": "openrouter"
    },
    "openai/gpt-audio": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT Audio",
      "source": "openrouter"
    },
    "openai/gpt-audio-mini": {
      "input_mtok": 0.6,
      "output_mtok": 2.4,
      "context_length": 128000,
      "name": "OpenAI: GPT Audio Mini",
      "source": "openrouter"
    },
    "z-ai/glm-4.7-flash": {
      "input_mtok": 0.06,
      "output_mtok": 0.4,
      "context_length": 202752,
      "name": "Z.ai: GLM 4.7 Flash",
      "source": "openrouter"
    },
    "openai/gpt-5.2-codex": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 400000,
      "name": "OpenAI: GPT-5.2-Codex",
      "source": "openrouter"
    },
    "allenai/molmo-2-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 36864,
      "name": "AllenAI: Molmo2 8B",
      "source": "openrouter"
    },
    "allenai/olmo-3.1-32b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 65536,
      "name": "AllenAI: Olmo 3.1 32B Instruct",
      "source": "openrouter"
    },
    "bytedance-seed/seed-1.6-flash": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 262144,
      "name": "ByteDance Seed: Seed 1.6 Flash",
      "source": "openrouter"
    },
    "bytedance-seed/seed-1.6": {
      "input_mtok": 0.25,
      "output_mtok": 2.0,
      "context_length": 262144,
      "name": "ByteDance Seed: Seed 1.6",
      "source": "openrouter"
    },
    "minimax/minimax-m2.1": {
      "input_mtok": 0.27,
      "output_mtok": 0.95,
      "context_length": 196608,
      "name": "MiniMax: MiniMax M2.1",
      "source": "openrouter"
    },
    "z-ai/glm-4.7": {
      "input_mtok": 0.4,
      "output_mtok": 1.5,
      "context_length": 202752,
      "name": "Z.ai: GLM 4.7",
      "source": "openrouter"
    },
    "mistralai/mistral-small-creative": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32768,
      "name": "Mistral: Mistral Small Creative",
      "source": "openrouter"
    },
    "allenai/olmo-3.1-32b-think": {
      "input_mtok": 0.15,
      "output_mtok": 0.5,
      "context_length": 65536,
      "name": "AllenAI: Olmo 3.1 32B Think",
      "source": "openrouter"
    },
    "xiaomi/mimo-v2-flash": {
      "input_mtok": 0.09,
      "output_mtok": 0.29,
      "context_length": 262144,
      "name": "Xiaomi: MiMo-V2-Flash",
      "source": "openrouter"
    },
    "nvidia/nemotron-3-nano-30b-a3b:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 256000,
      "name": "NVIDIA: Nemotron 3 Nano 30B A3B (free)",
      "source": "openrouter"
    },
    "nvidia/nemotron-3-nano-30b-a3b": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 262144,
      "name": "NVIDIA: Nemotron 3 Nano 30B A3B",
      "source": "openrouter"
    },
    "openai/gpt-5.2-chat": {
      "input_mtok": 1.75,
      "output_mtok": 14.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-5.2 Chat",
      "source": "openrouter"
    },
    "mistralai/devstral-2512": {
      "input_mtok": 0.05,
      "output_mtok": 0.22,
      "context_length": 262144,
      "name": "Mistral: Devstral 2 2512",
      "source": "openrouter"
    },
    "relace/relace-search": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 256000,
      "name": "Relace: Relace Search",
      "source": "openrouter"
    },
    "z-ai/glm-4.6v": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 131072,
      "name": "Z.ai: GLM 4.6V",
      "source": "openrouter"
    },
    "nex-agi/deepseek-v3.1-nex-n1": {
      "input_mtok": 0.27,
      "output_mtok": 1.0,
      "context_length": 131072,
      "name": "Nex AGI: DeepSeek V3.1 Nex N1",
      "source": "openrouter"
    },
    "essentialai/rnj-1-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 32768,
      "name": "EssentialAI: Rnj 1 Instruct",
      "source": "openrouter"
    },
    "openrouter/bodybuilder": {
      "input_mtok": -1000000.0,
      "output_mtok": -1000000.0,
      "context_length": 128000,
      "name": "Body Builder (beta)",
      "source": "openrouter"
    },
    "openai/gpt-5.1-codex-max": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 400000,
      "name": "OpenAI: GPT-5.1-Codex-Max",
      "source": "openrouter"
    },
    "amazon/nova-2-lite-v1": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 1000000,
      "name": "Amazon: Nova 2 Lite",
      "source": "openrouter"
    },
    "mistralai/ministral-14b-2512": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 262144,
      "name": "Mistral: Ministral 3 14B 2512",
      "source": "openrouter"
    },
    "mistralai/ministral-8b-2512": {
      "input_mtok": 0.15,
      "output_mtok": 0.15,
      "context_length": 262144,
      "name": "Mistral: Ministral 3 8B 2512",
      "source": "openrouter"
    },
    "mistralai/ministral-3b-2512": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 131072,
      "name": "Mistral: Ministral 3 3B 2512",
      "source": "openrouter"
    },
    "mistralai/mistral-large-2512": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 262144,
      "name": "Mistral: Mistral Large 3 2512",
      "source": "openrouter"
    },
    "arcee-ai/trinity-mini:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Arcee AI: Trinity Mini (free)",
      "source": "openrouter"
    },
    "arcee-ai/trinity-mini": {
      "input_mtok": 0.045,
      "output_mtok": 0.15,
      "context_length": 131072,
      "name": "Arcee AI: Trinity Mini",
      "source": "openrouter"
    },
    "deepseek/deepseek-v3.2-speciale": {
      "input_mtok": 0.27,
      "output_mtok": 0.41,
      "context_length": 163840,
      "name": "DeepSeek: DeepSeek V3.2 Speciale",
      "source": "openrouter"
    },
    "prime-intellect/intellect-3": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "context_length": 131072,
      "name": "Prime Intellect: INTELLECT-3",
      "source": "openrouter"
    },
    "tngtech/tng-r1t-chimera": {
      "input_mtok": 0.25,
      "output_mtok": 0.85,
      "context_length": 163840,
      "name": "TNG: R1T Chimera",
      "source": "openrouter"
    },
    "anthropic/claude-opus-4.5": {
      "input_mtok": 5.0,
      "output_mtok": 25.0,
      "context_length": 200000,
      "name": "Anthropic: Claude Opus 4.5",
      "source": "openrouter"
    },
    "allenai/olmo-3-32b-think": {
      "input_mtok": 0.15,
      "output_mtok": 0.5,
      "context_length": 65536,
      "name": "AllenAI: Olmo 3 32B Think",
      "source": "openrouter"
    },
    "allenai/olmo-3-7b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 65536,
      "name": "AllenAI: Olmo 3 7B Instruct",
      "source": "openrouter"
    },
    "allenai/olmo-3-7b-think": {
      "input_mtok": 0.12,
      "output_mtok": 0.2,
      "context_length": 65536,
      "name": "AllenAI: Olmo 3 7B Think",
      "source": "openrouter"
    },
    "google/gemini-3-pro-image-preview": {
      "input_mtok": 2.0,
      "output_mtok": 12.0,
      "context_length": 65536,
      "name": "Google: Nano Banana Pro (Gemini 3 Pro Image Preview)",
      "source": "openrouter"
    },
    "x-ai/grok-4.1-fast": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000,
      "name": "xAI: Grok 4.1 Fast",
      "source": "openrouter"
    },
    "deepcogito/cogito-v2.1-671b": {
      "input_mtok": 1.25,
      "output_mtok": 1.25,
      "context_length": 128000,
      "name": "Deep Cogito: Cogito v2.1 671B",
      "source": "openrouter"
    },
    "openai/gpt-5.1-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-5.1 Chat",
      "source": "openrouter"
    },
    "kwaipilot/kat-coder-pro": {
      "input_mtok": 0.207,
      "output_mtok": 0.828,
      "context_length": 256000,
      "name": "Kwaipilot: KAT-Coder-Pro V1",
      "source": "openrouter"
    },
    "moonshotai/kimi-k2-thinking": {
      "input_mtok": 0.4,
      "output_mtok": 1.75,
      "context_length": 262144,
      "name": "MoonshotAI: Kimi K2 Thinking",
      "source": "openrouter"
    },
    "amazon/nova-premier-v1": {
      "input_mtok": 2.5,
      "output_mtok": 12.5,
      "context_length": 1000000,
      "name": "Amazon: Nova Premier 1.0",
      "source": "openrouter"
    },
    "perplexity/sonar-pro-search": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 200000,
      "name": "Perplexity: Sonar Pro Search",
      "source": "openrouter"
    },
    "mistralai/voxtral-small-24b-2507": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 32000,
      "name": "Mistral: Voxtral Small 24B 2507",
      "source": "openrouter"
    },
    "openai/gpt-oss-safeguard-20b": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 131072,
      "name": "OpenAI: gpt-oss-safeguard-20b",
      "source": "openrouter"
    },
    "nvidia/nemotron-nano-12b-v2-vl:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 128000,
      "name": "NVIDIA: Nemotron Nano 12B 2 VL (free)",
      "source": "openrouter"
    },
    "nvidia/nemotron-nano-12b-v2-vl": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 131072,
      "name": "NVIDIA: Nemotron Nano 12B 2 VL",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-32b-instruct": {
      "input_mtok": 0.104,
      "output_mtok": 0.416,
      "context_length": 131072,
      "name": "Qwen: Qwen3 VL 32B Instruct",
      "source": "openrouter"
    },
    "liquid/lfm2-8b-a1b": {
      "input_mtok": 0.01,
      "output_mtok": 0.02,
      "context_length": 32768,
      "name": "LiquidAI: LFM2-8B-A1B",
      "source": "openrouter"
    },
    "liquid/lfm-2.2-6b": {
      "input_mtok": 0.01,
      "output_mtok": 0.02,
      "context_length": 32768,
      "name": "LiquidAI: LFM2-2.6B",
      "source": "openrouter"
    },
    "ibm-granite/granite-4.0-h-micro": {
      "input_mtok": 0.017,
      "output_mtok": 0.11,
      "context_length": 131000,
      "name": "IBM: Granite 4.0 Micro",
      "source": "openrouter"
    },
    "openai/gpt-5-image-mini": {
      "input_mtok": 2.5,
      "output_mtok": 2.0,
      "context_length": 400000,
      "name": "OpenAI: GPT-5 Image Mini",
      "source": "openrouter"
    },
    "anthropic/claude-haiku-4.5": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 200000,
      "name": "Anthropic: Claude Haiku 4.5",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-8b-thinking": {
      "input_mtok": 0.117,
      "output_mtok": 1.365,
      "context_length": 131072,
      "name": "Qwen: Qwen3 VL 8B Thinking",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-8b-instruct": {
      "input_mtok": 0.08,
      "output_mtok": 0.5,
      "context_length": 131072,
      "name": "Qwen: Qwen3 VL 8B Instruct",
      "source": "openrouter"
    },
    "openai/gpt-5-image": {
      "input_mtok": 10.0,
      "output_mtok": 10.0,
      "context_length": 400000,
      "name": "OpenAI: GPT-5 Image",
      "source": "openrouter"
    },
    "nvidia/llama-3.3-nemotron-super-49b-v1.5": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 131072,
      "name": "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
      "source": "openrouter"
    },
    "baidu/ernie-4.5-21b-a3b-thinking": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 131072,
      "name": "Baidu: ERNIE 4.5 21B A3B Thinking",
      "source": "openrouter"
    },
    "google/gemini-2.5-flash-image": {
      "input_mtok": 0.3,
      "output_mtok": 2.5,
      "context_length": 32768,
      "name": "Google: Gemini 2.5 Flash Image (Nano Banana)",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-30b-a3b-thinking": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Qwen: Qwen3 VL 30B A3B Thinking",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-30b-a3b-instruct": {
      "input_mtok": 0.13,
      "output_mtok": 0.52,
      "context_length": 131072,
      "name": "Qwen: Qwen3 VL 30B A3B Instruct",
      "source": "openrouter"
    },
    "z-ai/glm-4.6": {
      "input_mtok": 0.35,
      "output_mtok": 1.5,
      "context_length": 202752,
      "name": "Z.ai: GLM 4.6",
      "source": "openrouter"
    },
    "z-ai/glm-4.6:exacto": {
      "input_mtok": 0.44,
      "output_mtok": 1.76,
      "context_length": 204800,
      "name": "Z.ai: GLM 4.6 (exacto)",
      "source": "openrouter"
    },
    "deepseek/deepseek-v3.2-exp": {
      "input_mtok": 0.27,
      "output_mtok": 0.41,
      "context_length": 163840,
      "name": "DeepSeek: DeepSeek V3.2 Exp",
      "source": "openrouter"
    },
    "thedrummer/cydonia-24b-v4.1": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "name": "TheDrummer: Cydonia 24B V4.1",
      "source": "openrouter"
    },
    "relace/relace-apply-3": {
      "input_mtok": 0.85,
      "output_mtok": 1.25,
      "context_length": 256000,
      "name": "Relace: Relace Apply 3",
      "source": "openrouter"
    },
    "google/gemini-2.5-flash-lite-preview-09-2025": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 1048576,
      "name": "Google: Gemini 2.5 Flash Lite Preview 09-2025",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-235b-a22b-thinking": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Qwen: Qwen3 VL 235B A22B Thinking",
      "source": "openrouter"
    },
    "qwen/qwen3-vl-235b-a22b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.88,
      "context_length": 262144,
      "name": "Qwen: Qwen3 VL 235B A22B Instruct",
      "source": "openrouter"
    },
    "qwen/qwen3-max": {
      "input_mtok": 1.2,
      "output_mtok": 6.0,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Max",
      "source": "openrouter"
    },
    "qwen/qwen3-coder-plus": {
      "input_mtok": 1.0,
      "output_mtok": 5.0,
      "context_length": 1000000,
      "name": "Qwen: Qwen3 Coder Plus",
      "source": "openrouter"
    },
    "openai/gpt-5-codex": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 400000,
      "name": "OpenAI: GPT-5 Codex",
      "source": "openrouter"
    },
    "deepseek/deepseek-v3.1-terminus:exacto": {
      "input_mtok": 0.21,
      "output_mtok": 0.79,
      "context_length": 163840,
      "name": "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
      "source": "openrouter"
    },
    "deepseek/deepseek-v3.1-terminus": {
      "input_mtok": 0.21,
      "output_mtok": 0.79,
      "context_length": 163840,
      "name": "DeepSeek: DeepSeek V3.1 Terminus",
      "source": "openrouter"
    },
    "x-ai/grok-4-fast": {
      "input_mtok": 0.2,
      "output_mtok": 0.5,
      "context_length": 2000000,
      "name": "xAI: Grok 4 Fast",
      "source": "openrouter"
    },
    "alibaba/tongyi-deepresearch-30b-a3b": {
      "input_mtok": 0.09,
      "output_mtok": 0.45,
      "context_length": 131072,
      "name": "Tongyi DeepResearch 30B A3B",
      "source": "openrouter"
    },
    "qwen/qwen3-coder-flash": {
      "input_mtok": 0.3,
      "output_mtok": 1.5,
      "context_length": 1000000,
      "name": "Qwen: Qwen3 Coder Flash",
      "source": "openrouter"
    },
    "opengvlab/internvl3-78b": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 32768,
      "name": "OpenGVLab: InternVL3 78B",
      "source": "openrouter"
    },
    "qwen/qwen3-next-80b-a3b-thinking": {
      "input_mtok": 0.15,
      "output_mtok": 1.2,
      "context_length": 128000,
      "name": "Qwen: Qwen3 Next 80B A3B Thinking",
      "source": "openrouter"
    },
    "qwen/qwen3-next-80b-a3b-instruct:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Next 80B A3B Instruct (free)",
      "source": "openrouter"
    },
    "qwen/qwen3-next-80b-a3b-instruct": {
      "input_mtok": 0.09,
      "output_mtok": 1.1,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Next 80B A3B Instruct",
      "source": "openrouter"
    },
    "meituan/longcat-flash-chat": {
      "input_mtok": 0.2,
      "output_mtok": 0.8,
      "context_length": 131072,
      "name": "Meituan: LongCat Flash Chat",
      "source": "openrouter"
    },
    "qwen/qwen-plus-2025-07-28": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 1000000,
      "name": "Qwen: Qwen Plus 0728",
      "source": "openrouter"
    },
    "qwen/qwen-plus-2025-07-28:thinking": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 1000000,
      "name": "Qwen: Qwen Plus 0728 (thinking)",
      "source": "openrouter"
    },
    "nvidia/nemotron-nano-9b-v2:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 128000,
      "name": "NVIDIA: Nemotron Nano 9B V2 (free)",
      "source": "openrouter"
    },
    "nvidia/nemotron-nano-9b-v2": {
      "input_mtok": 0.04,
      "output_mtok": 0.16,
      "context_length": 131072,
      "name": "NVIDIA: Nemotron Nano 9B V2",
      "source": "openrouter"
    },
    "moonshotai/kimi-k2-0905": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 131072,
      "name": "MoonshotAI: Kimi K2 0905",
      "source": "openrouter"
    },
    "moonshotai/kimi-k2-0905:exacto": {
      "input_mtok": 0.6,
      "output_mtok": 2.5,
      "context_length": 262144,
      "name": "MoonshotAI: Kimi K2 0905 (exacto)",
      "source": "openrouter"
    },
    "qwen/qwen3-30b-a3b-thinking-2507": {
      "input_mtok": 0.051,
      "output_mtok": 0.34,
      "context_length": 32768,
      "name": "Qwen: Qwen3 30B A3B Thinking 2507",
      "source": "openrouter"
    },
    "x-ai/grok-code-fast-1": {
      "input_mtok": 0.2,
      "output_mtok": 1.5,
      "context_length": 256000,
      "name": "xAI: Grok Code Fast 1",
      "source": "openrouter"
    },
    "nousresearch/hermes-4-70b": {
      "input_mtok": 0.11,
      "output_mtok": 0.38,
      "context_length": 131072,
      "name": "Nous: Hermes 4 70B",
      "source": "openrouter"
    },
    "nousresearch/hermes-4-405b": {
      "input_mtok": 1.0,
      "output_mtok": 3.0,
      "context_length": 131072,
      "name": "Nous: Hermes 4 405B",
      "source": "openrouter"
    },
    "deepseek/deepseek-chat-v3.1": {
      "input_mtok": 0.15,
      "output_mtok": 0.75,
      "context_length": 32768,
      "name": "DeepSeek: DeepSeek V3.1",
      "source": "openrouter"
    },
    "openai/gpt-4o-audio-preview": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o Audio",
      "source": "openrouter"
    },
    "mistralai/mistral-medium-3.1": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 131072,
      "name": "Mistral: Mistral Medium 3.1",
      "source": "openrouter"
    },
    "baidu/ernie-4.5-21b-a3b": {
      "input_mtok": 0.07,
      "output_mtok": 0.28,
      "context_length": 120000,
      "name": "Baidu: ERNIE 4.5 21B A3B",
      "source": "openrouter"
    },
    "baidu/ernie-4.5-vl-28b-a3b": {
      "input_mtok": 0.14,
      "output_mtok": 0.56,
      "context_length": 30000,
      "name": "Baidu: ERNIE 4.5 VL 28B A3B",
      "source": "openrouter"
    },
    "z-ai/glm-4.5v": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "context_length": 65536,
      "name": "Z.ai: GLM 4.5V",
      "source": "openrouter"
    },
    "ai21/jamba-large-1.7": {
      "input_mtok": 2.0,
      "output_mtok": 8.0,
      "context_length": 256000,
      "name": "AI21: Jamba Large 1.7",
      "source": "openrouter"
    },
    "openai/gpt-5-chat": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-5 Chat",
      "source": "openrouter"
    },
    "openai/gpt-oss-120b:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "OpenAI: gpt-oss-120b (free)",
      "source": "openrouter"
    },
    "openai/gpt-oss-120b": {
      "input_mtok": 0.039,
      "output_mtok": 0.19,
      "context_length": 131072,
      "name": "OpenAI: gpt-oss-120b",
      "source": "openrouter"
    },
    "openai/gpt-oss-120b:exacto": {
      "input_mtok": 0.039,
      "output_mtok": 0.19,
      "context_length": 131072,
      "name": "OpenAI: gpt-oss-120b (exacto)",
      "source": "openrouter"
    },
    "openai/gpt-oss-20b:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "OpenAI: gpt-oss-20b (free)",
      "source": "openrouter"
    },
    "openai/gpt-oss-20b": {
      "input_mtok": 0.03,
      "output_mtok": 0.14,
      "context_length": 131072,
      "name": "OpenAI: gpt-oss-20b",
      "source": "openrouter"
    },
    "anthropic/claude-opus-4.1": {
      "input_mtok": 15.0,
      "output_mtok": 75.0,
      "context_length": 200000,
      "name": "Anthropic: Claude Opus 4.1",
      "source": "openrouter"
    },
    "mistralai/codestral-2508": {
      "input_mtok": 0.3,
      "output_mtok": 0.9,
      "context_length": 256000,
      "name": "Mistral: Codestral 2508",
      "source": "openrouter"
    },
    "qwen/qwen3-coder-30b-a3b-instruct": {
      "input_mtok": 0.07,
      "output_mtok": 0.27,
      "context_length": 160000,
      "name": "Qwen: Qwen3 Coder 30B A3B Instruct",
      "source": "openrouter"
    },
    "qwen/qwen3-30b-a3b-instruct-2507": {
      "input_mtok": 0.08,
      "output_mtok": 0.33,
      "context_length": 262144,
      "name": "Qwen: Qwen3 30B A3B Instruct 2507",
      "source": "openrouter"
    },
    "z-ai/glm-4.5": {
      "input_mtok": 0.35,
      "output_mtok": 1.55,
      "context_length": 131072,
      "name": "Z.ai: GLM 4.5",
      "source": "openrouter"
    },
    "z-ai/glm-4.5-air:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Z.ai: GLM 4.5 Air (free)",
      "source": "openrouter"
    },
    "z-ai/glm-4.5-air": {
      "input_mtok": 0.13,
      "output_mtok": 0.85,
      "context_length": 131072,
      "name": "Z.ai: GLM 4.5 Air",
      "source": "openrouter"
    },
    "qwen/qwen3-235b-a22b-thinking-2507": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Qwen: Qwen3 235B A22B Thinking 2507",
      "source": "openrouter"
    },
    "z-ai/glm-4-32b": {
      "input_mtok": 0.1,
      "output_mtok": 0.1,
      "context_length": 128000,
      "name": "Z.ai: GLM 4 32B ",
      "source": "openrouter"
    },
    "qwen/qwen3-coder:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 262000,
      "name": "Qwen: Qwen3 Coder 480B A35B (free)",
      "source": "openrouter"
    },
    "qwen/qwen3-coder": {
      "input_mtok": 0.22,
      "output_mtok": 1.0,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Coder 480B A35B",
      "source": "openrouter"
    },
    "qwen/qwen3-coder:exacto": {
      "input_mtok": 0.22,
      "output_mtok": 1.8,
      "context_length": 262144,
      "name": "Qwen: Qwen3 Coder 480B A35B (exacto)",
      "source": "openrouter"
    },
    "bytedance/ui-tars-1.5-7b": {
      "input_mtok": 0.1,
      "output_mtok": 0.2,
      "context_length": 128000,
      "name": "ByteDance: UI-TARS 7B ",
      "source": "openrouter"
    },
    "qwen/qwen3-235b-a22b-2507": {
      "input_mtok": 0.071,
      "output_mtok": 0.1,
      "context_length": 262144,
      "name": "Qwen: Qwen3 235B A22B Instruct 2507",
      "source": "openrouter"
    },
    "switchpoint/router": {
      "input_mtok": 0.85,
      "output_mtok": 3.4,
      "context_length": 131072,
      "name": "Switchpoint Router",
      "source": "openrouter"
    },
    "moonshotai/kimi-k2": {
      "input_mtok": 0.5,
      "output_mtok": 2.4,
      "context_length": 131072,
      "name": "MoonshotAI: Kimi K2 0711",
      "source": "openrouter"
    },
    "mistralai/devstral-medium": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 131072,
      "name": "Mistral: Devstral Medium",
      "source": "openrouter"
    },
    "mistralai/devstral-small": {
      "input_mtok": 0.1,
      "output_mtok": 0.3,
      "context_length": 131072,
      "name": "Mistral: Devstral Small 1.1",
      "source": "openrouter"
    },
    "cognitivecomputations/dolphin-mistral-24b-venice-edition:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 32768,
      "name": "Venice: Uncensored (free)",
      "source": "openrouter"
    },
    "x-ai/grok-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 256000,
      "name": "xAI: Grok 4",
      "source": "openrouter"
    },
    "google/gemma-3n-e2b-it:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 8192,
      "name": "Google: Gemma 3n 2B (free)",
      "source": "openrouter"
    },
    "tencent/hunyuan-a13b-instruct": {
      "input_mtok": 0.14,
      "output_mtok": 0.57,
      "context_length": 131072,
      "name": "Tencent: Hunyuan A13B Instruct",
      "source": "openrouter"
    },
    "tngtech/deepseek-r1t2-chimera": {
      "input_mtok": 0.25,
      "output_mtok": 0.85,
      "context_length": 163840,
      "name": "TNG: DeepSeek R1T2 Chimera",
      "source": "openrouter"
    },
    "baidu/ernie-4.5-vl-424b-a47b": {
      "input_mtok": 0.42,
      "output_mtok": 1.25,
      "context_length": 123000,
      "name": "Baidu: ERNIE 4.5 VL 424B A47B ",
      "source": "openrouter"
    },
    "baidu/ernie-4.5-300b-a47b": {
      "input_mtok": 0.28,
      "output_mtok": 1.1,
      "context_length": 123000,
      "name": "Baidu: ERNIE 4.5 300B A47B ",
      "source": "openrouter"
    },
    "inception/mercury": {
      "input_mtok": 0.25,
      "output_mtok": 1.0,
      "context_length": 128000,
      "name": "Inception: Mercury",
      "source": "openrouter"
    },
    "mistralai/mistral-small-3.2-24b-instruct": {
      "input_mtok": 0.06,
      "output_mtok": 0.18,
      "context_length": 131072,
      "name": "Mistral: Mistral Small 3.2 24B",
      "source": "openrouter"
    },
    "minimax/minimax-m1": {
      "input_mtok": 0.4,
      "output_mtok": 2.2,
      "context_length": 1000000,
      "name": "MiniMax: MiniMax M1",
      "source": "openrouter"
    },
    "x-ai/grok-3-mini": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "name": "xAI: Grok 3 Mini",
      "source": "openrouter"
    },
    "x-ai/grok-3": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "name": "xAI: Grok 3",
      "source": "openrouter"
    },
    "google/gemini-2.5-pro-preview": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 1048576,
      "name": "Google: Gemini 2.5 Pro Preview 06-05",
      "source": "openrouter"
    },
    "deepseek/deepseek-r1-0528:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 163840,
      "name": "DeepSeek: R1 0528 (free)",
      "source": "openrouter"
    },
    "deepseek/deepseek-r1-0528": {
      "input_mtok": 0.4,
      "output_mtok": 1.75,
      "context_length": 163840,
      "name": "DeepSeek: R1 0528",
      "source": "openrouter"
    },
    "anthropic/claude-sonnet-4": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 1000000,
      "name": "Anthropic: Claude Sonnet 4",
      "source": "openrouter"
    },
    "google/gemma-3n-e4b-it:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 8192,
      "name": "Google: Gemma 3n 4B (free)",
      "source": "openrouter"
    },
    "google/gemma-3n-e4b-it": {
      "input_mtok": 0.02,
      "output_mtok": 0.04,
      "context_length": 32768,
      "name": "Google: Gemma 3n 4B",
      "source": "openrouter"
    },
    "nousresearch/deephermes-3-mistral-24b-preview": {
      "input_mtok": 0.02,
      "output_mtok": 0.1,
      "context_length": 32768,
      "name": "Nous: DeepHermes 3 Mistral 24B Preview",
      "source": "openrouter"
    },
    "mistralai/mistral-medium-3": {
      "input_mtok": 0.4,
      "output_mtok": 2.0,
      "context_length": 131072,
      "name": "Mistral: Mistral Medium 3",
      "source": "openrouter"
    },
    "google/gemini-2.5-pro-preview-05-06": {
      "input_mtok": 1.25,
      "output_mtok": 10.0,
      "context_length": 1048576,
      "name": "Google: Gemini 2.5 Pro Preview 05-06",
      "source": "openrouter"
    },
    "arcee-ai/spotlight": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "context_length": 131072,
      "name": "Arcee AI: Spotlight",
      "source": "openrouter"
    },
    "arcee-ai/maestro-reasoning": {
      "input_mtok": 0.9,
      "output_mtok": 3.3,
      "context_length": 131072,
      "name": "Arcee AI: Maestro Reasoning",
      "source": "openrouter"
    },
    "arcee-ai/virtuoso-large": {
      "input_mtok": 0.75,
      "output_mtok": 1.2,
      "context_length": 131072,
      "name": "Arcee AI: Virtuoso Large",
      "source": "openrouter"
    },
    "arcee-ai/coder-large": {
      "input_mtok": 0.5,
      "output_mtok": 0.8,
      "context_length": 32768,
      "name": "Arcee AI: Coder Large",
      "source": "openrouter"
    },
    "inception/mercury-coder": {
      "input_mtok": 0.25,
      "output_mtok": 1.0,
      "context_length": 128000,
      "name": "Inception: Mercury Coder",
      "source": "openrouter"
    },
    "qwen/qwen3-4b:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 40960,
      "name": "Qwen: Qwen3 4B (free)",
      "source": "openrouter"
    },
    "qwen/qwen3-4b": {
      "input_mtok": 0.0715,
      "output_mtok": 0.273,
      "context_length": 131072,
      "name": "Qwen: Qwen3 4B",
      "source": "openrouter"
    },
    "meta-llama/llama-guard-4-12b": {
      "input_mtok": 0.18,
      "output_mtok": 0.18,
      "context_length": 163840,
      "name": "Meta: Llama Guard 4 12B",
      "source": "openrouter"
    },
    "qwen/qwen3-30b-a3b": {
      "input_mtok": 0.06,
      "output_mtok": 0.22,
      "context_length": 40960,
      "name": "Qwen: Qwen3 30B A3B",
      "source": "openrouter"
    },
    "qwen/qwen3-8b": {
      "input_mtok": 0.05,
      "output_mtok": 0.4,
      "context_length": 32000,
      "name": "Qwen: Qwen3 8B",
      "source": "openrouter"
    },
    "qwen/qwen3-14b": {
      "input_mtok": 0.05,
      "output_mtok": 0.22,
      "context_length": 40960,
      "name": "Qwen: Qwen3 14B",
      "source": "openrouter"
    },
    "qwen/qwen3-32b": {
      "input_mtok": 0.08,
      "output_mtok": 0.24,
      "context_length": 40960,
      "name": "Qwen: Qwen3 32B",
      "source": "openrouter"
    },
    "qwen/qwen3-235b-a22b": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 40960,
      "name": "Qwen: Qwen3 235B A22B",
      "source": "openrouter"
    },
    "tngtech/deepseek-r1t-chimera": {
      "input_mtok": 0.3,
      "output_mtok": 1.2,
      "context_length": 163840,
      "name": "TNG: DeepSeek R1T Chimera",
      "source": "openrouter"
    },
    "openai/o4-mini-high": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 200000,
      "name": "OpenAI: o4 Mini High",
      "source": "openrouter"
    },
    "qwen/qwen2.5-coder-7b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.09,
      "context_length": 32768,
      "name": "Qwen: Qwen2.5 Coder 7B Instruct",
      "source": "openrouter"
    },
    "eleutherai/llemma_7b": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "context_length": 4096,
      "name": "EleutherAI: Llemma 7b",
      "source": "openrouter"
    },
    "alfredpros/codellama-7b-instruct-solidity": {
      "input_mtok": 0.8,
      "output_mtok": 1.2,
      "context_length": 4096,
      "name": "AlfredPros: CodeLLaMa 7B Instruct Solidity",
      "source": "openrouter"
    },
    "x-ai/grok-3-mini-beta": {
      "input_mtok": 0.3,
      "output_mtok": 0.5,
      "context_length": 131072,
      "name": "xAI: Grok 3 Mini Beta",
      "source": "openrouter"
    },
    "x-ai/grok-3-beta": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 131072,
      "name": "xAI: Grok 3 Beta",
      "source": "openrouter"
    },
    "nvidia/llama-3.1-nemotron-ultra-253b-v1": {
      "input_mtok": 0.6,
      "output_mtok": 1.8,
      "context_length": 131072,
      "name": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1",
      "source": "openrouter"
    },
    "meta-llama/llama-4-maverick": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 1048576,
      "name": "Meta: Llama 4 Maverick",
      "source": "openrouter"
    },
    "meta-llama/llama-4-scout": {
      "input_mtok": 0.08,
      "output_mtok": 0.3,
      "context_length": 327680,
      "name": "Meta: Llama 4 Scout",
      "source": "openrouter"
    },
    "qwen/qwen2.5-vl-32b-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.22,
      "context_length": 16384,
      "name": "Qwen: Qwen2.5 VL 32B Instruct",
      "source": "openrouter"
    },
    "deepseek/deepseek-chat-v3-0324": {
      "input_mtok": 0.19,
      "output_mtok": 0.87,
      "context_length": 163840,
      "name": "DeepSeek: DeepSeek V3 0324",
      "source": "openrouter"
    },
    "mistralai/mistral-small-3.1-24b-instruct:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 128000,
      "name": "Mistral: Mistral Small 3.1 24B (free)",
      "source": "openrouter"
    },
    "mistralai/mistral-small-3.1-24b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.11,
      "context_length": 131072,
      "name": "Mistral: Mistral Small 3.1 24B",
      "source": "openrouter"
    },
    "allenai/olmo-2-0325-32b-instruct": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 128000,
      "name": "AllenAI: Olmo 2 32B Instruct",
      "source": "openrouter"
    },
    "google/gemma-3-4b-it:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 32768,
      "name": "Google: Gemma 3 4B (free)",
      "source": "openrouter"
    },
    "google/gemma-3-4b-it": {
      "input_mtok": 0.017,
      "output_mtok": 0.0682,
      "context_length": 96000,
      "name": "Google: Gemma 3 4B",
      "source": "openrouter"
    },
    "google/gemma-3-12b-it:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 32768,
      "name": "Google: Gemma 3 12B (free)",
      "source": "openrouter"
    },
    "google/gemma-3-12b-it": {
      "input_mtok": 0.03,
      "output_mtok": 0.1,
      "context_length": 131072,
      "name": "Google: Gemma 3 12B",
      "source": "openrouter"
    },
    "cohere/command-a": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 256000,
      "name": "Cohere: Command A",
      "source": "openrouter"
    },
    "openai/gpt-4o-mini-search-preview": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o-mini Search Preview",
      "source": "openrouter"
    },
    "openai/gpt-4o-search-preview": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o Search Preview",
      "source": "openrouter"
    },
    "google/gemma-3-27b-it:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Google: Gemma 3 27B (free)",
      "source": "openrouter"
    },
    "google/gemma-3-27b-it": {
      "input_mtok": 0.04,
      "output_mtok": 0.15,
      "context_length": 128000,
      "name": "Google: Gemma 3 27B",
      "source": "openrouter"
    },
    "thedrummer/skyfall-36b-v2": {
      "input_mtok": 0.55,
      "output_mtok": 0.8,
      "context_length": 32768,
      "name": "TheDrummer: Skyfall 36B V2",
      "source": "openrouter"
    },
    "qwen/qwq-32b": {
      "input_mtok": 0.15,
      "output_mtok": 0.4,
      "context_length": 32768,
      "name": "Qwen: QwQ 32B",
      "source": "openrouter"
    },
    "google/gemini-2.0-flash-lite-001": {
      "input_mtok": 0.075,
      "output_mtok": 0.3,
      "context_length": 1048576,
      "name": "Google: Gemini 2.0 Flash Lite",
      "source": "openrouter"
    },
    "anthropic/claude-3.7-sonnet:thinking": {
      "input_mtok": 3.0,
      "output_mtok": 15.0,
      "context_length": 200000,
      "name": "Anthropic: Claude 3.7 Sonnet (thinking)",
      "source": "openrouter"
    },
    "mistralai/mistral-saba": {
      "input_mtok": 0.2,
      "output_mtok": 0.6,
      "context_length": 32768,
      "name": "Mistral: Saba",
      "source": "openrouter"
    },
    "meta-llama/llama-guard-3-8b": {
      "input_mtok": 0.02,
      "output_mtok": 0.06,
      "context_length": 131072,
      "name": "Llama Guard 3 8B",
      "source": "openrouter"
    },
    "openai/o3-mini-high": {
      "input_mtok": 1.1,
      "output_mtok": 4.4,
      "context_length": 200000,
      "name": "OpenAI: o3 Mini High",
      "source": "openrouter"
    },
    "google/gemini-2.0-flash-001": {
      "input_mtok": 0.1,
      "output_mtok": 0.4,
      "context_length": 1048576,
      "name": "Google: Gemini 2.0 Flash",
      "source": "openrouter"
    },
    "qwen/qwen-vl-plus": {
      "input_mtok": 0.21,
      "output_mtok": 0.63,
      "context_length": 131072,
      "name": "Qwen: Qwen VL Plus",
      "source": "openrouter"
    },
    "aion-labs/aion-1.0": {
      "input_mtok": 4.0,
      "output_mtok": 8.0,
      "context_length": 131072,
      "name": "AionLabs: Aion-1.0",
      "source": "openrouter"
    },
    "aion-labs/aion-1.0-mini": {
      "input_mtok": 0.7,
      "output_mtok": 1.4,
      "context_length": 131072,
      "name": "AionLabs: Aion-1.0-Mini",
      "source": "openrouter"
    },
    "aion-labs/aion-rp-llama-3.1-8b": {
      "input_mtok": 0.8,
      "output_mtok": 1.6,
      "context_length": 32768,
      "name": "AionLabs: Aion-RP 1.0 (8B)",
      "source": "openrouter"
    },
    "qwen/qwen-vl-max": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 131072,
      "name": "Qwen: Qwen VL Max",
      "source": "openrouter"
    },
    "qwen/qwen-turbo": {
      "input_mtok": 0.05,
      "output_mtok": 0.2,
      "context_length": 131072,
      "name": "Qwen: Qwen-Turbo",
      "source": "openrouter"
    },
    "qwen/qwen2.5-vl-72b-instruct": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 32768,
      "name": "Qwen: Qwen2.5 VL 72B Instruct",
      "source": "openrouter"
    },
    "qwen/qwen-plus": {
      "input_mtok": 0.4,
      "output_mtok": 1.2,
      "context_length": 1000000,
      "name": "Qwen: Qwen-Plus",
      "source": "openrouter"
    },
    "qwen/qwen-max": {
      "input_mtok": 1.6,
      "output_mtok": 6.4,
      "context_length": 32768,
      "name": "Qwen: Qwen-Max ",
      "source": "openrouter"
    },
    "mistralai/mistral-small-24b-instruct-2501": {
      "input_mtok": 0.05,
      "output_mtok": 0.08,
      "context_length": 32768,
      "name": "Mistral: Mistral Small 3",
      "source": "openrouter"
    },
    "deepseek/deepseek-r1-distill-qwen-32b": {
      "input_mtok": 0.29,
      "output_mtok": 0.29,
      "context_length": 32768,
      "name": "DeepSeek: R1 Distill Qwen 32B",
      "source": "openrouter"
    },
    "deepseek/deepseek-r1-distill-llama-70b": {
      "input_mtok": 0.03,
      "output_mtok": 0.11,
      "context_length": 131072,
      "name": "DeepSeek: R1 Distill Llama 70B",
      "source": "openrouter"
    },
    "minimax/minimax-01": {
      "input_mtok": 0.2,
      "output_mtok": 1.1,
      "context_length": 1000192,
      "name": "MiniMax: MiniMax-01",
      "source": "openrouter"
    },
    "microsoft/phi-4": {
      "input_mtok": 0.06,
      "output_mtok": 0.14,
      "context_length": 16384,
      "name": "Microsoft: Phi 4",
      "source": "openrouter"
    },
    "sao10k/l3.1-70b-hanami-x1": {
      "input_mtok": 3.0,
      "output_mtok": 3.0,
      "context_length": 16000,
      "name": "Sao10K: Llama 3.1 70B Hanami x1",
      "source": "openrouter"
    },
    "sao10k/l3.3-euryale-70b": {
      "input_mtok": 0.65,
      "output_mtok": 0.75,
      "context_length": 131072,
      "name": "Sao10K: Llama 3.3 Euryale 70B",
      "source": "openrouter"
    },
    "openai/o1": {
      "input_mtok": 15.0,
      "output_mtok": 60.0,
      "context_length": 200000,
      "name": "OpenAI: o1",
      "source": "openrouter"
    },
    "cohere/command-r7b-12-2024": {
      "input_mtok": 0.0375,
      "output_mtok": 0.15,
      "context_length": 128000,
      "name": "Cohere: Command R7B (12-2024)",
      "source": "openrouter"
    },
    "meta-llama/llama-3.3-70b-instruct:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 128000,
      "name": "Meta: Llama 3.3 70B Instruct (free)",
      "source": "openrouter"
    },
    "meta-llama/llama-3.3-70b-instruct": {
      "input_mtok": 0.1,
      "output_mtok": 0.32,
      "context_length": 131072,
      "name": "Meta: Llama 3.3 70B Instruct",
      "source": "openrouter"
    },
    "amazon/nova-lite-v1": {
      "input_mtok": 0.06,
      "output_mtok": 0.24,
      "context_length": 300000,
      "name": "Amazon: Nova Lite 1.0",
      "source": "openrouter"
    },
    "amazon/nova-micro-v1": {
      "input_mtok": 0.035,
      "output_mtok": 0.14,
      "context_length": 128000,
      "name": "Amazon: Nova Micro 1.0",
      "source": "openrouter"
    },
    "amazon/nova-pro-v1": {
      "input_mtok": 0.8,
      "output_mtok": 3.2,
      "context_length": 300000,
      "name": "Amazon: Nova Pro 1.0",
      "source": "openrouter"
    },
    "openai/gpt-4o-2024-11-20": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o (2024-11-20)",
      "source": "openrouter"
    },
    "mistralai/mistral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 131072,
      "name": "Mistral Large 2411",
      "source": "openrouter"
    },
    "mistralai/mistral-large-2407": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 131072,
      "name": "Mistral Large 2407",
      "source": "openrouter"
    },
    "mistralai/pixtral-large-2411": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 131072,
      "name": "Mistral: Pixtral Large 2411",
      "source": "openrouter"
    },
    "qwen/qwen-2.5-coder-32b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.11,
      "context_length": 32768,
      "name": "Qwen2.5 Coder 32B Instruct",
      "source": "openrouter"
    },
    "raifle/sorcererlm-8x22b": {
      "input_mtok": 4.5,
      "output_mtok": 4.5,
      "context_length": 16000,
      "name": "SorcererLM 8x22B",
      "source": "openrouter"
    },
    "thedrummer/unslopnemo-12b": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 32768,
      "name": "TheDrummer: UnslopNemo 12B",
      "source": "openrouter"
    },
    "anthracite-org/magnum-v4-72b": {
      "input_mtok": 3.0,
      "output_mtok": 5.0,
      "context_length": 16384,
      "name": "Magnum v4 72B",
      "source": "openrouter"
    },
    "qwen/qwen-2.5-7b-instruct": {
      "input_mtok": 0.04,
      "output_mtok": 0.1,
      "context_length": 32768,
      "name": "Qwen: Qwen2.5 7B Instruct",
      "source": "openrouter"
    },
    "nvidia/llama-3.1-nemotron-70b-instruct": {
      "input_mtok": 1.2,
      "output_mtok": 1.2,
      "context_length": 131072,
      "name": "NVIDIA: Llama 3.1 Nemotron 70B Instruct",
      "source": "openrouter"
    },
    "inflection/inflection-3-pi": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 8000,
      "name": "Inflection: Inflection 3 Pi",
      "source": "openrouter"
    },
    "inflection/inflection-3-productivity": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 8000,
      "name": "Inflection: Inflection 3 Productivity",
      "source": "openrouter"
    },
    "thedrummer/rocinante-12b": {
      "input_mtok": 0.17,
      "output_mtok": 0.43,
      "context_length": 32768,
      "name": "TheDrummer: Rocinante 12B",
      "source": "openrouter"
    },
    "meta-llama/llama-3.2-3b-instruct:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Meta: Llama 3.2 3B Instruct (free)",
      "source": "openrouter"
    },
    "meta-llama/llama-3.2-3b-instruct": {
      "input_mtok": 0.02,
      "output_mtok": 0.02,
      "context_length": 131072,
      "name": "Meta: Llama 3.2 3B Instruct",
      "source": "openrouter"
    },
    "meta-llama/llama-3.2-1b-instruct": {
      "input_mtok": 0.027,
      "output_mtok": 0.2,
      "context_length": 60000,
      "name": "Meta: Llama 3.2 1B Instruct",
      "source": "openrouter"
    },
    "meta-llama/llama-3.2-11b-vision-instruct": {
      "input_mtok": 0.049,
      "output_mtok": 0.049,
      "context_length": 131072,
      "name": "Meta: Llama 3.2 11B Vision Instruct",
      "source": "openrouter"
    },
    "qwen/qwen-2.5-72b-instruct": {
      "input_mtok": 0.12,
      "output_mtok": 0.39,
      "context_length": 32768,
      "name": "Qwen2.5 72B Instruct",
      "source": "openrouter"
    },
    "neversleep/llama-3.1-lumimaid-8b": {
      "input_mtok": 0.09,
      "output_mtok": 0.6,
      "context_length": 32768,
      "name": "NeverSleep: Lumimaid v0.2 8B",
      "source": "openrouter"
    },
    "cohere/command-r-08-2024": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 128000,
      "name": "Cohere: Command R (08-2024)",
      "source": "openrouter"
    },
    "cohere/command-r-plus-08-2024": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "Cohere: Command R+ (08-2024)",
      "source": "openrouter"
    },
    "sao10k/l3.1-euryale-70b": {
      "input_mtok": 0.65,
      "output_mtok": 0.75,
      "context_length": 32768,
      "name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
      "source": "openrouter"
    },
    "qwen/qwen-2.5-vl-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "name": "Qwen: Qwen2.5-VL 7B Instruct",
      "source": "openrouter"
    },
    "nousresearch/hermes-3-llama-3.1-70b": {
      "input_mtok": 0.3,
      "output_mtok": 0.3,
      "context_length": 65536,
      "name": "Nous: Hermes 3 70B Instruct",
      "source": "openrouter"
    },
    "nousresearch/hermes-3-llama-3.1-405b:free": {
      "input_mtok": 0.0,
      "output_mtok": 0.0,
      "context_length": 131072,
      "name": "Nous: Hermes 3 405B Instruct (free)",
      "source": "openrouter"
    },
    "nousresearch/hermes-3-llama-3.1-405b": {
      "input_mtok": 1.0,
      "output_mtok": 1.0,
      "context_length": 131072,
      "name": "Nous: Hermes 3 405B Instruct",
      "source": "openrouter"
    },
    "sao10k/l3-lunaris-8b": {
      "input_mtok": 0.04,
      "output_mtok": 0.05,
      "context_length": 8192,
      "name": "Sao10K: Llama 3 8B Lunaris",
      "source": "openrouter"
    },
    "openai/gpt-4o-2024-08-06": {
      "input_mtok": 2.5,
      "output_mtok": 10.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o (2024-08-06)",
      "source": "openrouter"
    },
    "meta-llama/llama-3.1-405b": {
      "input_mtok": 4.0,
      "output_mtok": 4.0,
      "context_length": 32768,
      "name": "Meta: Llama 3.1 405B (base)",
      "source": "openrouter"
    },
    "meta-llama/llama-3.1-8b-instruct": {
      "input_mtok": 0.02,
      "output_mtok": 0.05,
      "context_length": 16384,
      "name": "Meta: Llama 3.1 8B Instruct",
      "source": "openrouter"
    },
    "meta-llama/llama-3.1-405b-instruct": {
      "input_mtok": 4.0,
      "output_mtok": 4.0,
      "context_length": 131000,
      "name": "Meta: Llama 3.1 405B Instruct",
      "source": "openrouter"
    },
    "meta-llama/llama-3.1-70b-instruct": {
      "input_mtok": 0.4,
      "output_mtok": 0.4,
      "context_length": 131072,
      "name": "Meta: Llama 3.1 70B Instruct",
      "source": "openrouter"
    },
    "mistralai/mistral-nemo": {
      "input_mtok": 0.02,
      "output_mtok": 0.04,
      "context_length": 131072,
      "name": "Mistral: Mistral Nemo",
      "source": "openrouter"
    },
    "openai/gpt-4o-mini-2024-07-18": {
      "input_mtok": 0.15,
      "output_mtok": 0.6,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o-mini (2024-07-18)",
      "source": "openrouter"
    },
    "google/gemma-2-27b-it": {
      "input_mtok": 0.65,
      "output_mtok": 0.65,
      "context_length": 8192,
      "name": "Google: Gemma 2 27B",
      "source": "openrouter"
    },
    "google/gemma-2-9b-it": {
      "input_mtok": 0.03,
      "output_mtok": 0.09,
      "context_length": 8192,
      "name": "Google: Gemma 2 9B",
      "source": "openrouter"
    },
    "sao10k/l3-euryale-70b": {
      "input_mtok": 1.48,
      "output_mtok": 1.48,
      "context_length": 8192,
      "name": "Sao10k: Llama 3 Euryale 70B v2.1",
      "source": "openrouter"
    },
    "nousresearch/hermes-2-pro-llama-3-8b": {
      "input_mtok": 0.14,
      "output_mtok": 0.14,
      "context_length": 8192,
      "name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
      "source": "openrouter"
    },
    "mistralai/mistral-7b-instruct": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "name": "Mistral: Mistral 7B Instruct",
      "source": "openrouter"
    },
    "mistralai/mistral-7b-instruct-v0.3": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "name": "Mistral: Mistral 7B Instruct v0.3",
      "source": "openrouter"
    },
    "meta-llama/llama-guard-2-8b": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 8192,
      "name": "Meta: LlamaGuard 2 8B",
      "source": "openrouter"
    },
    "openai/gpt-4o-2024-05-13": {
      "input_mtok": 5.0,
      "output_mtok": 15.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o (2024-05-13)",
      "source": "openrouter"
    },
    "openai/gpt-4o:extended": {
      "input_mtok": 6.0,
      "output_mtok": 18.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4o (extended)",
      "source": "openrouter"
    },
    "meta-llama/llama-3-70b-instruct": {
      "input_mtok": 0.51,
      "output_mtok": 0.74,
      "context_length": 8192,
      "name": "Meta: Llama 3 70B Instruct",
      "source": "openrouter"
    },
    "meta-llama/llama-3-8b-instruct": {
      "input_mtok": 0.03,
      "output_mtok": 0.04,
      "context_length": 8192,
      "name": "Meta: Llama 3 8B Instruct",
      "source": "openrouter"
    },
    "mistralai/mixtral-8x22b-instruct": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 65536,
      "name": "Mistral: Mixtral 8x22B Instruct",
      "source": "openrouter"
    },
    "microsoft/wizardlm-2-8x22b": {
      "input_mtok": 0.62,
      "output_mtok": 0.62,
      "context_length": 65535,
      "name": "WizardLM-2 8x22B",
      "source": "openrouter"
    },
    "openai/gpt-4-turbo": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4 Turbo",
      "source": "openrouter"
    },
    "mistralai/mistral-large": {
      "input_mtok": 2.0,
      "output_mtok": 6.0,
      "context_length": 128000,
      "name": "Mistral Large",
      "source": "openrouter"
    },
    "openai/gpt-3.5-turbo-0613": {
      "input_mtok": 1.0,
      "output_mtok": 2.0,
      "context_length": 4095,
      "name": "OpenAI: GPT-3.5 Turbo (older v0613)",
      "source": "openrouter"
    },
    "openai/gpt-4-turbo-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4 Turbo Preview",
      "source": "openrouter"
    },
    "mistralai/mistral-7b-instruct-v0.2": {
      "input_mtok": 0.2,
      "output_mtok": 0.2,
      "context_length": 32768,
      "name": "Mistral: Mistral 7B Instruct v0.2",
      "source": "openrouter"
    },
    "mistralai/mixtral-8x7b-instruct": {
      "input_mtok": 0.54,
      "output_mtok": 0.54,
      "context_length": 32768,
      "name": "Mistral: Mixtral 8x7B Instruct",
      "source": "openrouter"
    },
    "neversleep/noromaid-20b": {
      "input_mtok": 1.0,
      "output_mtok": 1.75,
      "context_length": 4096,
      "name": "Noromaid 20B",
      "source": "openrouter"
    },
    "alpindale/goliath-120b": {
      "input_mtok": 3.75,
      "output_mtok": 7.5,
      "context_length": 6144,
      "name": "Goliath 120B",
      "source": "openrouter"
    },
    "openrouter/auto": {
      "input_mtok": -1000000.0,
      "output_mtok": -1000000.0,
      "context_length": 2000000,
      "name": "Auto Router",
      "source": "openrouter"
    },
    "openai/gpt-4-1106-preview": {
      "input_mtok": 10.0,
      "output_mtok": 30.0,
      "context_length": 128000,
      "name": "OpenAI: GPT-4 Turbo (older v1106)",
      "source": "openrouter"
    },
    "openai/gpt-3.5-turbo-instruct": {
      "input_mtok": 1.5,
      "output_mtok": 2.0,
      "context_length": 4095,
      "name": "OpenAI: GPT-3.5 Turbo Instruct",
      "source": "openrouter"
    },
    "mistralai/mistral-7b-instruct-v0.1": {
      "input_mtok": 0.11,
      "output_mtok": 0.19,
      "context_length": 2824,
      "name": "Mistral: Mistral 7B Instruct v0.1",
      "source": "openrouter"
    },
    "openai/gpt-3.5-turbo-16k": {
      "input_mtok": 3.0,
      "output_mtok": 4.0,
      "context_length": 16385,
      "name": "OpenAI: GPT-3.5 Turbo 16k",
      "source": "openrouter"
    },
    "mancer/weaver": {
      "input_mtok": 0.75,
      "output_mtok": 1.0,
      "context_length": 8000,
      "name": "Mancer: Weaver (alpha)",
      "source": "openrouter"
    },
    "undi95/remm-slerp-l2-13b": {
      "input_mtok": 0.45,
      "output_mtok": 0.65,
      "context_length": 6144,
      "name": "ReMM SLERP 13B",
      "source": "openrouter"
    },
    "gryphe/mythomax-l2-13b": {
      "input_mtok": 0.06,
      "output_mtok": 0.06,
      "context_length": 4096,
      "name": "MythoMax 13B",
      "source": "openrouter"
    },
    "openai/gpt-4-0314": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 8191,
      "name": "OpenAI: GPT-4 (older v0314)",
      "source": "openrouter"
    },
    "openai/gpt-4": {
      "input_mtok": 30.0,
      "output_mtok": 60.0,
      "context_length": 8191,
      "name": "OpenAI: GPT-4",
      "source": "openrouter"
    },
    "openai/gpt-3.5-turbo": {
      "input_mtok": 0.5,
      "output_mtok": 1.5,
      "context_length": 16385,
      "name": "OpenAI: GPT-3.5 Turbo",
      "source": "openrouter"
    }
  }
}