{
  "fetched_at": "2026-02-21T06:15:07.521723+00:00",
  "models": {
    "ai21.j2-mid-v1": {
      "input_cost_per_token": 1.25e-05,
      "output_cost_per_token": 1.25e-05,
      "context_length": 8191,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ai21.j2-ultra-v1": {
      "input_cost_per_token": 1.88e-05,
      "output_cost_per_token": 1.88e-05,
      "context_length": 8191,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ai21.jamba-1-5-large-v1:0": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ai21.jamba-1-5-mini-v1:0": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ai21.jamba-instruct-v1:0": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 70000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.writer.palmyra-x4-v1:0": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.writer.palmyra-x5-v1:0": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "writer.palmyra-x4-v1:0": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "writer.palmyra-x5-v1:0": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.nova-lite-v1:0": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.nova-2-lite-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_cost_per_token": 2.1875e-06,
      "output_cost_per_token": 1.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.46875e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.amazon.nova-2-lite-v1:0": {
      "input_cost_per_token": 3.3e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 8.25e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_cost_per_token": 2.1875e-06,
      "output_cost_per_token": 1.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.46875e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.amazon.nova-2-lite-v1:0": {
      "input_cost_per_token": 3.3e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 8.25e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_cost_per_token": 2.1875e-06,
      "output_cost_per_token": 1.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.46875e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.amazon.nova-2-lite-v1:0": {
      "input_cost_per_token": 3.3e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 8.25e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.amazon.nova-2-pro-preview-20251202-v1:0": {
      "input_cost_per_token": 2.1875e-06,
      "output_cost_per_token": 1.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.46875e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.nova-micro-v1:0": {
      "input_cost_per_token": 3.5e-08,
      "output_cost_per_token": 1.4e-07,
      "context_length": 128000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.nova-pro-v1:0": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 3.2e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "twelvelabs.pegasus-1-2-v1:0": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 7.5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.twelvelabs.pegasus-1-2-v1:0": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 7.5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.twelvelabs.pegasus-1-2-v1:0": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 7.5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.titan-text-express-v1": {
      "input_cost_per_token": 1.3e-06,
      "output_cost_per_token": 1.7e-06,
      "context_length": 42000,
      "max_output_tokens": 8000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.titan-text-lite-v1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 42000,
      "max_output_tokens": 4000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon.titan-text-premier-v1:0": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 42000,
      "max_output_tokens": 32000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-haiku-4-5@20251001": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-7-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3.6e-06,
      "output_cost_per_token": 1.8e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.6e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-instant-v1": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-1-20250805-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-20250514-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-opus-4-6-v1": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.anthropic.claude-opus-4-6-v1": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-6-v1": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-6-v1": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "au.anthropic.claude-opus-4-6-v1": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.75e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-sonnet-4-6": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.anthropic.claude-sonnet-4-6": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-sonnet-4-6": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-sonnet-4-6": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-sonnet-4-6": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-v1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anthropic.claude-v2:1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/HuggingFaceH4/zephyr-7b-beta": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/codellama/CodeLlama-34b-Instruct-hf": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/codellama/CodeLlama-70b-Instruct-hf": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/google/gemma-7b-it": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/meta-llama/Llama-2-13b-chat-hf": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2.5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/meta-llama/Llama-2-70b-chat-hf": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/meta-llama/Llama-2-7b-chat-hf": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/mistralai/Mistral-7B-Instruct-v0.1": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "anyscale",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.amazon.nova-lite-v1:0": {
      "input_cost_per_token": 6.3e-08,
      "output_cost_per_token": 2.52e-07,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.amazon.nova-micro-v1:0": {
      "input_cost_per_token": 3.7e-08,
      "output_cost_per_token": 1.48e-07,
      "context_length": 128000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.amazon.nova-pro-v1:0": {
      "input_cost_per_token": 8.4e-07,
      "output_cost_per_token": 3.36e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-haiku-20240307-v1:0": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 5.5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "apac.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "au.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/command-r-plus": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/claude-haiku-4-5": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/claude-opus-4-5": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/claude-opus-4-6": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/claude-opus-4-1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/claude-sonnet-4-5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/claude-sonnet-4-6": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/computer-use-preview": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/gpt-oss-120b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/model_router": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-2024-08-06": {
      "input_cost_per_token": 2.75e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.375e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-2024-11-20": {
      "input_cost_per_token": 2.75e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-mini-2024-07-18": {
      "input_cost_per_token": 1.65e-07,
      "output_cost_per_token": 6.6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8.3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_cost_per_token": 6.6e-07,
      "output_cost_per_token": 2.64e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.75e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.75e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-5-2025-08-07": {
      "input_cost_per_token": 1.375e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.375e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-5-mini-2025-08-07": {
      "input_cost_per_token": 2.75e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-5.1": {
      "input_cost_per_token": 1.38e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-5.1-chat": {
      "input_cost_per_token": 1.38e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/gpt-5-nano-2025-08-07": {
      "input_cost_per_token": 5.5e-08,
      "output_cost_per_token": 4.4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/o1-2024-12-17": {
      "input_cost_per_token": 1.65e-05,
      "output_cost_per_token": 6.6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/o1-mini-2024-09-12": {
      "input_cost_per_token": 1.21e-06,
      "output_cost_per_token": 4.84e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 6.05e-07,
      "batch_input_cost": 6.05e-07,
      "batch_output_cost": 2.42e-06,
      "source": "litellm"
    },
    "azure/eu/o1-preview-2024-09-12": {
      "input_cost_per_token": 1.65e-05,
      "output_cost_per_token": 6.6e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/eu/o3-mini-2025-01-31": {
      "input_cost_per_token": 1.21e-06,
      "output_cost_per_token": 4.84e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 6.05e-07,
      "batch_input_cost": 6.05e-07,
      "batch_output_cost": 2.42e-06,
      "source": "litellm"
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/global-standard/gpt-4o-2024-11-20": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/global-standard/gpt-4o-mini": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/global/gpt-4o-2024-08-06": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/global/gpt-4o-2024-11-20": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/global/gpt-5.1": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/global/gpt-5.1-chat": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-3.5-turbo": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 4097,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-3.5-turbo-0125": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 0,
      "provider": "azure_text",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 4097,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-0125": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-0301": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-0613": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-1106": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-16k": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-16k-0613": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-instruct": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 0,
      "provider": "azure_text",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-35-turbo-instruct-0914": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 0,
      "provider": "azure_text",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-0125-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-0613": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-1106-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-32k": {
      "input_cost_per_token": 6e-05,
      "output_cost_per_token": 0.00012,
      "context_length": 32768,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-32k-0613": {
      "input_cost_per_token": 6e-05,
      "output_cost_per_token": 0.00012,
      "context_length": 32768,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-turbo": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-turbo-2024-04-09": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4-turbo-vision-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4.1": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 4e-06,
      "source": "litellm"
    },
    "azure/gpt-4.1-2025-04-14": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 4e-06,
      "source": "litellm"
    },
    "azure/gpt-4.1-mini": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 2e-07,
      "batch_output_cost": 8e-07,
      "source": "litellm"
    },
    "azure/gpt-4.1-mini-2025-04-14": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 2e-07,
      "batch_output_cost": 8e-07,
      "source": "litellm"
    },
    "azure/gpt-4.1-nano": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 5e-08,
      "batch_output_cost": 2e-07,
      "source": "litellm"
    },
    "azure/gpt-4.1-nano-2025-04-14": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 5e-08,
      "batch_output_cost": 2e-07,
      "source": "litellm"
    },
    "azure/gpt-4.5-preview": {
      "input_cost_per_token": 7.5e-05,
      "output_cost_per_token": 0.00015,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.75e-05,
      "batch_input_cost": 3.75e-05,
      "batch_output_cost": 7.5e-05,
      "source": "litellm"
    },
    "azure/gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-2024-05-13": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-2024-08-06": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-2024-11-20": {
      "input_cost_per_token": 2.75e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-audio-2025-08-28": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-audio-mini-2025-10-06": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-audio-preview-2024-12-17": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-mini": {
      "input_cost_per_token": 1.65e-07,
      "output_cost_per_token": 6.6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-2024-07-18": {
      "input_cost_per_token": 1.65e-07,
      "output_cost_per_token": 6.6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-audio-preview-2024-12-17": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-realtime-2025-08-28": {
      "input_cost_per_token": 4e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 32000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 4e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-realtime-mini-2025-10-06": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 32000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 6e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-realtime-preview-2024-10-01": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-4o-realtime-preview-2024-12-17": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.1-2025-11-13": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.1-chat-2025-11-13": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-2025-08-07": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-chat": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-chat-latest": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-mini-2025-08-07": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-nano": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5-nano-2025-08-07": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.1": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.1-chat": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.2": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.2-2025-12-11": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.2-chat": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/gpt-5.2-chat-2025-12-11": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/mistral-large-2402": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 32000,
      "max_output_tokens": 0,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/mistral-large-latest": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 32000,
      "max_output_tokens": 0,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o1-2024-12-17": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o1-mini": {
      "input_cost_per_token": 1.21e-06,
      "output_cost_per_token": 4.84e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 6.05e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o1-mini-2024-09-12": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o1-preview": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o1-preview-2024-09-12": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o3": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o3-2025-04-16": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o3-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o3-mini-2025-01-31": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o4-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/o4-mini-2025-04-16": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-4.1-2025-04-14": {
      "input_cost_per_token": 2.2e-06,
      "output_cost_per_token": 8.8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 1.1e-06,
      "batch_output_cost": 4.4e-06,
      "source": "litellm"
    },
    "azure/us/gpt-4.1-mini-2025-04-14": {
      "input_cost_per_token": 4.4e-07,
      "output_cost_per_token": 1.76e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 2.2e-07,
      "batch_output_cost": 8.8e-07,
      "source": "litellm"
    },
    "azure/us/gpt-4.1-nano-2025-04-14": {
      "input_cost_per_token": 1.1e-07,
      "output_cost_per_token": 4.4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 6e-08,
      "batch_output_cost": 2.2e-07,
      "source": "litellm"
    },
    "azure/us/gpt-4o-2024-08-06": {
      "input_cost_per_token": 2.75e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.375e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-4o-2024-11-20": {
      "input_cost_per_token": 2.75e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-4o-mini-2024-07-18": {
      "input_cost_per_token": 1.65e-07,
      "output_cost_per_token": 6.6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8.3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_cost_per_token": 6.6e-07,
      "output_cost_per_token": 2.64e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-4o-realtime-preview-2024-10-01": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.75e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-4o-realtime-preview-2024-12-17": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.75e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-5-2025-08-07": {
      "input_cost_per_token": 1.375e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.375e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-5-mini-2025-08-07": {
      "input_cost_per_token": 2.75e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-5-nano-2025-08-07": {
      "input_cost_per_token": 5.5e-08,
      "output_cost_per_token": 4.4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-5.1": {
      "input_cost_per_token": 1.38e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/gpt-5.1-chat": {
      "input_cost_per_token": 1.38e-06,
      "output_cost_per_token": 1.1e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/o1-2024-12-17": {
      "input_cost_per_token": 1.65e-05,
      "output_cost_per_token": 6.6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/o1-mini-2024-09-12": {
      "input_cost_per_token": 1.21e-06,
      "output_cost_per_token": 4.84e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 6.05e-07,
      "batch_input_cost": 6.05e-07,
      "batch_output_cost": 2.42e-06,
      "source": "litellm"
    },
    "azure/us/o1-preview-2024-09-12": {
      "input_cost_per_token": 1.65e-05,
      "output_cost_per_token": 6.6e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/o3-2025-04-16": {
      "input_cost_per_token": 2.2e-06,
      "output_cost_per_token": 8.8e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure/us/o3-mini-2025-01-31": {
      "input_cost_per_token": 1.21e-06,
      "output_cost_per_token": 4.84e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 6.05e-07,
      "batch_input_cost": 6.05e-07,
      "batch_output_cost": 2.42e-06,
      "source": "litellm"
    },
    "azure/us/o4-mini-2025-04-16": {
      "input_cost_per_token": 1.21e-06,
      "output_cost_per_token": 4.84e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
      "input_cost_per_token": 3.7e-07,
      "output_cost_per_token": 3.7e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
      "input_cost_per_token": 2.04e-06,
      "output_cost_per_token": 2.04e-06,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
      "input_cost_per_token": 7.1e-07,
      "output_cost_per_token": 7.1e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_cost_per_token": 1.41e-06,
      "output_cost_per_token": 3.5e-07,
      "context_length": 1000000,
      "max_output_tokens": 16384,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 7.8e-07,
      "context_length": 10000000,
      "max_output_tokens": 16384,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 3.7e-07,
      "context_length": 8192,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
      "input_cost_per_token": 5.33e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
      "input_cost_per_token": 2.68e-06,
      "output_cost_per_token": 3.54e-06,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 6.1e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
      "input_cost_per_token": 1.7e-07,
      "output_cost_per_token": 6.8e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3-medium-4k-instruct": {
      "input_cost_per_token": 1.7e-07,
      "output_cost_per_token": 6.8e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 5.2e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3-mini-4k-instruct": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 5.2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3-small-128k-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3-small-8k-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
      "input_cost_per_token": 1.6e-07,
      "output_cost_per_token": 6.4e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3.5-mini-instruct": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 5.2e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-3.5-vision-instruct": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 5.2e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-4": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-4-mini-instruct": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-4-multimodal-instruct": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 3.2e-07,
      "context_length": 131072,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-4-mini-reasoning": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 3.2e-07,
      "context_length": 131072,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/Phi-4-reasoning": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/MAI-DS-R1": {
      "input_cost_per_token": 1.35e-06,
      "output_cost_per_token": 5.4e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3.2": {
      "input_cost_per_token": 5.8e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3.2-speciale": {
      "input_cost_per_token": 5.8e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/deepseek-r1": {
      "input_cost_per_token": 1.35e-06,
      "output_cost_per_token": 5.4e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3": {
      "input_cost_per_token": 1.14e-06,
      "output_cost_per_token": 4.56e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/deepseek-v3-0324": {
      "input_cost_per_token": 1.14e-06,
      "output_cost_per_token": 4.56e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/global/grok-3": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/global/grok-3-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.27e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/grok-3": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/grok-3-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.27e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/grok-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/grok-4-fast-non-reasoning": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/grok-4-fast-reasoning": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/grok-code-fast-1": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/jais-30b-chat": {
      "input_cost_per_token": 0.0032,
      "output_cost_per_token": 0.00971,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/jamba-instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 70000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/ministral-3b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-large": {
      "input_cost_per_token": 4e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-large-2407": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-large-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-large-3": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 256000,
      "max_output_tokens": 8191,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-medium-2505": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 131072,
      "max_output_tokens": 8191,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-nemo": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 131072,
      "max_output_tokens": 4096,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-small": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "azure_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "azure_ai/mistral-small-2503": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "azure_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "babbage-002": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "text-completion-openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
      "input_cost_per_token": 2.23e-06,
      "output_cost_per_token": 7.55e-06,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/deepseek.v3.2": {
      "input_cost_per_token": 7.4e-07,
      "output_cost_per_token": 2.22e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 7.3e-07,
      "output_cost_per_token": 3.03e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 3.6e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-northeast-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 7.3e-07,
      "output_cost_per_token": 3.03e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3.03e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 3.18e-06,
      "output_cost_per_token": 4.2e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/deepseek.v3.2": {
      "input_cost_per_token": 7.4e-07,
      "output_cost_per_token": 2.22e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 7.1e-07,
      "output_cost_per_token": 2.94e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 3.6e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-south-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/deepseek.v3.2": {
      "input_cost_per_token": 7.4e-07,
      "output_cost_per_token": 2.22e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 3.6e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ap-southeast-3/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 3.05e-06,
      "output_cost_per_token": 4.03e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 6.9e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-north-1/deepseek.v3.2": {
      "input_cost_per_token": 7.4e-07,
      "output_cost_per_token": 2.22e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-north-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-north-1/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 3.6e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-central-1/anthropic.claude-instant-v1": {
      "input_cost_per_token": 2.48e-06,
      "output_cost_per_token": 8.38e-06,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-central-1/anthropic.claude-v1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-central-1/anthropic.claude-v2:1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-central-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-central-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 2.86e-06,
      "output_cost_per_token": 3.78e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3.2e-07,
      "output_cost_per_token": 6.5e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 3.45e-06,
      "output_cost_per_token": 4.55e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3.9e-07,
      "output_cost_per_token": 7.8e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-2/minimax.minimax-m2.1": {
      "input_cost_per_token": 4.7e-07,
      "output_cost_per_token": 1.86e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-2/qwen.qwen3-coder-next": {
      "input_cost_per_token": 7.8e-07,
      "output_cost_per_token": 1.86e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2.6e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
      "input_cost_per_token": 1.04e-05,
      "output_cost_per_token": 3.12e-05,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
      "input_cost_per_token": 5.9e-07,
      "output_cost_per_token": 9.1e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-south-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/eu-south-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 4.45e-06,
      "output_cost_per_token": 5.88e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.01e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/deepseek.v3.2": {
      "input_cost_per_token": 7.4e-07,
      "output_cost_per_token": 2.22e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3.6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 7.3e-07,
      "output_cost_per_token": 3.03e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 3.6e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/sa-east-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.44e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/anthropic.claude-instant-v1": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/anthropic.claude-v1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/anthropic.claude-v2:1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 2.65e-06,
      "output_cost_per_token": 3.5e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/deepseek.v3.2": {
      "input_cost_per_token": 6.2e-07,
      "output_cost_per_token": 1.85e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/minimax.minimax-m2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-1/qwen.qwen3-coder-next": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-2/deepseek.v3.2": {
      "input_cost_per_token": 6.2e-07,
      "output_cost_per_token": 1.85e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-2/minimax.minimax-m2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-2/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-2/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-east-2/qwen.qwen3-coder-next": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.nova-pro-v1:0": {
      "input_cost_per_token": 9.6e-07,
      "output_cost_per_token": 3.84e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-text-express-v1": {
      "input_cost_per_token": 1.3e-06,
      "output_cost_per_token": 1.7e-06,
      "context_length": 42000,
      "max_output_tokens": 8000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-text-lite-v1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 42000,
      "max_output_tokens": 4000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 42000,
      "max_output_tokens": 32000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3.6e-06,
      "output_cost_per_token": 1.8e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 2.65e-06,
      "output_cost_per_token": 3.5e-06,
      "context_length": 8000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.65e-06,
      "context_length": 8000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.nova-pro-v1:0": {
      "input_cost_per_token": 9.6e-07,
      "output_cost_per_token": 3.84e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-text-express-v1": {
      "input_cost_per_token": 1.3e-06,
      "output_cost_per_token": 1.7e-06,
      "context_length": 42000,
      "max_output_tokens": 8000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-text-lite-v1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 42000,
      "max_output_tokens": 4000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 42000,
      "max_output_tokens": 32000,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_cost_per_token": 3.6e-06,
      "output_cost_per_token": 1.8e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.6e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3.6e-06,
      "output_cost_per_token": 1.8e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 2.65e-06,
      "output_cost_per_token": 3.5e-06,
      "context_length": 8000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.65e-06,
      "context_length": 8000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 2.65e-06,
      "output_cost_per_token": 3.5e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/anthropic.claude-instant-v1": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/anthropic.claude-v1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/anthropic.claude-v2:1": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 100000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/deepseek.v3.2": {
      "input_cost_per_token": 6.2e-07,
      "output_cost_per_token": 1.85e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/minimax.minimax-m2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/moonshotai.kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/moonshotai.kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us-west-2/qwen.qwen3-coder-next": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/llama-3.3-70b": {
      "input_cost_per_token": 8.5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/llama3.1-70b": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/llama3.1-8b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/gpt-oss-120b": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 7.5e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/qwen-3-32b": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/zai-glm-4.6": {
      "input_cost_per_token": 2.25e-06,
      "output_cost_per_token": 2.75e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cerebras/zai-glm-4.7": {
      "input_cost_per_token": 2.25e-06,
      "output_cost_per_token": 2.75e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "cerebras",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chat-bison": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chat-bison-32k": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 32000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chat-bison-32k@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 32000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chat-bison@001": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chat-bison@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chatdolphin": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "nlp_cloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "chatgpt-4o-latest": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-5-haiku-20241022": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-5-haiku-latest": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-haiku-4-5-20251001": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-haiku-4-5": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-5-sonnet-20240620": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-5-sonnet-20241022": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-5-sonnet-latest": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-7-sonnet-20250219": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-7-sonnet-latest": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-haiku-20240307": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-opus-20240229": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-3-opus-latest": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-4-opus-20250514": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-4-sonnet-20250514": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-sonnet-4-5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-sonnet-4-5-20250929": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-sonnet-4-6": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us/claude-sonnet-4-6": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-1-20250805": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-20250514": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-5-20251101": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-5": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-6": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fast/claude-opus-4-6": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 0.00015,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us/claude-opus-4-6": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.75e-05,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fast/us/claude-opus-4-6": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 0.00015,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-opus-4-6-20260205": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fast/claude-opus-4-6-20260205": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 0.00015,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us/claude-opus-4-6-20260205": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.75e-05,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "claude-sonnet-4-20250514": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "anthropic",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-fp16": {
      "input_cost_per_token": 1.923e-06,
      "output_cost_per_token": 1.923e-06,
      "context_length": 3072,
      "max_output_tokens": 3072,
      "provider": "cloudflare",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-int8": {
      "input_cost_per_token": 1.923e-06,
      "output_cost_per_token": 1.923e-06,
      "context_length": 2048,
      "max_output_tokens": 2048,
      "provider": "cloudflare",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": {
      "input_cost_per_token": 1.923e-06,
      "output_cost_per_token": 1.923e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "cloudflare",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": {
      "input_cost_per_token": 1.923e-06,
      "output_cost_per_token": 1.923e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "cloudflare",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-bison": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-bison-32k@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-bison32k": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-bison@001": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-bison@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-gecko": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 2048,
      "max_output_tokens": 64,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-gecko-latest": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 2048,
      "max_output_tokens": 64,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-gecko@001": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 2048,
      "max_output_tokens": 64,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "code-gecko@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 2048,
      "max_output_tokens": 64,
      "provider": "vertex_ai-code-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "codechat-bison": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "codechat-bison-32k": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 32000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-code-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "codechat-bison-32k@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 32000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-code-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "codechat-bison@001": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "codechat-bison@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "codechat-bison@latest": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 6144,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-code-chat-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cohere.command-light-text-v14": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cohere.command-r-plus-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cohere.command-r-v1:0": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "cohere.command-text-v14": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "cohere",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-a-03-2025": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 256000,
      "max_output_tokens": 8000,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-light": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-nightly": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "cohere",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-r": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-r-08-2024": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-r-plus": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-r-plus-08-2024": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "command-r7b-12-2024": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 3.75e-08,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "cohere_chat",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "computer-use-preview": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "azure",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek-chat": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4.2e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek-reasoner": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4.2e-07,
      "context_length": 131072,
      "max_output_tokens": 65536,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 2.8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-coder": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 1000000,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-max": {
      "input_cost_per_token": 1.6e-06,
      "output_cost_per_token": 6.4e-06,
      "context_length": 30720,
      "max_output_tokens": 8192,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-plus": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 129024,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-plus-2025-01-25": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 129024,
      "max_output_tokens": 8192,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-plus-2025-04-28": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 129024,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-plus-2025-07-14": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 129024,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-turbo": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 129024,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-turbo-2024-11-01": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-turbo-2025-04-28": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 1000000,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwen-turbo-latest": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 1000000,
      "max_output_tokens": 16384,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dashscope/qwq-plus": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 98304,
      "max_output_tokens": 8192,
      "provider": "dashscope",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-3-7-sonnet": {
      "input_cost_per_token": 2.9999900000000002e-06,
      "output_cost_per_token": 1.5000020000000002e-05,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-haiku-4-5": {
      "input_cost_per_token": 1.00002e-06,
      "output_cost_per_token": 5.00003e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-opus-4": {
      "input_cost_per_token": 1.5000020000000002e-05,
      "output_cost_per_token": 7.500003000000001e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-opus-4-1": {
      "input_cost_per_token": 1.5000020000000002e-05,
      "output_cost_per_token": 7.500003000000001e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-opus-4-5": {
      "input_cost_per_token": 5.00003e-06,
      "output_cost_per_token": 2.5000010000000002e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-sonnet-4": {
      "input_cost_per_token": 2.9999900000000002e-06,
      "output_cost_per_token": 1.5000020000000002e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-sonnet-4-1": {
      "input_cost_per_token": 2.9999900000000002e-06,
      "output_cost_per_token": 1.5000020000000002e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-claude-sonnet-4-5": {
      "input_cost_per_token": 2.9999900000000002e-06,
      "output_cost_per_token": 1.5000020000000002e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gemini-2-5-flash": {
      "input_cost_per_token": 3.0001999999999996e-07,
      "output_cost_per_token": 2.49998e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gemini-2-5-pro": {
      "input_cost_per_token": 1.24999e-06,
      "output_cost_per_token": 9.999990000000002e-06,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gemma-3-12b": {
      "input_cost_per_token": 1.5000999999999998e-07,
      "output_cost_per_token": 5.0001e-07,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5": {
      "input_cost_per_token": 1.24999e-06,
      "output_cost_per_token": 9.999990000000002e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5-1": {
      "input_cost_per_token": 1.24999e-06,
      "output_cost_per_token": 9.999990000000002e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5-mini": {
      "input_cost_per_token": 2.4997000000000006e-07,
      "output_cost_per_token": 1.9999700000000004e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gpt-5-nano": {
      "input_cost_per_token": 4.998e-08,
      "output_cost_per_token": 3.9998000000000007e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gpt-oss-120b": {
      "input_cost_per_token": 1.5000999999999998e-07,
      "output_cost_per_token": 5.9997e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-gpt-oss-20b": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 3.0001999999999996e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-llama-2-70b-chat": {
      "input_cost_per_token": 5.0001e-07,
      "output_cost_per_token": 1.5000300000000002e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-llama-4-maverick": {
      "input_cost_per_token": 5.0001e-07,
      "output_cost_per_token": 1.5000300000000002e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
      "input_cost_per_token": 5.00003e-06,
      "output_cost_per_token": 1.5000020000000002e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-1-8b-instruct": {
      "input_cost_per_token": 1.5000999999999998e-07,
      "output_cost_per_token": 4.5003000000000007e-07,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-3-70b-instruct": {
      "input_cost_per_token": 5.0001e-07,
      "output_cost_per_token": 1.5000300000000002e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
      "input_cost_per_token": 1.00002e-06,
      "output_cost_per_token": 2.9999900000000002e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-mixtral-8x7b-instruct": {
      "input_cost_per_token": 5.0001e-07,
      "output_cost_per_token": 1.00002e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-mpt-30b-instruct": {
      "input_cost_per_token": 1.00002e-06,
      "output_cost_per_token": 1.00002e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "databricks/databricks-mpt-7b-instruct": {
      "input_cost_per_token": 5.0001e-07,
      "output_cost_per_token": 0,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "databricks",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "davinci-002": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "text-completion-openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Gryphe/MythoMax-L2-13b": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 9e-08,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/QwQ-32B": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen2.5-72B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3.9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen2.5-7B-Instruct": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "deepinfra",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-14B": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-235B-A22B": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 5.4e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.9e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-30B-A3B": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 2.9e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-32B": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2.8e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
      "input_cost_per_token": 2.9e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 1.4e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 1.4e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 7.5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 7.5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/allenai/olmOCR-7B-0725-FP8": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/anthropic/claude-3-7-sonnet-latest": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/anthropic/claude-4-opus": {
      "input_cost_per_token": 1.65e-05,
      "output_cost_per_token": 8.25e-05,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/anthropic/claude-4-sonnet": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 2.15e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 2.7e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Turbo": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3": {
      "input_cost_per_token": 3.8e-07,
      "output_cost_per_token": 8.9e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3-0324": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 2.16e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 2.16e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/google/gemini-2.0-flash-001": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1000000,
      "max_output_tokens": 1000000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/google/gemini-2.5-flash": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1000000,
      "max_output_tokens": 1000000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/google/gemini-2.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1000000,
      "max_output_tokens": 1000000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/google/gemma-3-12b-it": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/google/gemma-3-27b-it": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 1.6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/google/gemma-3-4b-it": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct": {
      "input_cost_per_token": 4.9e-08,
      "output_cost_per_token": 4.9e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.2-3B-Instruct": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 2e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct": {
      "input_cost_per_token": 2.3e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 3.9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 1048576,
      "max_output_tokens": 1048576,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 327680,
      "max_output_tokens": 327680,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-Guard-3-8B": {
      "input_cost_per_token": 5.5e-08,
      "output_cost_per_token": 5.5e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Llama-Guard-4-12B": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 1.8e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 6e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2.8e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 3e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/microsoft/WizardLM-2-8x22B": {
      "input_cost_per_token": 4.8e-07,
      "output_cost_per_token": 4.8e-07,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/microsoft/phi-4": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 1.4e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mistral-Nemo-Instruct-2407": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct-0905": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/openai/gpt-oss-120b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4.5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/openai/gpt-oss-20b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepinfra/zai-org/GLM-4.5": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "deepinfra",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek/deepseek-chat": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4.2e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek/deepseek-coder": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 2.8e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek/deepseek-r1": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek/deepseek-reasoner": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4.2e-07,
      "context_length": 131072,
      "max_output_tokens": 65536,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 2.8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek/deepseek-v3": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1.1e-06,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek/deepseek-v3.2": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "deepseek",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek.v3-v1:0": {
      "input_cost_per_token": 5.8e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 163840,
      "max_output_tokens": 81920,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "deepseek.v3.2": {
      "input_cost_per_token": 6.2e-07,
      "output_cost_per_token": 1.85e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "dolphin": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "nlp_cloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.amazon.nova-lite-v1:0": {
      "input_cost_per_token": 7.8e-08,
      "output_cost_per_token": 3.12e-07,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.amazon.nova-micro-v1:0": {
      "input_cost_per_token": 4.6e-08,
      "output_cost_per_token": 1.84e-07,
      "context_length": 128000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.amazon.nova-pro-v1:0": {
      "input_cost_per_token": 1.05e-06,
      "output_cost_per_token": 4.2e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 5.5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-1-20250805-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-20250514-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.meta.llama3-2-1b-instruct-v1:0": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 1.3e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.meta.llama3-2-3b-instruct-v1:0": {
      "input_cost_per_token": 1.9e-07,
      "output_cost_per_token": 1.9e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.mistral.pixtral-large-2502-v1:0": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-4.1b-to-16b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-56b-to-176b": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-above-16b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-embedding-150m-to-350m": {
      "input_cost_per_token": 1.6e-08,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai-embedding-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-embedding-up-to-150m": {
      "input_cost_per_token": 8e-09,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai-embedding-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-moe-up-to-56b": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks-ai-up-to-4b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 128000,
      "max_output_tokens": 20480,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 160000,
      "max_output_tokens": 160000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 128000,
      "max_output_tokens": 20480,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1": {
      "input_cost_per_token": 5.6e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus": {
      "input_cost_per_token": 5.6e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p2": {
      "input_cost_per_token": 5.6e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v2": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 128000,
      "max_output_tokens": 96000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5-air": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 128000,
      "max_output_tokens": 96000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p6": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 202800,
      "max_output_tokens": 202800,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p7": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 202800,
      "max_output_tokens": 202800,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2p5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m2p1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 204800,
      "max_output_tokens": 204800,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-large": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/glm-4p7": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 202800,
      "max_output_tokens": 202800,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/kimi-k2p5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/minimax-m2p1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 204800,
      "max_output_tokens": 204800,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "friendliai/meta-llama-3.1-70b-instruct": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "friendliai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "friendliai/meta-llama-3.1-8b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "friendliai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ft:babbage-002": {
      "input_cost_per_token": 1.6e-06,
      "output_cost_per_token": 1.6e-06,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "text-completion-openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 2e-07,
      "batch_output_cost": 2e-07,
      "source": "litellm"
    },
    "ft:davinci-002": {
      "input_cost_per_token": 1.2e-05,
      "output_cost_per_token": 1.2e-05,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "text-completion-openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 1e-06,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 1.5e-06,
      "batch_output_cost": 3e-06,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo-0125": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo-0613": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ft:gpt-3.5-turbo-1106": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ft:gpt-4-0613": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ft:gpt-4o-2024-08-06": {
      "input_cost_per_token": 3.75e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-06,
      "batch_input_cost": 1.875e-06,
      "batch_output_cost": 7.5e-06,
      "source": "litellm"
    },
    "ft:gpt-4o-2024-11-20": {
      "input_cost_per_token": 3.75e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ft:gpt-4o-mini-2024-07-18": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 1.5e-07,
      "batch_output_cost": 6e-07,
      "source": "litellm"
    },
    "ft:gpt-4.1-2025-04-14": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-07,
      "batch_input_cost": 1.5e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "ft:gpt-4.1-mini-2025-04-14": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 3.2e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 4e-07,
      "batch_output_cost": 1.6e-06,
      "source": "litellm"
    },
    "ft:gpt-4.1-nano-2025-04-14": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 1e-07,
      "batch_output_cost": 4e-07,
      "source": "litellm"
    },
    "ft:o4-mini-2025-04-16": {
      "input_cost_per_token": 4e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-06,
      "batch_input_cost": 2e-06,
      "batch_output_cost": 8e-06,
      "source": "litellm"
    },
    "gemini-1.0-pro": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 32760,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.0-pro-001": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 32760,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.0-pro-002": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 32760,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.0-pro-vision": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16384,
      "max_output_tokens": 2048,
      "provider": "vertex_ai-vision-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.0-pro-vision-001": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16384,
      "max_output_tokens": 2048,
      "provider": "vertex_ai-vision-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.0-ultra": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 8192,
      "max_output_tokens": 2048,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.0-ultra-001": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 8192,
      "max_output_tokens": 2048,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-flash": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-flash-001": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-flash-002": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-flash-exp-0827": {
      "input_cost_per_token": 4.688e-09,
      "output_cost_per_token": 4.6875e-09,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-flash-preview-0514": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 4.6875e-09,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-pro-001": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-pro-002": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-pro-preview-0215": {
      "input_cost_per_token": 7.8125e-08,
      "output_cost_per_token": 3.125e-07,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-pro-preview-0409": {
      "input_cost_per_token": 7.8125e-08,
      "output_cost_per_token": 3.125e-07,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-1.5-pro-preview-0514": {
      "input_cost_per_token": 7.8125e-08,
      "output_cost_per_token": 3.125e-07,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash-001": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash-exp": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash-lite": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash-lite-001": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash-live-preview-04-09": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-flash-preview-image-generation": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.0-pro-exp-02-05": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.125e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-lite": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-09-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-live-2.5-flash-preview-native-audio-09-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-lite-preview-06-17": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-04-17": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-preview-05-20": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-3-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "gemini-3.1-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "gemini-3.1-pro-preview-customtools": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "vertex_ai/gemini-3-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "vertex_ai/gemini-3-flash-preview": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/gemini-3.1-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "vertex_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "vertex_ai/gemini-3.1-pro-preview-customtools": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "vertex_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "gemini-2.5-pro-exp-03-25": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-03-25": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-05-06": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-06-05": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-pro-preview-tts": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-robotics-er-1.5-preview": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-robotics-er-1.5-preview": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-computer-use-preview-10-2025": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-pro": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 32760,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-language-models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-pro-vision": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16384,
      "max_output_tokens": 2048,
      "provider": "vertex_ai-vision-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash-001": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash-002": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-flash-latest": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro": {
      "input_cost_per_token": 3.5e-06,
      "output_cost_per_token": 1.05e-05,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-001": {
      "input_cost_per_token": 3.5e-06,
      "output_cost_per_token": 1.05e-05,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-002": {
      "input_cost_per_token": 3.5e-06,
      "output_cost_per_token": 1.05e-05,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-exp-0801": {
      "input_cost_per_token": 3.5e-06,
      "output_cost_per_token": 1.05e-05,
      "context_length": 2097152,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-1.5-pro-latest": {
      "input_cost_per_token": 3.5e-06,
      "output_cost_per_token": 1.05e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-001": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-lite": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-live-001": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-preview-image-generation": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-lite": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-lite-preview-09-2025": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-09-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-flash-latest": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-flash-lite-latest": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-lite-preview-06-17": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-04-17": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-preview-05-20": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-computer-use-preview-10-2025": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 64000,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-3-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "gemini/gemini-3-flash-preview": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-3.1-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "gemini/gemini-3.1-pro-preview-customtools": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "gemini-3-flash-preview": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "vertex_ai-language-models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-05-06": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-06-05": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-pro-preview-tts": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-gemma-2-27b-it": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.05e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-gemma-2-9b-it": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.05e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-pro": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.05e-06,
      "context_length": 32760,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-pro-vision": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.05e-06,
      "context_length": 30720,
      "max_output_tokens": 2048,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/anthropic/claude-opus-4.5": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/anthropic/claude-sonnet-4.5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/anthropic/claude-sonnet-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/anthropic/claude-opus-4": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/openai/gpt-5.2": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/openai/gpt-5.1": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/openai/gpt-5": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 409600,
      "max_output_tokens": 32000,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/openai/gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/openai/gpt-4o-mini": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/deepseek-ai/DeepSeek-V3.2": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 163840,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/deepseek-ai/DeepSeek-V3-0324": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 163840,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/google/gemini-3-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/google/gemini-3-flash-preview": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/moonshotai/Kimi-K2-Thinking": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/MiniMaxAI/MiniMax-M2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 196608,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/Qwen/Qwen3-VL-235B-A22B-Instruct-FP8": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.4e-06,
      "context_length": 262144,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gmi/zai-org/GLM-4.7-FP8": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 202752,
      "max_output_tokens": 16384,
      "provider": "gmi",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "google.gemma-3-12b-it": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 2.9e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "google.gemma-3-27b-it": {
      "input_cost_per_token": 2.3e-07,
      "output_cost_per_token": 3.8e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "google.gemma-3-4b-it": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.amazon.nova-2-lite-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-0125": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-0301": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-0613": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4097,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-1106": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-16k": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-16k-0613": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-instruct": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "text-completion-openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-3.5-turbo-instruct-0914": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 4097,
      "provider": "text-completion-openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-0125-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-0314": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-0613": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-1106-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-1106-vision-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-32k": {
      "input_cost_per_token": 6e-05,
      "output_cost_per_token": 0.00012,
      "context_length": 32768,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-32k-0314": {
      "input_cost_per_token": 6e-05,
      "output_cost_per_token": 0.00012,
      "context_length": 32768,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-32k-0613": {
      "input_cost_per_token": 6e-05,
      "output_cost_per_token": 0.00012,
      "context_length": 32768,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-turbo": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-turbo-2024-04-09": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-turbo-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4-vision-preview": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4.1": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 4e-06,
      "source": "litellm"
    },
    "gpt-4.1-2025-04-14": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 4e-06,
      "source": "litellm"
    },
    "gpt-4.1-mini": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 2e-07,
      "batch_output_cost": 8e-07,
      "source": "litellm"
    },
    "gpt-4.1-mini-2025-04-14": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 2e-07,
      "batch_output_cost": 8e-07,
      "source": "litellm"
    },
    "gpt-4.1-nano": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 5e-08,
      "batch_output_cost": 2e-07,
      "source": "litellm"
    },
    "gpt-4.1-nano-2025-04-14": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 5e-08,
      "batch_output_cost": 2e-07,
      "source": "litellm"
    },
    "gpt-4.5-preview": {
      "input_cost_per_token": 7.5e-05,
      "output_cost_per_token": 0.00015,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.75e-05,
      "batch_input_cost": 3.75e-05,
      "batch_output_cost": 7.5e-05,
      "source": "litellm"
    },
    "gpt-4.5-preview-2025-02-27": {
      "input_cost_per_token": 7.5e-05,
      "output_cost_per_token": 0.00015,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3.75e-05,
      "batch_input_cost": 3.75e-05,
      "batch_output_cost": 7.5e-05,
      "source": "litellm"
    },
    "gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 1.25e-06,
      "batch_output_cost": 5e-06,
      "source": "litellm"
    },
    "gpt-4o-2024-05-13": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 2.5e-06,
      "batch_output_cost": 7.5e-06,
      "source": "litellm"
    },
    "gpt-4o-2024-08-06": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 1.25e-06,
      "batch_output_cost": 5e-06,
      "source": "litellm"
    },
    "gpt-4o-2024-11-20": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 1.25e-06,
      "batch_output_cost": 5e-06,
      "source": "litellm"
    },
    "gpt-4o-audio-preview": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-audio-preview-2024-10-01": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-audio-preview-2024-12-17": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-audio-preview-2025-06-03": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-audio": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-audio-2025-08-28": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-audio-mini": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-audio-mini-2025-10-06": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-audio-mini-2025-12-15": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-mini": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 7.5e-08,
      "batch_output_cost": 3e-07,
      "source": "litellm"
    },
    "gpt-4o-mini-2024-07-18": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 7.5e-08,
      "batch_output_cost": 3e-07,
      "source": "litellm"
    },
    "gpt-4o-mini-audio-preview": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-mini-realtime-preview": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-mini-search-preview": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 7.5e-08,
      "batch_output_cost": 3e-07,
      "source": "litellm"
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 7.5e-08,
      "batch_output_cost": 3e-07,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview-2024-10-01": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview-2024-12-17": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-realtime-preview-2025-06-03": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-4o-search-preview": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 1.25e-06,
      "batch_output_cost": 5e-06,
      "source": "litellm"
    },
    "gpt-4o-search-preview-2025-03-11": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 1.25e-06,
      "batch_output_cost": 5e-06,
      "source": "litellm"
    },
    "gpt-5": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5.1": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5.1-2025-11-13": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5.1-chat-latest": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5.2": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5.2-2025-12-11": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5.2-chat-latest": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-2025-08-07": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-chat": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-chat-latest": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-mini-2025-08-07": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-nano": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-nano-2025-08-07": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-realtime": {
      "input_cost_per_token": 4e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 32000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-realtime-mini": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-realtime-2025-08-28": {
      "input_cost_per_token": 4e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 32000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 4e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3-opus": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 1024,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3.5-haiku": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 1024,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3.5-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1024,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/anthropic-claude-3.7-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1024,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/deepseek-r1-distill-llama-70b": {
      "input_cost_per_token": 9.9e-07,
      "output_cost_per_token": 9.9e-07,
      "context_length": 8000,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/llama3-8b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 512,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/llama3.3-70b-instruct": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 6.5e-07,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/mistral-nemo-instruct-2407": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 512,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/openai-o3": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 100000,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gradient_ai/openai-o3-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 100000,
      "max_output_tokens": 0,
      "provider": "gradient_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon-nova/nova-micro-v1": {
      "input_cost_per_token": 3.5e-08,
      "output_cost_per_token": 1.4e-07,
      "context_length": 128000,
      "max_output_tokens": 10000,
      "provider": "amazon_nova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon-nova/nova-lite-v1": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "amazon_nova",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon-nova/nova-premier-v1": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1.25e-05,
      "context_length": 1000000,
      "max_output_tokens": 10000,
      "provider": "amazon_nova",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "amazon-nova/nova-pro-v1": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 3.2e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "amazon_nova",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/llama-3.1-8b-instant": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/llama-3.3-70b-versatile": {
      "input_cost_per_token": 5.9e-07,
      "output_cost_per_token": 7.9e-07,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/gemma-7b-it": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/meta-llama/llama-guard-4-12b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "groq",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
      "input_cost_per_token": 1.1e-07,
      "output_cost_per_token": 3.4e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "groq",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 16384,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/openai/gpt-oss-120b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 32766,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/openai/gpt-oss-20b": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.75e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "groq/qwen/qwen3-32b": {
      "input_cost_per_token": 2.9e-07,
      "output_cost_per_token": 5.9e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "groq",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/Qwen/QwQ-32B": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/Qwen/Qwen3-235B-A22B": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2.5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "hyperbolic/moonshotai/Kimi-K2-Instruct": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "hyperbolic",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "j2-light": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "j2-mid": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 1e-05,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "j2-ultra": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 1.5e-05,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-1.5": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-1.5-large": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-1.5-large@001": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-1.5-mini": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-1.5-mini@001": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-large-1.6": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-large-1.7": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-mini-1.6": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jamba-mini-1.7": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ai21",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jp.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "jp.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 5.5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/deepseek-llama3.3-70b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/deepseek-r1-0528": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/deepseek-r1-671b": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/deepseek-v3-0324": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/hermes3-405b": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/hermes3-70b": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/hermes3-8b": {
      "input_cost_per_token": 2.5e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/lfm-40b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/lfm-7b": {
      "input_cost_per_token": 2.5e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama-4-scout-17b-16e-instruct": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 16384,
      "max_output_tokens": 8192,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-405b-instruct-fp8": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-70b-instruct-fp8": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-8b-instruct": {
      "input_cost_per_token": 2.5e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.2-11b-vision-instruct": {
      "input_cost_per_token": 1.5e-08,
      "output_cost_per_token": 2.5e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.2-3b-instruct": {
      "input_cost_per_token": 1.5e-08,
      "output_cost_per_token": 2.5e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/llama3.3-70b-instruct-fp8": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/qwen25-coder-32b-instruct": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "lambda_ai/qwen3-32b-fp8": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "lambda_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "luminous-base": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 3.3e-05,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "aleph_alpha",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "luminous-base-control": {
      "input_cost_per_token": 3.75e-05,
      "output_cost_per_token": 4.125e-05,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "aleph_alpha",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "luminous-extended": {
      "input_cost_per_token": 4.5e-05,
      "output_cost_per_token": 4.95e-05,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "aleph_alpha",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "luminous-extended-control": {
      "input_cost_per_token": 5.625e-05,
      "output_cost_per_token": 6.1875e-05,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "aleph_alpha",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "luminous-supreme": {
      "input_cost_per_token": 0.000175,
      "output_cost_per_token": 0.0001925,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "aleph_alpha",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "luminous-supreme-control": {
      "input_cost_per_token": 0.00021875,
      "output_cost_per_token": 0.000240625,
      "context_length": 2048,
      "max_output_tokens": 0,
      "provider": "aleph_alpha",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama2-13b-chat-v1": {
      "input_cost_per_token": 7.5e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama2-70b-chat-v1": {
      "input_cost_per_token": 1.95e-06,
      "output_cost_per_token": 2.56e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-1-405b-instruct-v1:0": {
      "input_cost_per_token": 5.32e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-1-70b-instruct-v1:0": {
      "input_cost_per_token": 9.9e-07,
      "output_cost_per_token": 9.9e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-1-8b-instruct-v1:0": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 2.2e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-2-11b-instruct-v1:0": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 3.5e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-2-1b-instruct-v1:0": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-2-3b-instruct-v1:0": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-2-90b-instruct-v1:0": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-3-70b-instruct-v1:0": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-70b-instruct-v1:0": {
      "input_cost_per_token": 2.65e-06,
      "output_cost_per_token": 3.5e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama3-8b-instruct-v1:0": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "meta.llama4-maverick-17b-instruct-v1:0": {
      "input_cost_per_token": 2.4e-07,
      "output_cost_per_token": 9.7e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 1.2e-07,
      "batch_output_cost": 4.85e-07,
      "source": "litellm"
    },
    "meta.llama4-scout-17b-instruct-v1:0": {
      "input_cost_per_token": 1.7e-07,
      "output_cost_per_token": 6.6e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 8.5e-08,
      "batch_output_cost": 3.3e-07,
      "source": "litellm"
    },
    "minimax.minimax-m2": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "minimax.minimax-m2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 196000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "minimax",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.1-lightning": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "minimax",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.5": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "minimax",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "minimax/MiniMax-M2.5-lightning": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "provider": "minimax",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "minimax/MiniMax-M2": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "minimax",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.magistral-small-2509": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.ministral-3-14b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.ministral-3-3b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.ministral-3-8b-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.mistral-7b-instruct-v0:2": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.mistral-large-2402-v1:0": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.mistral-large-2407-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 9e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.mistral-large-3-675b-instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.mistral-small-2402-v1:0": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.voxtral-mini-3b-2507": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral.voxtral-small-24b-2507": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/codestral-2405": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/codestral-2508": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/codestral-latest": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/codestral-mamba-latest": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2.5e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-medium-2507": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-small-2505": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-small-2507": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-small-latest": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/labs-devstral-small-2512": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-latest": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-medium-latest": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/devstral-2512": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/magistral-medium-2506": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 40000,
      "max_output_tokens": 40000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/magistral-medium-2509": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 40000,
      "max_output_tokens": 40000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/magistral-medium-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 40000,
      "max_output_tokens": 40000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/magistral-small-2506": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 40000,
      "max_output_tokens": 40000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/magistral-small-latest": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 40000,
      "max_output_tokens": 40000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-large-2402": {
      "input_cost_per_token": 4e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-large-2407": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 9e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-large-2411": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-large-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-large-3": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 256000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-medium": {
      "input_cost_per_token": 2.7e-06,
      "output_cost_per_token": 8.1e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-medium-2312": {
      "input_cost_per_token": 2.7e-06,
      "output_cost_per_token": 8.1e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-medium-2505": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 131072,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-medium-latest": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 131072,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-small": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-small-latest": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/mistral-tiny": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2.5e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/open-codestral-mamba": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2.5e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/open-mistral-7b": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2.5e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/open-mistral-nemo": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/open-mistral-nemo-2407": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/open-mixtral-8x22b": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 65336,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/open-mixtral-8x7b": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "mistral",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/pixtral-12b-2409": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/pixtral-large-2411": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "mistral/pixtral-large-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "mistral",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot.kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshotai.kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-k2-0711-preview": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-k2-0905-preview": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-k2-turbo-preview": {
      "input_cost_per_token": 1.15e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-latest-128k": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-latest-32k": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-latest-8k": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-thinking-preview": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/kimi-k2-thinking-turbo": {
      "input_cost_per_token": 1.15e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-128k": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-128k-0430": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-128k-vision-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-32k": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-32k-0430": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-32k-vision-preview": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-8k": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-8k-0430": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-8k-vision-preview": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "moonshot",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "moonshot/moonshot-v1-auto": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "moonshot",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "morph/morph-v3-fast": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 16000,
      "max_output_tokens": 16000,
      "provider": "morph",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "morph/morph-v3-large": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 1.9e-06,
      "context_length": 16000,
      "max_output_tokens": 16000,
      "provider": "morph",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/Qwen/QwQ-32B": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": {
      "input_cost_per_token": 1e-08,
      "output_cost_per_token": 3e-08,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": {
      "input_cost_per_token": 1e-08,
      "output_cost_per_token": 3e-08,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "input_cost_per_token": 3.75e-07,
      "output_cost_per_token": 3.75e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
      "input_cost_per_token": 2.5e-08,
      "output_cost_per_token": 2.5e-08,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 9e-08,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 7e-08,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/meta-llama/Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 3e-08,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/meta-llama/Llama-3.3-70B-Instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 2.9e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nscale/mistralai/mixtral-8x22b-instruct-v0.1": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "nscale",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nvidia.nemotron-nano-12b-v2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nvidia.nemotron-nano-9b-v2": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.3e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "nvidia.nemotron-nano-3-30b": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o1-2024-12-17": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o1-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o1-mini-2024-09-12": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o1-preview": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o1-preview-2024-09-12": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o3": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o3-2025-04-16": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o3-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o3-mini-2025-01-31": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o4-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "o4-mini-2025-04-16": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/meta.llama-3.1-405b-instruct": {
      "input_cost_per_token": 1.068e-05,
      "output_cost_per_token": 1.068e-05,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/meta.llama-3.2-90b-vision-instruct": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/meta.llama-3.3-70b-instruct": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 512000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/meta.llama-4-scout-17b-16e-instruct": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 192000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/xai.grok-3": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/xai.grok-3-fast": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/xai.grok-3-mini": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/xai.grok-3-mini-fast": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/xai.grok-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/cohere.command-latest": {
      "input_cost_per_token": 1.56e-06,
      "output_cost_per_token": 1.56e-06,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/cohere.command-a-03-2025": {
      "input_cost_per_token": 1.56e-06,
      "output_cost_per_token": 1.56e-06,
      "context_length": 256000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "oci/cohere.command-plus-latest": {
      "input_cost_per_token": 1.56e-06,
      "output_cost_per_token": 1.56e-06,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "oci",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openai.gpt-oss-120b-1:0": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openai.gpt-oss-20b-1:0": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openai.gpt-oss-safeguard-120b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openai.gpt-oss-safeguard-20b": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-3-haiku": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-opus-4": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-opus-4.1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-sonnet-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-opus-4.5": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 1000000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/anthropic/claude-haiku-4.5": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/bytedance/ui-tars-1.5-7b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 2048,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-chat": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 2.8e-07,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 2.8e-07,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-v3.2": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-v3.2-exp": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-r1": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 65336,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/deepseek/deepseek-r1-0528": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 2.15e-06,
      "context_length": 65336,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/google/gemini-2.0-flash-001": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/google/gemini-2.5-flash": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/google/gemini-2.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/google/gemini-3-pro-preview": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-07,
      "batch_input_cost": 1e-06,
      "batch_output_cost": 6e-06,
      "source": "litellm"
    },
    "openrouter/google/gemini-3-flash-preview": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/gryphe/mythomax-l2-13b": {
      "input_cost_per_token": 1.875e-06,
      "output_cost_per_token": 1.875e-06,
      "context_length": 8192,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mancer/weaver": {
      "input_cost_per_token": 5.625e-06,
      "output_cost_per_token": 5.625e-06,
      "context_length": 8000,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
      "input_cost_per_token": 5.9e-07,
      "output_cost_per_token": 7.9e-07,
      "context_length": 8192,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/minimax/minimax-m2": {
      "input_cost_per_token": 2.55e-07,
      "output_cost_per_token": 1.02e-06,
      "context_length": 204800,
      "max_output_tokens": 204800,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/devstral-2512": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 65536,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/ministral-3b-2512": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/ministral-8b-2512": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/ministral-14b-2512": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-large-2512": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-7b-instruct": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 1.3e-07,
      "context_length": 8192,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-large": {
      "input_cost_per_token": 8e-06,
      "output_cost_per_token": 2.4e-05,
      "context_length": 32000,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 6.5e-07,
      "context_length": 65536,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/moonshotai/kimi-k2.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-3.5-turbo": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 4095,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 16383,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4": {
      "input_cost_per_token": 3e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 8192,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4.1": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4.1-mini": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4.1-nano": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-chat": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-codex": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2-codex": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5-nano": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 5e-09,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2-chat": {
      "input_cost_per_token": 1.75e-06,
      "output_cost_per_token": 1.4e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-5.2-pro": {
      "input_cost_per_token": 2.1e-05,
      "output_cost_per_token": 0.000168,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-oss-120b": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/gpt-oss-20b": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/o1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/o3-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/openai/o3-mini-high": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 128000,
      "max_output_tokens": 65536,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 1.8e-07,
      "context_length": 33792,
      "max_output_tokens": 33792,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/qwen/qwen-vl-plus": {
      "input_cost_per_token": 2.1e-07,
      "output_cost_per_token": 6.3e-07,
      "context_length": 8192,
      "max_output_tokens": 2048,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/qwen/qwen3-coder": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 9.5e-07,
      "context_length": 262100,
      "max_output_tokens": 262100,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/qwen/qwen3-235b-a22b-2507": {
      "input_cost_per_token": 7.1e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/qwen/qwen3-235b-a22b-thinking-2507": {
      "input_cost_per_token": 1.1e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/switchpoint/router": {
      "input_cost_per_token": 8.5e-07,
      "output_cost_per_token": 3.4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
      "input_cost_per_token": 1.875e-06,
      "output_cost_per_token": 1.875e-06,
      "context_length": 6144,
      "max_output_tokens": 0,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/x-ai/grok-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.6": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.75e-06,
      "context_length": 202800,
      "max_output_tokens": 131000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.6:exacto": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 1.9e-06,
      "context_length": 202800,
      "max_output_tokens": 131000,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/xiaomi/mimo-v2-flash": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 2.9e-07,
      "context_length": 262144,
      "max_output_tokens": 16384,
      "provider": "openrouter",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0.0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.7": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 202752,
      "max_output_tokens": 64000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0.0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/z-ai/glm-4.7-flash": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0.0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "openrouter/minimax/minimax-m2.1": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 204000,
      "max_output_tokens": 64000,
      "provider": "openrouter",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0.0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
      "input_cost_per_token": 6.7e-07,
      "output_cost_per_token": 6.7e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
      "input_cost_per_token": 6.7e-07,
      "output_cost_per_token": 6.7e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
      "input_cost_per_token": 6.7e-07,
      "output_cost_per_token": 6.7e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Mistral-7B-Instruct-v0.3": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 127000,
      "max_output_tokens": 127000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Mistral-Nemo-Instruct-2407": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 1.3e-07,
      "context_length": 118000,
      "max_output_tokens": 118000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "ovhcloud",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Mixtral-8x7B-Instruct-v0.1": {
      "input_cost_per_token": 6.3e-07,
      "output_cost_per_token": 6.3e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Qwen2.5-Coder-32B-Instruct": {
      "input_cost_per_token": 8.7e-07,
      "output_cost_per_token": 8.7e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Qwen2.5-VL-72B-Instruct": {
      "input_cost_per_token": 9.1e-07,
      "output_cost_per_token": 9.1e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "ovhcloud",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/Qwen3-32B": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 2.3e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/gpt-oss-120b": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/gpt-oss-20b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.5e-07,
      "context_length": 131000,
      "max_output_tokens": 131000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/llava-v1.6-mistral-7b-hf": {
      "input_cost_per_token": 2.9e-07,
      "output_cost_per_token": 2.9e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "ovhcloud",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "ovhcloud/mamba-codestral-7B-v0.1": {
      "input_cost_per_token": 1.9e-07,
      "output_cost_per_token": 1.9e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "ovhcloud",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "palm/chat-bison": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "palm",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "palm/chat-bison-001": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "palm",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "palm/text-bison": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "palm",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "palm/text-bison-001": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "palm",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "palm/text-bison-safety-off": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "palm",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "palm/text-bison-safety-recitation-off": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "palm",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/codellama-34b-instruct": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.4e-06,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/codellama-70b-instruct": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.8e-06,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-2-70b-chat": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.8e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-70b-instruct": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-8b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 127072,
      "max_output_tokens": 127072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 127072,
      "max_output_tokens": 127072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 127072,
      "max_output_tokens": 127072,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/mistral-7b-instruct": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/mixtral-8x7b-instruct": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/pplx-70b-chat": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.8e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/pplx-70b-online": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 2.8e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/pplx-7b-chat": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/pplx-7b-online": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 2.8e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-deep-research": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-medium-chat": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-medium-online": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 1.8e-06,
      "context_length": 12000,
      "max_output_tokens": 12000,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-pro": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8000,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-reasoning": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-reasoning-pro": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-small-chat": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "perplexity/sonar-small-online": {
      "input_cost_per_token": 0,
      "output_cost_per_token": 2.8e-07,
      "context_length": 12000,
      "max_output_tokens": 12000,
      "provider": "perplexity",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-coder-480b-a35b-v1:0": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 262000,
      "max_output_tokens": 65536,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-235b-a22b-2507-v1:0": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 262144,
      "max_output_tokens": 131072,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-coder-30b-a3b-v1:0": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 131072,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-32b-v1:0": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-next-80b-a3b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-vl-235b-a22b": {
      "input_cost_per_token": 5.3e-07,
      "output_cost_per_token": 2.66e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "qwen.qwen3-coder-next": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-2-13b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-2-13b-chat": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-2-70b": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-2-70b-chat": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-2-7b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-2-7b-chat": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-3-70b": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-3-70b-instruct": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 2.75e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-3-8b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 8086,
      "max_output_tokens": 8086,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/meta/llama-3-8b-instruct": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 8086,
      "max_output_tokens": 8086,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/mistralai/mistral-7b-instruct-v0.2": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/mistralai/mistral-7b-v0.1": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/mistralai/mixtral-8x7b-instruct-v0.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-5": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicateopenai/gpt-oss-20b": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 3.6e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/anthropic/claude-4.5-haiku": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/ibm-granite/granite-3.3-8b-instruct": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/o4-mini": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/o1-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/o1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-4o-mini": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/qwen/qwen3-235b-a22b-instruct-2507": {
      "input_cost_per_token": 2.64e-07,
      "output_cost_per_token": 1.06e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/anthropic/claude-4-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/deepseek-ai/deepseek-v3": {
      "input_cost_per_token": 1.45e-06,
      "output_cost_per_token": 1.45e-06,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/anthropic/claude-3.7-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/anthropic/claude-3.5-haiku": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/anthropic/claude-3.5-sonnet": {
      "input_cost_per_token": 3.75e-06,
      "output_cost_per_token": 1.875e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/google/gemini-3-pro": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1.2e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/anthropic/claude-4.5-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-4.1": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-4.1-nano": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-4.1-mini": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-5-nano": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-5-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/google/gemini-2.5-flash": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 2.5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/openai/gpt-oss-120b": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/deepseek-ai/deepseek-v3.1": {
      "input_cost_per_token": 6.72e-07,
      "output_cost_per_token": 2.016e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/xai/grok-4": {
      "input_cost_per_token": 7.2e-06,
      "output_cost_per_token": 3.6e-05,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "replicate/deepseek-ai/deepseek-r1": {
      "input_cost_per_token": 3.75e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "replicate",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/DeepSeek-R1": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 7e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/DeepSeek-R1-Distill-Llama-70B": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 1.4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/DeepSeek-V3-0324": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4.5e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
      "input_cost_per_token": 6.3e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "sambanova",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Llama-4-Scout-17B-16E-Instruct": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.1-405B-Instruct": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.2-1B-Instruct": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.2-3B-Instruct": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 1.6e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-3.3-70B-Instruct": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Meta-Llama-Guard-3-8B": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/QwQ-32B": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Qwen2-Audio-7B-Instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 0.0001,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/Qwen3-32B": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/DeepSeek-V3.1": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4.5e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "sambanova/gpt-oss-120b": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 4.5e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "sambanova",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "text-bison32k": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "text-bison32k@002": {
      "input_cost_per_token": 1.25e-07,
      "output_cost_per_token": 1.25e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "text-unicorn": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 2.8e-05,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "text-unicorn@001": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 2.8e-05,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "vertex_ai-text-models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together-ai-21.1b-41b": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together-ai-4.1b-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together-ai-41.1b-80b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together-ai-8.1b-21b": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 1000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together-ai-81.1b-110b": {
      "input_cost_per_token": 1.8e-06,
      "output_cost_per_token": 1.8e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together-ai-up-to-4b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-06,
      "context_length": 262000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "input_cost_per_token": 6.5e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 256000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-235B-A22B-fp8-tput": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 40000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 256000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-R1": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 7e-06,
      "context_length": 128000,
      "max_output_tokens": 20480,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-R1-0528-tput": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-V3": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1.25e-06,
      "context_length": 65536,
      "max_output_tokens": 8192,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/deepseek-ai/DeepSeek-V3.1": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.7e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "input_cost_per_token": 8.8e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 8.5e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 5.9e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
      "input_cost_per_token": 3.5e-06,
      "output_cost_per_token": 3.5e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "input_cost_per_token": 8.8e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 1.8e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/moonshotai/Kimi-K2-Instruct": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/openai/gpt-oss-120b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/openai/gpt-oss-20b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/zai-org/GLM-4.5-Air-FP8": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.1e-06,
      "context_length": 128000,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/zai-org/GLM-4.6": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/zai-org/GLM-4.7": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/moonshotai/Kimi-K2.5": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 2.8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "together_ai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/moonshotai/Kimi-K2-Instruct-0905": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 262144,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 262144,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 262144,
      "max_output_tokens": 0,
      "provider": "together_ai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.amazon.nova-lite-v1:0": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.amazon.nova-micro-v1:0": {
      "input_cost_per_token": 3.5e-08,
      "output_cost_per_token": 1.4e-07,
      "context_length": 128000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.amazon.nova-premier-v1:0": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1.25e-05,
      "context_length": 1000000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.amazon.nova-pro-v1:0": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 3.2e-06,
      "context_length": 300000,
      "max_output_tokens": 10000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 5.5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-1-20250805-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "input_cost_per_token": 3.3e-06,
      "output_cost_per_token": 1.65e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "au.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 5.5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-20250514-v1:0": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_cost_per_token": 5.5e-06,
      "output_cost_per_token": 2.75e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "global.anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.anthropic.claude-opus-4-5-20251101-v1:0": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.anthropic.claude-sonnet-4-20250514-v1:0": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "bedrock_converse",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.deepseek.r1-v1:0": {
      "input_cost_per_token": 1.35e-06,
      "output_cost_per_token": 5.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.deepseek.v3.2": {
      "input_cost_per_token": 6.2e-07,
      "output_cost_per_token": 1.85e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "eu.deepseek.v3.2": {
      "input_cost_per_token": 7.4e-07,
      "output_cost_per_token": 2.22e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-1-405b-instruct-v1:0": {
      "input_cost_per_token": 5.32e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-1-70b-instruct-v1:0": {
      "input_cost_per_token": 9.9e-07,
      "output_cost_per_token": 9.9e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-1-8b-instruct-v1:0": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 2.2e-07,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-2-11b-instruct-v1:0": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 3.5e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-2-1b-instruct-v1:0": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-2-3b-instruct-v1:0": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-2-90b-instruct-v1:0": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama3-3-70b-instruct-v1:0": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "us.meta.llama4-maverick-17b-instruct-v1:0": {
      "input_cost_per_token": 2.4e-07,
      "output_cost_per_token": 9.7e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 1.2e-07,
      "batch_output_cost": 4.85e-07,
      "source": "litellm"
    },
    "us.meta.llama4-scout-17b-instruct-v1:0": {
      "input_cost_per_token": 1.7e-07,
      "output_cost_per_token": 6.6e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 8.5e-08,
      "batch_output_cost": 3.3e-07,
      "source": "litellm"
    },
    "us.mistral.pixtral-large-2502-v1:0": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "v0/v0-1.0-md": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "v0",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "v0/v0-1.5-lg": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 512000,
      "max_output_tokens": 512000,
      "provider": "v0",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "v0/v0-1.5-md": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "v0",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-14b": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 40960,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-235b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 40960,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-30b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 40960,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen-3-32b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 40960,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/alibaba/qwen3-coder": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 262144,
      "max_output_tokens": 66536,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/nova-lite": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.4e-07,
      "context_length": 300000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/nova-micro": {
      "input_cost_per_token": 3.5e-08,
      "output_cost_per_token": 1.4e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/nova-pro": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 3.2e-06,
      "context_length": 300000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/amazon/titan-embed-text-v2": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-haiku": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-opus": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 8e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-4-opus": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-4-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-5-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-5-sonnet-20241022": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-3-7-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-haiku-4.5": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.5": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.6": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-sonnet-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/anthropic/claude-sonnet-4.5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/command-a": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 256000,
      "max_output_tokens": 8000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/command-r": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/command-r-plus": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/cohere/embed-v4.0": {
      "input_cost_per_token": 1.2e-07,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/deepseek/deepseek-r1": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.19e-06,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
      "input_cost_per_token": 7.5e-07,
      "output_cost_per_token": 9.9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/deepseek/deepseek-v3": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.0-flash": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.5-flash": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1000000,
      "max_output_tokens": 65536,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemini-2.5-pro": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65536,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/google/gemma-2-9b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/inception/mercury-coder-small": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 32000,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3-70b": {
      "input_cost_per_token": 5.9e-07,
      "output_cost_per_token": 7.9e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3-8b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.1-70b": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.1-8b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 131000,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-11b": {
      "input_cost_per_token": 1.6e-07,
      "output_cost_per_token": 1.6e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-1b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-3b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.2-90b": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-3.3-70b": {
      "input_cost_per_token": 7.2e-07,
      "output_cost_per_token": 7.2e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-4-maverick": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/meta/llama-4-scout": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/codestral": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 256000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/codestral-embed": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/devstral-small": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/magistral-medium": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 128000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/magistral-small": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 128000,
      "max_output_tokens": 64000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/ministral-3b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/ministral-8b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-embed": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 0,
      "context_length": 0,
      "max_output_tokens": 0,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-large": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 32000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-saba-24b": {
      "input_cost_per_token": 7.9e-07,
      "output_cost_per_token": 7.9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mistral-small": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/mixtral-8x22b-instruct": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 65536,
      "max_output_tokens": 2048,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/pixtral-12b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/mistral/pixtral-large": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/moonshotai/kimi-k2": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/morph/morph-v3-fast": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 32768,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/morph/morph-v3-large": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 1.9e-06,
      "context_length": 32768,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 16385,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct": {
      "input_cost_per_token": 1.5e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 8192,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4-turbo": {
      "input_cost_per_token": 1e-05,
      "output_cost_per_token": 3e-05,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4.1": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4.1-mini": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4.1-nano": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1047576,
      "max_output_tokens": 32768,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/gpt-4o-mini": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 16384,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 6e-05,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o3": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o3-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/openai/o4-mini": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.4e-06,
      "context_length": 200000,
      "max_output_tokens": 100000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 2.75e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 1e-06,
      "context_length": 127000,
      "max_output_tokens": 8000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar-pro": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 127000,
      "max_output_tokens": 8000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 127000,
      "max_output_tokens": 8000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/vercel/v0-1.0-md": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/vercel/v0-1.5-md": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 128000,
      "max_output_tokens": 32768,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-2": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 131072,
      "max_output_tokens": 4000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-2-vision": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "vercel_ai_gateway",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3-fast": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3-mini": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-3-mini-fast": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/xai/grok-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/zai/glm-4.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/zai/glm-4.5-air": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.1e-06,
      "context_length": 128000,
      "max_output_tokens": 96000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vercel_ai_gateway/zai/glm-4.6": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "vercel_ai_gateway",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-haiku": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-haiku@20241022": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-haiku-4-5@20251001": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet-v2": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet-v2@20241022": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-7-sonnet@20250219": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-haiku": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-haiku@20240307": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-opus": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-opus@20240229": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-sonnet": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-3-sonnet@20240229": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 4096,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 7.5e-06,
      "batch_output_cost": 3.75e-05,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-1@20250805": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 7.5e-06,
      "batch_output_cost": 3.75e-05,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-5": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-5@20251101": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-6": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4-6@default": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4-5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 1.5e-06,
      "batch_output_cost": 7.5e-06,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4-6": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4-5@20250929": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 1.5e-06,
      "batch_output_cost": 7.5e-06,
      "source": "litellm"
    },
    "vertex_ai/claude-opus-4@20250514": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "context_length": 200000,
      "max_output_tokens": 32000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4@20250514": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 1000000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistralai/codestral-2@001": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/codestral-2": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/codestral-2@001": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistralai/codestral-2": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/codestral-2501": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/codestral@2405": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/codestral@latest": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
      "input_cost_per_token": 1.35e-06,
      "output_cost_per_token": 5.4e-06,
      "context_length": 163840,
      "max_output_tokens": 32768,
      "provider": "vertex_ai-deepseek_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
      "input_cost_per_token": 5.6e-07,
      "output_cost_per_token": 1.68e-06,
      "context_length": 163840,
      "max_output_tokens": 32768,
      "provider": "vertex_ai-deepseek_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 2.8e-07,
      "batch_output_cost": 8.4e-07,
      "source": "litellm"
    },
    "vertex_ai/deepseek-ai/deepseek-r1-0528-maas": {
      "input_cost_per_token": 1.35e-06,
      "output_cost_per_token": 5.4e-06,
      "context_length": 65336,
      "max_output_tokens": 8192,
      "provider": "vertex_ai-deepseek_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vertex_ai-ai21_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-large": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vertex_ai-ai21_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-large@001": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vertex_ai-ai21_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-mini": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vertex_ai-ai21_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5-mini@001": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vertex_ai-ai21_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-3.1-405b-instruct-maas": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.6e-05,
      "context_length": 128000,
      "max_output_tokens": 2048,
      "provider": "vertex_ai-llama_models",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.15e-06,
      "context_length": 1000000,
      "max_output_tokens": 1000000,
      "provider": "vertex_ai-llama_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.15e-06,
      "context_length": 1000000,
      "max_output_tokens": 1000000,
      "provider": "vertex_ai-llama_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 10000000,
      "max_output_tokens": 10000000,
      "provider": "vertex_ai-llama_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 10000000,
      "max_output_tokens": 10000000,
      "provider": "vertex_ai-llama_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/minimaxai/minimax-m2-maas": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 196608,
      "max_output_tokens": 196608,
      "provider": "vertex_ai-minimax_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/moonshotai/kimi-k2-thinking-maas": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "vertex_ai-moonshot_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/zai-org/glm-4.7-maas": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-zai_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/zai-org/glm-5-maas": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3.2e-06,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-zai_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-medium-3": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-medium-3@001": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistralai/mistral-medium-3": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistralai/mistral-medium-3@001": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-large-2411": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-large@2407": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-large@2411-001": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-large@latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 6e-06,
      "context_length": 128000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-nemo@2407": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-nemo@latest": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-small-2503": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/mistral-small-2503@001": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 3e-06,
      "context_length": 32000,
      "max_output_tokens": 8191,
      "provider": "vertex_ai-mistral_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/openai/gpt-oss-120b-maas": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "vertex_ai-openai_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/openai/gpt-oss-20b-maas": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "vertex_ai-openai_models",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 262144,
      "max_output_tokens": 16384,
      "provider": "vertex_ai-qwen_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 4e-06,
      "context_length": 262144,
      "max_output_tokens": 32768,
      "provider": "vertex_ai-qwen_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "vertex_ai-qwen_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "vertex_ai-qwen_models",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/openai/gpt-oss-120b": {
      "input_cost_per_token": 0.015,
      "output_cost_per_token": 0.06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/openai/gpt-oss-20b": {
      "input_cost_per_token": 0.005,
      "output_cost_per_token": 0.02,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/zai-org/GLM-4.5": {
      "input_cost_per_token": 0.055,
      "output_cost_per_token": 0.2,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "input_cost_per_token": 0.01,
      "output_cost_per_token": 0.01,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "input_cost_per_token": 0.1,
      "output_cost_per_token": 0.15,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "input_cost_per_token": 0.01,
      "output_cost_per_token": 0.01,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
      "input_cost_per_token": 0.022,
      "output_cost_per_token": 0.022,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/deepseek-ai/DeepSeek-V3.1": {
      "input_cost_per_token": 0.055,
      "output_cost_per_token": 0.165,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
      "input_cost_per_token": 0.135,
      "output_cost_per_token": 0.54,
      "context_length": 161000,
      "max_output_tokens": 161000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
      "input_cost_per_token": 0.114,
      "output_cost_per_token": 0.275,
      "context_length": 161000,
      "max_output_tokens": 161000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
      "input_cost_per_token": 0.071,
      "output_cost_per_token": 0.071,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_cost_per_token": 0.017,
      "output_cost_per_token": 0.066,
      "context_length": 64000,
      "max_output_tokens": 64000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
      "input_cost_per_token": 0.008,
      "output_cost_per_token": 0.035,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "wandb",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-3-8b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 1024,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-large": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/bigscience/mt0-xxl-13b": {
      "input_cost_per_token": 0.0005,
      "output_cost_per_token": 0.002,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/core42/jais-13b-chat": {
      "input_cost_per_token": 0.0005,
      "output_cost_per_token": 0.002,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/google/flan-t5-xl-3b": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-13b-chat-v2": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-13b-instruct-v2": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-3-3-8b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-4-h-small": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 20480,
      "max_output_tokens": 20480,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-guardian-3-2-2b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-guardian-3-3-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-ttm-1024-96-r2": {
      "input_cost_per_token": 3.8e-07,
      "output_cost_per_token": 3.8e-07,
      "context_length": 512,
      "max_output_tokens": 512,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-ttm-1536-96-r2": {
      "input_cost_per_token": 3.8e-07,
      "output_cost_per_token": 3.8e-07,
      "context_length": 512,
      "max_output_tokens": 512,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-ttm-512-96-r2": {
      "input_cost_per_token": 3.8e-07,
      "output_cost_per_token": 3.8e-07,
      "context_length": 512,
      "max_output_tokens": 512,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/ibm/granite-vision-3-2-2b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-11b-vision-instruct": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 3.5e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-1b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-3b-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-2-90b-vision-instruct": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 2e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-3-3-70b-instruct": {
      "input_cost_per_token": 7.1e-07,
      "output_cost_per_token": 7.1e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-4-maverick-17b": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 1.4e-06,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/meta-llama/llama-guard-3-11b-vision": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 3.5e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-medium-2505": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-small-2503": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/mistralai/pixtral-12b-2409": {
      "input_cost_per_token": 3.5e-07,
      "output_cost_per_token": 3.5e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "watsonx",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/openai/gpt-oss-120b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "watsonx/sdaia/allam-1-13b-instruct": {
      "input_cost_per_token": 1.8e-06,
      "output_cost_per_token": 1.8e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "watsonx",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-2": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-2-1212": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-2-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-2-vision": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-2-vision-1212": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-2-vision-latest": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-beta": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-fast-beta": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-fast-latest": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 2.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-06,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-latest": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 7.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-mini": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-mini-beta": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-mini-fast": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-mini-fast-beta": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-mini-fast-latest": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 4e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-3-mini-latest": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 7.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-fast-reasoning": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-fast-non-reasoning": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-0709": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-latest": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-reasoning": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-reasoning-latest": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-non-reasoning": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-4-1-fast-non-reasoning-latest": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 2000000.0,
      "max_output_tokens": 2000000.0,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-beta": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-code-fast": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-code-fast-1": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-code-fast-1-0825": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "xai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "xai/grok-vision-beta": {
      "input_cost_per_token": 5e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "xai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai.glm-4.7": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "bedrock_converse",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.7": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.6": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 200000,
      "max_output_tokens": 128000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.5v": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "zai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.5-x": {
      "input_cost_per_token": 2.2e-06,
      "output_cost_per_token": 8.9e-06,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.5-air": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1.1e-06,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4.5-airx": {
      "input_cost_per_token": 1.1e-06,
      "output_cost_per_token": 4.5e-06,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "zai/glm-4-32b-0414-128k": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "zai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
      "input_cost_per_token": 4.5e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/chronos-hermes-13b-v2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-python": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-python": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-python": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-python": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/code-qwen-1p5-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-2b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dbrx-instruct": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-1b-base": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-33b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base-v1p5": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2p5": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/devstral-small-2505": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-21b-a3b-pt": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-300b-a47b-pt": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/fare-20b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v1": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firellava-13b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/firesearch-ocr-v6": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-controlnet-union": {
      "input_cost_per_token": 1e-09,
      "output_cost_per_token": 1e-09,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-2b-it": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b-it": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gemma2-9b-it": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5v": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/hermes-2-pro-mistral-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-38b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-78b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kat-coder": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-2-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b-chat": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b-chat": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 2048,
      "max_output_tokens": 2048,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b-chat": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct-hf": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b-instruct-hf": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct-long": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct-1b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llamaguard-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/llava-yi-34b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m1-80k": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m2": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-4k": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v0p2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v3": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-v0p2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 256000,
      "max_output_tokens": 256000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-small-24b-instruct-2501": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/mythomax-l2-13b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nemotron-nano-v2-12b-vl": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-capybara-7b-v1p9": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-yi-34b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-13b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-70b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openchat-3p5-0106-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2-mistral-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2p5-mistral-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/openorca-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phi-2-3b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 2048,
      "max_output_tokens": 2048,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-vision-128k-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32064,
      "max_output_tokens": 32064,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-python-v1": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v1": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v2": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/pythia-12b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 2048,
      "max_output_tokens": 2048,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-qwq-32b-preview": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-14b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen1p5-72b-chat": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-7b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-2b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-72b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-7b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-0p5b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-14b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-1p5b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-7b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b-instruct": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-math-72b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-0p6b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-14b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-8b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 40960,
      "max_output_tokens": 40960,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-thinking": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
      "input_cost_per_token": 2.2e-07,
      "output_cost_per_token": 8.8e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-32b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-8b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/qwq-32b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/rolm-ocr": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 128000,
      "max_output_tokens": 128000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/stablecode-3b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-16b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-15b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-3b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/toppy-m-7b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 200000,
      "max_output_tokens": 200000,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-chat": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/yi-6b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 4096,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "fireworks_ai/accounts/fireworks/models/zephyr-7b-beta": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "fireworks_ai",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.2": {
      "input_cost_per_token": 2.69e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 163840,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.345e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/minimax/minimax-m2.1": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 204800,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.7": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 204800,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/xiaomimimo/mimo-v2-flash": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 262144,
      "max_output_tokens": 32000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 2e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/autoglm-phone-9b-multilingual": {
      "input_cost_per_token": 3.5e-08,
      "output_cost_per_token": 1.38e-07,
      "context_length": 65536,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/moonshotai/kimi-k2-thinking": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/minimax/minimax-m2": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 204800,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/paddlepaddle/paddleocr-vl": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 2e-08,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.2-exp": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 4.1e-07,
      "context_length": 163840,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-235b-a22b-thinking": {
      "input_cost_per_token": 9.8e-07,
      "output_cost_per_token": 3.95e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.6v": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 9e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 5.5e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.6": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 204800,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/kwaipilot/kat-coder-pro": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "context_length": 256000,
      "max_output_tokens": 128000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 6e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-next-80b-a3b-instruct": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-next-80b-a3b-thinking": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-ocr": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 3e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.1-terminus": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.35e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-235b-a22b-instruct": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.5e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-max": {
      "input_cost_per_token": 2.11e-06,
      "output_cost_per_token": 8.45e-06,
      "context_length": 262144,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/skywork/r1v4-lite": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 6e-07,
      "context_length": 262144,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3.1": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.35e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/moonshotai/kimi-k2-0905": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 262144,
      "max_output_tokens": 262144,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-coder-480b-a35b-instruct": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.3e-06,
      "context_length": 262144,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-coder-30b-a3b-instruct": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.7e-07,
      "context_length": 160000,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/openai/gpt-oss-120b": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 2.5e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/moonshotai/kimi-k2-instruct": {
      "input_cost_per_token": 5.7e-07,
      "output_cost_per_token": 2.3e-06,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3-0324": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 1.12e-06,
      "context_length": 163840,
      "max_output_tokens": 163840,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.35e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.5": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 131072,
      "max_output_tokens": 98304,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-235b-a22b-thinking-2507": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3.1-8b-instruct": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 16384,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/google/gemma-3-12b-it": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 1e-07,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.5v": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 1.8e-06,
      "context_length": 65536,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.1e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/openai/gpt-oss-20b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.5e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-235b-a22b-instruct-2507": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 5.8e-07,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-distill-qwen-14b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 32768,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3.3-70b-instruct": {
      "input_cost_per_token": 1.35e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 131072,
      "max_output_tokens": 120000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen-2.5-72b-instruct": {
      "input_cost_per_token": 3.8e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 32000,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/mistralai/mistral-nemo": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.7e-07,
      "context_length": 60288,
      "max_output_tokens": 16000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/minimaxai/minimax-m1-80k": {
      "input_cost_per_token": 5.5e-07,
      "output_cost_per_token": 2.2e-06,
      "context_length": 1000000,
      "max_output_tokens": 40000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-0528": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 163840,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3.5e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-distill-qwen-32b": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 3e-07,
      "context_length": 64000,
      "max_output_tokens": 32000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3-8b-instruct": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 4e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/microsoft/wizardlm-2-8x22b": {
      "input_cost_per_token": 6.2e-07,
      "output_cost_per_token": 6.2e-07,
      "context_length": 65535,
      "max_output_tokens": 8000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-0528-qwen3-8b": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 9e-08,
      "context_length": 128000,
      "max_output_tokens": 32000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-distill-llama-70b": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3-70b-instruct": {
      "input_cost_per_token": 5.1e-07,
      "output_cost_per_token": 7.4e-07,
      "context_length": 8192,
      "max_output_tokens": 8000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-235b-a22b-fp8": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 40960,
      "max_output_tokens": 20000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8": {
      "input_cost_per_token": 2.7e-07,
      "output_cost_per_token": 8.5e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-4-scout-17b-16e-instruct": {
      "input_cost_per_token": 1.8e-07,
      "output_cost_per_token": 5.9e-07,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/nousresearch/hermes-2-pro-llama-3-8b": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 1.4e-07,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen2.5-vl-72b-instruct": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 8e-07,
      "context_length": 32768,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/sao10k/l3-70b-euryale-v2.1": {
      "input_cost_per_token": 1.48e-06,
      "output_cost_per_token": 1.48e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-21B-a3b-thinking": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 131072,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/sao10k/l3-8b-lunaris": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baichuan/baichuan-m2-32b": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 7e-08,
      "context_length": 131072,
      "max_output_tokens": 131072,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-vl-424b-a47b": {
      "input_cost_per_token": 4.2e-07,
      "output_cost_per_token": 1.25e-06,
      "context_length": 123000,
      "max_output_tokens": 16000,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-300b-a47b-paddle": {
      "input_cost_per_token": 2.8e-07,
      "output_cost_per_token": 1.1e-06,
      "context_length": 123000,
      "max_output_tokens": 12000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-prover-v2-671b": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 160000,
      "max_output_tokens": 160000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-32b-fp8": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4.5e-07,
      "context_length": 40960,
      "max_output_tokens": 20000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-30b-a3b-fp8": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 4.5e-07,
      "context_length": 40960,
      "max_output_tokens": 20000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/google/gemma-3-27b-it": {
      "input_cost_per_token": 1.19e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 98304,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-v3-turbo": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.3e-06,
      "context_length": 64000,
      "max_output_tokens": 16000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/deepseek/deepseek-r1-turbo": {
      "input_cost_per_token": 7e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 64000,
      "max_output_tokens": 16000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/Sao10K/L3-8B-Stheno-v3.2": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 8192,
      "max_output_tokens": 32000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/gryphe/mythomax-l2-13b": {
      "input_cost_per_token": 9e-08,
      "output_cost_per_token": 9e-08,
      "context_length": 4096,
      "max_output_tokens": 3200,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-vl-28b-a3b-thinking": {
      "input_cost_per_token": 3.9e-07,
      "output_cost_per_token": 3.9e-07,
      "context_length": 131072,
      "max_output_tokens": 65536,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-8b-instruct": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 5e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/zai-org/glm-4.5-air": {
      "input_cost_per_token": 1.3e-07,
      "output_cost_per_token": 8.5e-07,
      "context_length": 131072,
      "max_output_tokens": 98304,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-30b-a3b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 7e-07,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-vl-30b-a3b-thinking": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 1e-06,
      "context_length": 131072,
      "max_output_tokens": 32768,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-omni-30b-a3b-thinking": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 9.7e-07,
      "context_length": 65536,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-omni-30b-a3b-instruct": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 9.7e-07,
      "context_length": 65536,
      "max_output_tokens": 16384,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen-mt-plus": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 7.5e-07,
      "context_length": 16384,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-vl-28b-a3b": {
      "input_cost_per_token": 1.4e-07,
      "output_cost_per_token": 5.6e-07,
      "context_length": 30000,
      "max_output_tokens": 8000,
      "provider": "novita",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/baidu/ernie-4.5-21B-a3b": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 2.8e-07,
      "context_length": 120000,
      "max_output_tokens": 8000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-8b-fp8": {
      "input_cost_per_token": 3.5e-08,
      "output_cost_per_token": 1.38e-07,
      "context_length": 128000,
      "max_output_tokens": 20000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen3-4b-fp8": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 3e-08,
      "context_length": 128000,
      "max_output_tokens": 20000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/qwen/qwen2.5-7b-instruct": {
      "input_cost_per_token": 7e-08,
      "output_cost_per_token": 7e-08,
      "context_length": 32000,
      "max_output_tokens": 32000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/meta-llama/llama-3.2-3b-instruct": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 32768,
      "max_output_tokens": 32000,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "novita/sao10k/l31-70b-euryale-v2.2": {
      "input_cost_per_token": 1.48e-06,
      "output_cost_per_token": 1.48e-06,
      "context_length": 8192,
      "max_output_tokens": 8192,
      "provider": "novita",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/llama-3.1-8b": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 5e-08,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/llama-3.2-3b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 131072,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/mistral-7b-v0.3": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 1.5e-07,
      "context_length": 32768,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/qwen3-8b": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.4e-07,
      "context_length": 32768,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/dolphin3-8b": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 1.5e-07,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/deepseek-r1-8b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 65536,
      "max_output_tokens": 16384,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/deepseek-r1-7b-qwen": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 1.5e-07,
      "context_length": 131072,
      "max_output_tokens": 16384,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/openthinker-7b": {
      "input_cost_per_token": 8e-08,
      "output_cost_per_token": 1.5e-07,
      "context_length": 32768,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/qwen2.5-coder-7b": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 1.2e-07,
      "context_length": 32768,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/deepseek-coder-6.7b": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 1.2e-07,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/codellama-7b": {
      "input_cost_per_token": 6e-08,
      "output_cost_per_token": 1.2e-07,
      "context_length": 16384,
      "max_output_tokens": 4096,
      "provider": "llamagate",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/qwen3-vl-8b": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 5.5e-07,
      "context_length": 32768,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/llava-7b": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 2e-07,
      "context_length": 4096,
      "max_output_tokens": 2048,
      "provider": "llamagate",
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "llamagate/gemma3-4b": {
      "input_cost_per_token": 3e-08,
      "output_cost_per_token": 8e-08,
      "context_length": 128000,
      "max_output_tokens": 8192,
      "provider": "llamagate",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-search-api": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-5-search-api-2025-10-14": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 272000,
      "max_output_tokens": 128000,
      "provider": "openai",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-realtime-mini-2025-10-06": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 6e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gpt-realtime-mini-2025-12-15": {
      "input_cost_per_token": 6e-07,
      "output_cost_per_token": 2.4e-06,
      "context_length": 128000,
      "max_output_tokens": 4096,
      "provider": "openai",
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 6e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.0-flash-lite-001": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": false,
      "cache_read_cost": 1.875e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-native-audio-latest": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-native-audio-preview-09-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-2.5-flash-native-audio-preview-12-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-native-audio-latest": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-native-audio-preview-09-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-2.5-flash-native-audio-preview-12-2025": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 8192,
      "provider": "gemini",
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_reasoning": false,
      "cache_read_cost": 0,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-flash-latest": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-flash-lite-latest": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-pro-latest": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini/gemini-pro-latest": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 1.25e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "gemini-exp-1206": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 2.5e-06,
      "context_length": 1048576,
      "max_output_tokens": 65535,
      "provider": "gemini",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-08,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    },
    "vertex_ai/claude-sonnet-4-6@default": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "context_length": 200000,
      "max_output_tokens": 64000,
      "provider": "vertex_ai-anthropic_models",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "cache_read_cost": 3e-07,
      "batch_input_cost": 0,
      "batch_output_cost": 0,
      "source": "litellm"
    }
  }
}